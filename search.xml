<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[源码编译Portable Pyton]]></title>
    <url>%2Fblog%2Fpractice-compile-portable-python.html</url>
    <content type="text"><![CDATA[Portable的意思是可拔插的，便携式的。Portable 程序在一台计算机上编译好后，移植到其他计算机上就可以直接运行。一般程序运行时都会依赖一些第三方库，只要把对这些库的依赖方式由静态依赖改成动态依赖，再把这些库和主体程序放到一起打包，就成为一个Portable 程序。当然Portable 也是有限度的，不能跨操作系统移植，毕竟程序对操作系统的依赖关联太多，除非把整个系统也移植了😂。 以Python-3.6.5 为例，讲述一下源码编译一个Portable Pyton 的主要流程。 Windows 平台winpython 是一个专门编译Windows 平台下Portable Pyton 的项目，可以直接下载WinPython32-3.6.5.0Zero.exe或者WinPython64-3.6.5.0Zero.exe，解压出来就是对应的32位Portable Pyton 或64位Portable Pyton. macOS 平台最好在OS X10.9系统下编译Portable Pyton，对其他更高级的macOS 兼容性会好一些。python 的一些内置模块会依赖第三方库，主要是： lzma openssl tcl/tk 所以，我们要先安装这些库。 编译lzma下载xz-5.2.3.tar.gz，解压到/tmp/xz-5.2.3，然后： 12345$ cd /tmp$ mkdir local$ cd xz-5.2.3$ ./configure --prefix=/tmp/local$ make &amp;&amp; make install 编译openssl下载openssl-OpenSSL_1_0_2t.zip，解压到/tmp/openssl-OpenSSL_1_0_2t，然后： 123$ cd /tmp/openssl-OpenSSL_1_0_2t$ ./Configure darwin64-x86_64-cc --prefix=/tmp/local -shared$ make &amp;&amp; make install 编译tcl/tk下载tcl8519-src.zip，解压到/tmp/tk8519-src；下载tk8519-src.zip，解压到/tmp/tk8519-src，然后： 12345678$ cd /tmp/tcl8519-src$ cd unix/$ ./configure --prefix=/tmp/local$ make &amp;&amp; make install$ cd /tmp/tk8519-src$ cd unix/$ ./configure --prefix=/tmp/local --with-tcl=/tmp/tcl8519-src/unix --enable-aqua$ make &amp;&amp; make install 编译python下载Python-3.6.5，解压到/tmp/Python-3.6.5， 然后： 1234567$ cd /tmp$ mkdir python$ cd Python-3.6.5$ CPPFLAGS="-I/tmp/local/include" \LDFLAGS="-L/tmp/local/lib" \./configure --prefix=/tmp/python $ make &amp;&amp; make install 修改依赖路径以上python 安装在/tmp/python，把python 依赖的第三方动态库，复制到/tmp/python/lib： 123456789$ cd /tmp/python/lib$ cp /tmp/local/lib/liblzma.5.dylib ./$ cp /tmp/local/lib/libcrypto.1.0.0.dylib ./$ cp /tmp/local/lib/libssl.1.0.0.dylib ./$ cp /tmp/local/lib/libtcl8.5.dylib ./$ cp /tmp/local/lib/libtk8.5.dylib ./$ cp -R /tmp/local/lib/tcl8 ./$ cp -R /tmp/local/lib/tcl8.5 ./$ cp -R /tmp/local/lib/tk8.5 ./ macOS下，otool工具可以查看动态库的依赖路径，intall_name_tool工具可以修改动态库的依赖路径。我们要把所有的外部依赖（除了系统依赖）都修改为/tmp/python/lib内部依赖，绝对的依赖路径也改为相对的依赖路径： 修改libssl.1.0.0.dylib：123$ cd /tmp/python/lib$ otool -L libssl.1.0.0.dylib$ sudo install_name_tool -change /tmp/local/lib/libcrypto.1.0.0.dylib @executable_path/../lib/libcrypto.1.0.0.dylib libssl.1.0.0.dylib 修改_lzma.cpython-36m-darwin.so：123$ cd /tmp/python/lib/python3.6/lib-dynload$ otool -L _lzma.cpython-36m-darwin.so$ install_name_tool -change /tmp/local/lib/liblzma.5.dylib @executable_path/../lib/liblzma.5.dylib _lzma.cpython-36m-darwin.so 修改_ssl.cpython-36m-darwin.so：123$ cd /tmp/python/lib/python3.6/lib-dynload$ otool -L libssl.1.0.0.dylib$ install_name_tool -change /tmp/local/lib/libssl.1.0.0.dylib @executable_path/../lib/libssl.1.0.0.dylib -change /tmp/local/lib/libcrypto.1.0.0.dylib @executable_path/../lib/libcrypto.1.0.0.dylib _ssl.cpython-36m-darwin.so 修改_tkinter.cpython-36m-darwin.so：123$ cd /tmp/python/lib/python3.6/lib-dynload$ otool -L libssl.1.0.0.dylib$ install_name_tool -change /System/Library/Frameworks/Tcl.framework/Versions/8.5/Tcl @executable_path/../lib/libtcl8.5.dylib -change /System/Library/Frameworks/Tk.framework/Versions/8.5/Tk @executable_path/../lib/libtk8.5.dylib _tkinter.cpython-36m-darwin.so 测试测试修改依赖路径后的python运行情况： 1234$ cd /tmp/python$ ./bin/python -m pip lmza$ ./bin/python -m pip ssl$ ./bin/python -m pip tkinter 升级pip12$ cd /tmp/python$ ./bin/python -m pip install --upgrade pip 最后我们得到了一个Portable Pyton /tmp/python，可以内嵌到其他程序中一起打包，分发到各个计算机运行。 参考 How to Compile Tcl Getting Started — Python Developer’s Guide TkDocs - Tk Tutorial - Installing Tk Portable OpenSSL dylib on Mac OS X]]></content>
      <categories>
        <category>实践</category>
      </categories>
      <tags>
        <tag>practice</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开发一个React + Electron应用]]></title>
    <url>%2Fblog%2Fpractice-develop-an-electron-app-with-react.html</url>
    <content type="text"><![CDATA[最近用React + Electron开发了一个RSS阅读器，开源在：https://github.com/breeze2/breader，这里记录一下大致的开发过程。 初始化创建项目以普通的React应用做基础，一步步初始化项目。预先安装yarn工具，用yarn来创建一个React应用项目，假设名字叫demo，再引入Electron依赖。 1234$ cd /PATH/TO/PROJECTS$ yarn create react-app YOUR_APP_NAME$ cd /PATH/TO/PROJECTS/YOUR_APP_NAME$ yarn add electron --dev 配置入口文件创建项目后，大致的目录结构如下： 123456789|--&gt;demo |--&gt;node_modules |--... |--&gt;public |--index.html |--... |--&gt;src |--package.json |--... 一般来说，React应用（测试环境下）的入口文件就是public/index.html，而Electron应用的入口文件最好也放在public目录下，并命名为electron.js（这样electron-builder可以自动识别）。 先在package.json中lectron应用的入口文件，添加main配置： 12345&#123; ... "main": "public/electron.js", ...&#125; public/electron.js代码： 123456789101112131415161718192021222324252627282930const &#123; app, BrowserWindow &#125; = require('electron')const path = require('path')let mainWindowfunction createWindow() &#123; mainWindow = new BrowserWindow(&#123; width: 960, height: 600, &#125;) mainWindow.loadFile('index.html') mainWindow.webContents.openDevTools() mainWindow.on('closed', function () &#123; mainWindow = null &#125;)&#125;app.on('ready', createWindow)app.on('window-all-closed', function () &#123; if (process.platform !== 'darwin') &#123; app.quit() &#125;&#125;)app.on('activate', function () &#123; if (mainWindow === null) &#123; createWindow() &#125;&#125;) 在执行执行yarn electron ./命令就可以启动Electron应用了，不过React应用还没启动起来。 启动应用一般用yarn react-scripts start命令，就可以将React应用挂载在本地3000端口上（ http://localhost:3000 ），用于开发调试。要用React结合Electron一起开发调试，先安装electron-is-dev来识别当前是否开发环境。 1$ yarn add electron-is-dev 一般开发环境是加载http://localhost:3000/，正式环境是加载../build/index.html文件，所以修改public/electron.js代码（createWindow函数内）： 12345678910const isDev = require('electron-is-dev')...-- // mainWindow.loadFile('index.html')++ if (isDev) &#123;++ mainWindow.loadURL('http://localhost:3000/')++ &#125; else &#123;++ mainWindow.loadFile(path.join(__dirname, '/../build/index.html'))++ &#125;... 然后，在项目目录下，打开两个终端，一个执行yarn react-scripts start，一个执行yarn electron ./，就可以开发调试React + Electron应用了。不用羡慕electron-vue，可以一句命令可以直接启动，其实原理是一样的。要实现一句命令启动也不难，只要把两句命令合到一起执行就可以了。先安装工具库： 12$ yarn add concurrently --dev$ yarn add wait-on --dev 修改package.json，添加一个electron-dev脚本命令： 123456789&#123; ... "scripts": &#123; ... "electron-dev": "concurrently \"BROWSER=none react-scripts start\" \"wait-on http://localhost:3000 &amp;&amp; electron .\"", ... &#125; ...&#125; 这样，执行一句yarn electron-dev就可以启动React + Electron应用了。 JS运行时一般来说，浏览器提供一种JS运行时，NodeJS提供另一种JS运行时，Electron则是将这两种运行时结合到一起来提供。不过，这两种运行时并不是完美地和睦相处，比如说使用webpack时，通过webpack打包的JS代码中，不能直接通过import关键字或者require函数来引入NodeJS提供的功能接口，因为webpack覆盖了NodeJS自带的require函数。不过Electron中，window对象的require属性会映射到NodeJS自带的require函数上，比如要调用NodeJS提供的http接口，可以这样写： 1const http = window.require('http') 重新编译NodeJS扩展通常，纯JS代码实现的工具库都可以在Electron环境中运行。不过有些NodeJS的工具库并不是纯JS代码实现的，比如node-sqlite3。node-sqlite3是C++编写，算是NodeJS的扩展，而不是单纯的工具库。node-sqlite3需要针对Electron环境重新编译，才能在Electron环境中运行。 electron-rebuildelectron-rebuild是专门Electron环境针对重新编译NodeJS扩展的一个工具。在项目目录下，安装electron-rebuild： 1$ yarn add electron-rebuild --dev 比如，重新编译node-sqlite3，只需要： 1$ yarn electron-rebuild -f -w sqlite3 在MacOS系统上就是这么简单，在Windows系统就复杂一些。 Windows系统上重新编译NodeJS扩展在Windows系统上也一样可以使用electron-rebuild工具，但必须预先配置好编译环境。 首先，安装window编译工具： 12$ npm install --global --production windows-build-tools$ npm config set msvs_version 2017 然后，下载并安装Python2，必须Python2不能Python3，如果同时安装了Python2和Python3，须给npm指定Python2可执行文件路径，避免调用了Python3： 1$ npm config set python /path/to/executable/python2 这样，才能在Windows系统上调用electron-rebuild。如果electron-rebuild执行过程中，遇上CONNECT ERROR可能是网络问题，可以换成淘宝源再试试。 所以尽量少用NodeJS扩展，可以免去跨平台时重新编译的麻烦。 应用打包应用开发完成后，需要打包成dmg或exe等安装文件，可以使用electron-builder electron-builderelectron-builder有很多配置选项，来调用各式各样的程序打包。这里只简单介绍一下MacOS系统安装程序和Windows系统NSIS安装程序的打包配置（NSIS是一个开源的 Windows 系统下安装程序制作工具）。 修改package.json，添加build配置： 123456789101112131415161718192021222324252627&#123; ... "homepage": "./", // 因为最后React应用引用的JS、CSS等资源都是本地的，只要用当前的相对路径即可 "build": &#123; "appId": "com.xxx.app", // 应用ID "npmRebuild": true, // 打包前是否重新编译NodeJS扩展 "mac": &#123; "category": "news", // 应用分类 "icon": "build/icon.png" // 应用icon路径 &#125;, "win": &#123; "icon": "build/icon.png", // 应用icon路径 "target": "nsis" // Windows安装文件的目标类型 &#125;, "nsis": &#123; "allowToChangeInstallationDirectory": true, // 是否允许修改安装路径 "allowElevation": false, // 是否允许提升权限 "createDesktopShortcut": true, // 是否创建桌面快捷方式 "menuCategory": true, //是否在菜单栏创建分类 "oneClick": false // 是否一键安装 &#125;, "files": [ "build/**/*" // 引入的文件 ] &#125; ...&#125; 然后，就可以打包Electron应用了： 12$ yarn react-scripts build // 先用webpack打包React应用到`build`目录下$ yarn eletron-builder // 再用eletron-builder打包Electron应用 当然，正式打包还需要代码签名，还有更多配置，请查看electron-builder配置说明。 参考 From React to an Electron app ready for production]]></content>
      <categories>
        <category>实践</category>
      </categories>
      <tags>
        <tag>practice</tag>
        <tag>react</tag>
        <tag>electron</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP代码静态分析工具PHPStan]]></title>
    <url>%2Fblog%2Fpractice-php-static-analysis-tool-phpstan.html</url>
    <content type="text"><![CDATA[最近发现自己写的PHP代码运行结果总跟自己预想的不一样，排查时发现大多是语法错误，在运行之前错误已经种下。可能是自己粗心大意，或者说php -l检测太简单，不过的确是有一些语法错误埋藏得太深（毕竟PHP是动态语言），那么有没有办法，在代码代码正式运行之前，把语法错误全找出来呢？ 这里介绍一款PHP代码静态分析工具：PHPStan，不需要运行代码，也可以对代码进行严格的语法检测，尽量将代码运行错误率降到最低。 PHPStan安装目前，PHPStanV0.10.2要求系统环境的PHP版本不低于7.1。用Composer全局安装： 1$ composer global require phpstan/phpstan 使用PHPStan静态分析的使用方法十分简单： 1$ phpstan analyse [-c|--configuration CONFIGURATION] [-l|--level LEVEL] [--no-progress] [--debug] [-a|--autoload-file AUTOLOAD-FILE] [--errorFormat ERRORFORMAT] [--memory-limit MEMORY-LIMIT] [--] [&lt;paths&gt;]... configuration：运行配置文件的路径； level：严格级别，0-7，越大越严格； no-progress：不显示进度； debug：debug模式； autoload-file：自动加载文件的路径； errorFormat：错误格式； memory-limit：内存限制； paths：待分析的文件路径。 比如，分析一个PHP文件： 1$ phpstan analyse --level=7 --autoload-file=/PATH/TO/vendor/autoload.php /PATH/TO/someone.php PHPStan in VSCode当然，语法分析应该是编辑器做的事，写完代码还要切换到命令终端执行phpstan，未免过于繁琐。所以这里推荐一款VSCode扩展：PHP Static Analysis。 首先，用Composer全局安装PHPStan；然后，在VSCode的扩展管理中搜索PHP Static Analysis，安装第一个匹配的扩展；重载VSCode重载窗口后，扩展会自动分析VSCode下打开的PHP文件。 运行效果： 比如，声明了一个变量未调用，调用了一个未声明的变量和调用了一个未定义的方法等等这样错误都会被检测出了。 不过，宽松一点地来说，其实$this-&gt;array()方法是存在的，只是通过魔术方法__call()实现的。 PHPStan with Laravel高严格级别的PHPStan检测到调用未声明的类方法时，会报告类中方法不存在的错误，即使这个类定义了__call()或__callStatic()。 很多应用框架为了优雅，大量使用了魔术方法，比如Laravel。用PHPStan检测Laravel项目，自然会报告很多调用未声明类方法的错误，对于这个问题，可以借助laravel-ide-helper来降低误报。 安装laravel-ide-helper12$ cd /PATH/TO/LARAVEL_PROJECT$ composer require barryvdh/laravel-ide-helper 注入LaravelIdeHelper编辑app/Providers/AppServiceProvider.php里的注册方法： 123456789&lt;?php ... public function register() &#123; if ($this-&gt;app-&gt;environment() !== 'production') &#123; $this-&gt;app-&gt;register(\Barryvdh\LaravelIdeHelper\IdeHelperServiceProvider::class); &#125; // ... &#125; 生成_ide_helper.php12$ cd /PATH/TO/LARAVEL_PROJECT$ php artisan ide-helper:generate 这时，Laravel框架中的Facade类，原本通过__callStatic()获取的静态方法，全部在_ide_helper.php声明了，在PHPStan检测Laravel项目代码时引入_ide_helper.php文件，就可以减少误报。 PHPStan配置在Laravel项目的根目录下，新建phpstan.neon文件： 123parameters: autoload_files: - %currentWorkingDirectory%/_ide_helper.php 在Laravel项目的根目录下，执行phpstan命令时，会自动使用phpstan.neon这个配置。 最后代码的语法错误，应该在编写的时候及时发现，尽量减少正式运行时错误。]]></content>
      <categories>
        <category>实践</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>practice</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用Swoole实现一个简单的MySQL连接池]]></title>
    <url>%2Fblog%2Fswoole-a-simple-mysql-connection-pool.html</url>
    <content type="text"><![CDATA[最近Swoole发布了4.0.2版本，内置协程更加完善，利用Swoole\Coroutine\Channel和Swoole\Coroutine\MySQL可以轻松实现一个MySQL连接池。 实现代码直接看代码，脚本mysql_connection_pool.php： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192&lt;?php// mysql_connection_pool.phpuse Swoole\Coroutine as Co;use Swoole\Coroutine\Channel as CoChannel;use Swoole\Coroutine\MySQL as CoMySQL;use Swoole\Http\Server as HttpServer;class MySqlCoroutine extends CoMySQL&#123; protected $used_at = null; public function getUsedAt() &#123; return $this-&gt;used_at; &#125; public function setUsedAt($time) &#123; $this-&gt;used_at = $time; &#125; public function isConnected() &#123; return $this-&gt;connected; &#125;&#125;class MySqlManager&#123; protected $max_number; protected $min_number; protected $config; protected $channel; protected $number; private $is_recycling = false; /** * [__construct 构造函数] * @param array $config [MySQL服务器信息] * @param integer $max_number [最大连接数] * @param integer $min_number [最小连接数] */ public function __construct(array $config, $max_number = 150, $min_number = 50) &#123; $this-&gt;max_number = $max_number; $this-&gt;min_number = $min_number; $this-&gt;config = $config; // $this-&gt;channel = new CoChannel($max_number); $this-&gt;number = 0; &#125; public function initChannel() &#123; $this-&gt;channel = new CoChannel($this-&gt;max_number); &#125; private function isFull() &#123; return $this-&gt;number === $this-&gt;max_number; &#125; private function isEmpty() &#123; return $this-&gt;number === 0; &#125; private function shouldRecover() &#123; return $this-&gt;number &gt; $this-&gt;min_number; &#125; private function increase() &#123; return $this-&gt;number += 1; &#125; private function decrease() &#123; return $this-&gt;number -= 1; &#125; protected function build() &#123; if (!$this-&gt;isFull()) &#123; printf("%d do %s\n", time(), 'build one'); $this-&gt;increase(); $mysql = new MySqlCoroutine(); $mysql-&gt;connect($this-&gt;config); $mysql-&gt;setUsedAt(time()); return $mysql; &#125; return false; &#125; protected function rebuild(MySqlCoroutine $mysql) &#123; printf("%d do %s\n", time(), 'rebuild one'); $mysql-&gt;connect($this-&gt;config); $mysql-&gt;setUsedAt(time()); return $mysql; &#125; protected function destroy(MySqlCoroutine $mysql) &#123; if (!$this-&gt;isEmpty()) &#123; printf("%d do %s\n", time(), 'destroy one'); $this-&gt;decrease(); return true; &#125; return false; &#125; public function push(MySqlCoroutine $mysql) &#123; if (!$this-&gt;channel-&gt;isFull()) &#123; printf("%d do %s\n", time(), 'push one'); $this-&gt;channel-&gt;push($mysql); return; &#125; &#125; public function pop() &#123; if ($mysql = $this-&gt;build()) &#123; return $mysql; &#125; $mysql = $this-&gt;channel-&gt;pop(); $now = time(); printf("%d do %s\n", time(), 'pop one'); if (!$mysql-&gt;isConnected()) &#123; return $this-&gt;rebuild($mysql); &#125; $mysql-&gt;setUsedAt($now); return $mysql; &#125; /** * [autoRecycling 自动回收连接] * @param integer $timeout [连接空置时限] * @param integer $sleep [循环检查的时间间隔] * @return null [null] */ public function autoRecycling($timeout = 200, $sleep = 20) &#123; if (!$this-&gt;is_recycling) &#123; $this-&gt;is_recycling = true; while (1) &#123; Co::sleep($sleep); if ($this-&gt;shouldRecover()) &#123; $mysql = $this-&gt;channel-&gt;pop(); $now = time(); if ($now - $mysql-&gt;getUsedAt() &gt; $timeout) &#123; printf("%d do %s\n", time(), 'recover one'); $this-&gt;decrease(); &#125; else &#123; !$this-&gt;channel-&gt;isFull() &amp;&amp; $this-&gt;channel-&gt;push($mysql); &#125; &#125; &#125; &#125; &#125;&#125;$server = new HttpServer('127.0.0.1', 9501, SWOOLE_BASE);$server-&gt;set([ 'worker_num' =&gt; 1,]);$manager = new MySqlManager([ 'host' =&gt; '127.0.0.1', 'port' =&gt; 3306, 'user' =&gt; 'root', 'password' =&gt; '', 'database' =&gt; 'test', 'timeout' =&gt; -1,], 4, 2);$server-&gt;on('workerStart', function ($server) use ($manager) &#123; $manager-&gt;initChannel(); $manager-&gt;autoRecycling(4, 2); // 启动自动回收&#125;);$server-&gt;on('request', function ($request, $response) use ($server, $manager) &#123; $mysql = $manager-&gt;pop(); // 取出一个MySQL连接 $mysql-&gt;query('select sleep(1);'); $manager-&gt;push($mysql); // 返回一个MySQL连接 $response-&gt;end(json_encode($server-&gt;stats()));&#125;);$server-&gt;start(); 运行效果运行脚本： 1$ php mysql_connection_pool.php ab测试： 1$ ab -c 8 -n 8 http://127.0.0.1:9501/ 间隔10秒后，再次测试： 1$ ab -c 8 -n 8 http://127.0.0.1:9501/ 输出结果： 12345678910111213141516171819202122232425262728293031323334353637381532083141 do build one1532083141 do build one1532083141 do build one1532083141 do build one1532083142 do push one1532083142 do push one1532083142 do push one1532083142 do pop one1532083142 do pop one1532083142 do pop one1532083142 do push one1532083142 do pop one1532083143 do push one1532083143 do push one1532083143 do push one1532083143 do push one1532083147 do recover one1532083149 do recover one1532083160 do build one1532083160 do build one1532083160 do pop one1532083160 do rebuild one1532083160 do pop one1532083160 do rebuild one1532083161 do push one1532083161 do pop one1532083161 do push one1532083161 do push one1532083161 do push one1532083161 do pop one1532083161 do pop one1532083161 do pop one1532083162 do push one1532083162 do push one1532083162 do push one1532083162 do push one1532083166 do recover one1532083168 do recover one 代码解释首先代码里定义了两个类，分别是： MySqlCoroutine MySqlManager MySqlCoroutineMySqlCoroutine继承自Swoole\Coroutine\MySQL，主要是为了增加一个属性used_at和两个与之配套的get/set方法：getUsedAt和setUsedAt。used_at是个时间戳，记录MySqlCoroutine的被调用的时间点。而isConnected方法是判断与服务器的连接是否有效。 MySqlManager每个MySqlCoroutine实例与MySQL服务器维系一个连接，而MySqlManager来管理这些MySqlCoroutine，即管理整个连接池。构建MySqlManager时，用到三个参数： config：用于构建MySqlCoroutine； max_number：最大连接数； min_number：最小连接数。 其实这里说的连接池，就是MySqlManager的mysql_channel属性，实际的数据类型是Swoole\Coroutine\Channel。而池内连接的数量，会用number属性记录下来。 内部方法：build/rebuild/destroy build方法：如果当前连接的数量未达到最大值，则新建一个MySqlCoroutine实例作返回值，并且number属性加1；否则，返回false。 rebuild方法：传入一个MySqlCoroutine实例，返回一个新的MySqlCoroutine实例。 destroy方法：传入一个MySqlCoroutine实例，如果number大于0，那么number减1。 公有方法：pop/push/autoRecycling pop方法：先执行build方法，若是返回MySqlCoroutine实例，则直接返回这个MySqlCoroutine实例；否则，从mysql_channel里pop（如果mysql_channel已经空了，当前协程会被挂起，等待其他协程往mysql_channel放入MySqlCoroutine实例），若是取出的MySqlCoroutine实例的连接已无效（连接可能已经被MySQL服务器自动断开），那就返回rebuild方法的值，否则直接返回这个MySqlCoroutine实例。 push方法：如果mysql_channel未满，就往mysql_channel放入一个MySqlCoroutine；否则，什么也不做。 autoRecycling方法：接收两个参数，$timeou和$sleep；每隔$sleep秒，就检查一次，当前连接的数量超过了最小值，那么就从mysql_channel里pop一个MySqlCoroutine实例，若是MySqlCoroutine实例上一次使用时间与现在时间间隔超过了$timeou秒，说明这个MySqlCoroutine实例没有被频繁使用，可以回收；所谓回收，就是从mysql_channel取出后，不再放回，并且number减1。 调用在Swoole\Http\Server的workerStart回调函数里，让MySqlManager实例开始自动回收MySqlCoroutine实例；而在Swoole\Http\Server的request回调函数里，需要MySqlCoroutine实例时，调用MySqlManager实例的pop方法从连接池里获取，用完再调用MySqlManager实例的push方法放回连接池。 最后就这样，利用Swoole扩展，几十行PHP代码就能实现一个连接间可以并行使用，池内有最大/最小数量限制，有自动回收空闲连接机制的MySQL连接池。]]></content>
      <categories>
        <category>实践</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>php</tag>
        <tag>practice</tag>
        <tag>swoole</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在JPEG图片中嵌入HTML]]></title>
    <url>%2Fblog%2Fpractice-embed-html-in-jpeg.html</url>
    <content type="text"><![CDATA[最近看到一个有趣的网页：http://lcamtuf.coredump.cx/squirrel/，或者说一张有趣的图片——因为用网络浏览器打开它看到的是一个网页，用图片浏览器打开它看到的又是一张图片。 在服务端要对同一个请求地址实现不同响应是十分简单的，比如通过请求头Accept来判断： Accept=text/html则返回超文本； Accept=image/*则返回图片； …… 可是http://lcamtuf.coredump.cx/squirrel/这个网页（或者说图片）在脱离服务端的情况下，依然能够呈现出网页和图片两种文件内容，这是怎样实现的呢？ 在前端没有秘密，打开网络浏览器的开发者工具查看一下网址的响应内容： 响应内容中有熟悉HTML标签，也有一大堆乱码。这堆乱码应该是图片文件的字符读码，但是为什么在网页上看不到呢？原来HTML中使用了body { visibility: hidden; }样式和&lt;!--注释标签（浏览器自动补全），乱码部分就这样被隐藏了。 HTML内容： 1&lt;html&gt;&lt;body&gt;&lt;style&gt;body &#123; visibility: hidden; &#125; .n &#123; visibility: visible; position: absolute; padding: 0 1ex 0 1ex; margin: 0; top: 0; left: 0; &#125; h1 &#123; margin-top: 0.4ex; margin-bottom: 0.8ex; &#125;&lt;/style&gt;&lt;div class=n&gt;&lt;h1&gt;&lt;i&gt;Hello, squirrel fans!&lt;/i&gt;&lt;/h1&gt;This is an embedded landing page for an image. You can link to this URL and get the HTML document you are viewing right now (soon to include essential squirrel facts); or embed the exact same URL as an image on your own squirrel-themed page:&lt;p&gt;&lt;xmp&gt;&lt;a href="http://lcamtuf.coredump.cx/squirrel/"&gt;Click here!&lt;/a&gt;&lt;/xmp&gt;&lt;xmp&gt;&lt;img src="http://lcamtuf.coredump.cx/squirrel/"&gt;&lt;/xmp&gt;&lt;p&gt;No server-side hacks involved - the magic happens in your browser. Let's try embedding the current page as an image right now (INCEPTION!):&lt;p&gt;&lt;img src="#" style="border: 1px solid crimson"&gt;&lt;p&gt;Pretty radical, eh? Send money to: lcamtuf@coredump.cx&lt;!-- 然而图片展示中，也没看到HTML的内容，又是为什么呢？ JPEG相关首先可以确定这张图片是JPEG格式，因为内容开头有明显的JFIF标记（JFIF，是JPEG最常见的文件存储格式，也是标准的JPEG文件转换格式）。JPEG格式定义了一系列标记码，都是以0xFF开头，常见的有： 0xFFD8：SOI（Start Of Image），图片开始标记； 0xFFD9：EOI（End Of Image），图片结束标记； 0xFFDA：SOS（Start Of Scan），扫描开始标记； 0xFFDB：DQT（Define Quantization Table），定义量化表； 0xFFC4：DHT（Define Huffman Table），定义哈夫曼表； 0xFFEn：APPn（Application Specific），应用程序信息； 0xFFFE：COM（Comment），注释； …… 图片的注释内容不会展示，很显然我们可以把HTML隐藏在图片注释中。用十六进制读取这张图片，可以看到： 这张图片中使用了注释标记0xFFFE，标记后面跟着0x0372。0x0372转成十进制是882，而HTML内容的长度刚好是880个字节（0x0372本身占2个字节），所以可以知道，HTML内容就是写在这张图片注释中。 代码实现下面用PHP代码简单实现一个将HTML内容嵌入JPEG中的函数： 1234567891011121314151617181920212223242526272829303132&lt;?phpfunction embedHtmlInJpeg($jpeg_file, $html_str, $html_file)&#123; $length = strlen($html_str) + 2; if ($length &gt; 256 * 256 - 1) &#123; return false; &#125; $content = ''; $reader = fopen($jpeg_file, 'rb'); $writer = fopen($html_file, 'wb'); $content = fread($reader, 2); // read 0xFFD8 fwrite($writer, $content); // write 0xFFD8 $header = 'FFFE' . sprintf('%04X', $length); $header = pack('H*', $header); $content = $header . $html_str; fwrite($writer, $content); // write 0xFFFE while (!feof($reader)) &#123; $content = fread($reader, 8192); fwrite($writer, $content); // write else &#125; fclose($reader); fclose($writer); return true;&#125;// call itembedHtmlInJpeg('lena.jpg', '&lt;html&gt;&lt;body&gt;&lt;style&gt;body &#123; visibility: hidden; &#125; .n &#123; visibility: visible; position: absolute; padding: 0 1ex 0 1ex; margin: 0; top: 0; left: 0; &#125; h1 &#123; margin-top: 0.4ex; margin-bottom: 0.8ex; &#125;&lt;/style&gt;&lt;div class=n&gt;&lt;h1&gt;&lt;i&gt;This image is a page.&lt;/i&gt;&lt;/h1&gt;Just open it in new tab.&lt;p&gt;&lt;img src="#" style="border: 1px solid crimson"&gt;&lt;!--', 'lena.html'); 这张图片是一个网页，不信你就在新标签页中打开它 实际应用将一段HTML文本嵌入到一张图片中，实际上，还没什么应用，哈哈哈😂。如果能将JS或Shell脚本藏在图片中，并能后期执行，那就有意思了；而且本身是一个图片文件，可以避过一些安全软件的检查。]]></content>
      <categories>
        <category>实践</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>practice</tag>
        <tag>html</tag>
        <tag>frontend</tag>
        <tag>jpeg</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在Ubuntu上运行多实例MySQL]]></title>
    <url>%2Fblog%2Fmysql-run-multiple-instances-on-ubuntu.html</url>
    <content type="text"><![CDATA[一般情况下，都是一台服务器主机运行一个MySQL实例；不过在单机配置非常高的情况下，也可以考虑运行多个MySQL实例。毕竟MySQL是单进程（多线程）的运行模式，单实例MySQL用不上太多资源。 当然，高配置的单机应该考虑使用Docker实现多MySQL服务，只是这里介绍一下如何运行多实例MySQL。本以为在Ubuntu上实现很容易，原来也并不简单。 运行环境 Ubuntu 16.04 MySQL 5.17 mysqld_multi在安装好MySQL Server后，应该是可以使用mysqld_multi的。查看配置示例命令： 123456789101112131415$ mysqld_multi --example[mysqld_multi]mysqld = /usr/bin/mysqld_safemysqladmin = /usr/bin/mysqladminuser = multi_adminpassword = my_password[mysqld2]socket = /tmp/mysql.sock2port = 3307pid-file = /var/lib/mysql2/hostname.pid2datadir = /var/lib/mysql2language = /usr/share/mysql/mysql/englishuser = unix_user1... 一般MySQL的配置文件是/etc/mysql/my.cnf或者/etc/mysql/mysql.cnf，在配置文件中最开始的地方添加： 123[mysqld_multi]mysqld = /usr/bin/mysqld_safemysqladmin = /usr/bin/mysqladmin 查看当前mysqld_multi状态： 123$ mysqld_multi report Reporting MySQL serversNo groups to be reported (check your GNRs) 可以看到没有服务组群，现在添加一个——在MySQL的配置文件中，追加： 123456[mysqld3307]socket = /tmp/mysqld/mysqld3307.sockport = 3307pid-file = /tmp/mysqld/mysqld3307.piddatadir = /var/lib/mysql/multi/data3307user = mysql 再查看当前mysqld_multi状态： 123$ mysqld_multi report Reporting MySQL serversMySQL server from group: mysqld3307 is not running 可以看到服务组群mysqld3307（注意每个服务组群名称必须以mysqld开头）没有在运行。现在还不能直接运行mysqld3307服务，因为没有初始化数据目录/var/lib/mysql/multi/data3307。 初始化数据库 过去MySQL初始化数据库使用的是mysql_install_db命令，现在是mysqld --initialize。 在Ubuntu系统上有一个系统安全程序，叫AppArmor，它会限制各个应用程序访问系统资源的权限。Root用户运行程序时也碰到权限不足错误的话，那么应该就是AppArmor限制了。比如我们需要修改mysqld的权限，就得编辑对应的AppArmor配置文件，然后重启AppArmor服务： 12$ sudo vi /etc/apparmor.d/usr.sbin.mysqld$ sudo service apparmor restart 上面服务组群mysqld3307的配置中用到的目录是/tmp/mysqld和/var/lib/mysql/multi，mysqld程序对/tmp和/var/lib/mysql都是具有读写权限的，所以不需要修改AppArmor配置文件。 现在来初始化一个新的数据库目录/var/lib/mysql/multi/data3307（以mysql用户身份执行）： 123$ sudo -u mysql mkdir /tmp/mysqld$ sudo -u mysql mkdir /var/lib/mysql/multi$ sudo -u mysql mysqld --initialize --user=mysql --datadir=/var/lib/mysql/multi/data3307 初始化成功后，新数据库会自动建立root用户，并随机生成密码，这些会记录在MySQL日志中： 1234567$ sudo tail /var/log/mysql/error.log2018-03-18T12:15:25.378684Z 0 [Warning] TIMESTAMP with implicit DEFAULT value is deprecated. Please use --explicit_defaults_for_timestamp server option (see documentation for more details).2018-03-18T12:15:26.642564Z 0 [Warning] InnoDB: New log files created, LSN=457902018-03-18T12:15:26.900383Z 0 [Warning] InnoDB: Creating foreign key constraint system tables.2018-03-18T12:15:26.986706Z 0 [Warning] No existing UUID has been found, so we assume that this is the first time that this server has been started. Generating a new UUID: 3544d1ec-2b6f-11e8-bf0a-aaaa0007ba64.2018-03-18T12:15:26.998294Z 0 [Warning] Gtid table is not ready to be used. Table 'mysql.gtid_executed' cannot be opened.2018-03-18T12:15:26.998765Z 1 [Note] A temporary password is generated for root@localhost: 4kDUVrlO&gt;zT) 我们先记住密码4kDUVrlO&gt;zT)。 启动新实例执行一下命令即可以mysql用户身份启动服务组群mysqld3307（不需要前缀mysqld）： 1$ sudo -u mysql mysqld_multi start 3307 查看当前mysqld_multi状态： 123$ mysqld_multi report Reporting MySQL serversMySQL server from group: mysqld3307 is running 重置一下密码： 123$ mysqladmin -uroot -h 127.0.0.1 -P 3307 -p'4kDUVrlO&gt;zT)' passwordNew password:Confirm new password: 连接服务组群mysqld3307： 1$ mysql -uroot -h 127.0.0.1 -P 3307 -p 关闭实例原以为关闭服务组群mysqld3307，只需要： 1$ sudo -u mysql mysqld_multi stop 3307 结果查看mysqld_multi状态，mysqld3307依然是运行中： 123$ mysqld_multi report Reporting MySQL serversMySQL server from group: mysqld3307 is running 可能是因为mysqld3307数据库中没有与mysqld_multi配置对应的用户，所以mysqld_multi stop命令没能关闭mysqld3307。 我们可以用mysqladmin命令来关闭服务组群mysqld3307： 1$ mysqladmin -uroot -h 127.0.0.1 -P 3307 -p shutdown 最后这里只介绍了监听3307端口的MySQL实例的建立过程，其他更多MySQL实例，如监听3308、3309端口，只需按照上述流程（添加配置，初始化数据目录，启动服务）执行即可。]]></content>
      <categories>
        <category>躬行</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一些有趣的MySQL查询问题]]></title>
    <url>%2Fblog%2Fnote-mysql-in-leetcode.html</url>
    <content type="text"><![CDATA[在LeetCode上有一些有趣的MySQL查询问题，这里记录下来，方便以后查阅。 Department Top Three Salaries部门前三薪资问题：查询各个部门薪资前三的员工（薪资），并列排名只占一位。 原题The Employee table holds all employees. Every employee has an Id, and there is also a column for the department Id. 12345678910+----+-------+--------+--------------+| Id | Name | Salary | DepartmentId |+----+-------+--------+--------------+| 1 | Joe | 70000 | 1 || 2 | Henry | 80000 | 2 || 3 | Sam | 60000 | 2 || 4 | Max | 90000 | 1 || 5 | Janet | 69000 | 1 || 6 | Randy | 85000 | 1 |+----+-------+--------+--------------+ The Department table holds all departments of the company. 123456+----+----------+| Id | Name |+----+----------+| 1 | IT || 2 | Sales |+----+----------+ Write a SQL query to find employees who earn the top three salaries in each of the department. For the above tables, your SQL query should return the following rows. 123456789+------------+----------+--------+| Department | Employee | Salary |+------------+----------+--------+| IT | Max | 90000 || IT | Randy | 85000 || IT | Joe | 70000 || Sales | Henry | 80000 || Sales | Sam | 60000 |+------------+----------+--------+ 答案先说答案： 12345select dep.Name as "Department", emp.Name as "Employee", emp.Salary as "Salary"from Department as dep join Employee as emp on dep.Id = emp.DepartmentIdwhere exists (select 'x' from Employee as emp1 where emp1.Salary &gt; emp.Salary and emp1.DepartmentId = emp.DepartmentId having count(distinct emp1.Salary) &lt; 3); 首先Department和Employee联接是不可少的，因为结果包含两张表的字段；再用子查询（exists），保留同部门内高于本身薪资的不超过三个的员工（having），并列排名只占一位，需要去重（distinct）。 注意：以上&#39;x&#39;并无特殊意义，只是有值时表示存在，无值时表示不存在。；having应该配合group by使用，单独使用having时视当前数据为一组；count()函数也是，单独使用having时也相当于给当前数据分成一组。 另外：只用一个select（没有子查询）也能实现，就是将Employee和自身join，on薪资比自己高的员工；然后用group by去重，再结合having count(distinct emp1.Salary) &lt; 3，保留有效结果。这个join方法效率远低于上面子查询方法，所以不要对子查询有偏见。 Human Traffic of Stadium连续达标问题：查询连续3天体育馆人数高于100的日期。 原题X city built a new stadium, each day many people visit it and the stats are saved as these columns: id, date, peoplePlease write a query to display the records which have 3 or more consecutive rows and the amount of people more than 100(inclusive).For example, the table stadium: 123456789101112+------+------------+-----------+| id | date | people |+------+------------+-----------+| 1 | 2017-01-01 | 10 || 2 | 2017-01-02 | 109 || 3 | 2017-01-03 | 150 || 4 | 2017-01-04 | 99 || 5 | 2017-01-05 | 145 || 6 | 2017-01-06 | 1455 || 7 | 2017-01-07 | 199 || 8 | 2017-01-08 | 188 |+------+------------+-----------+ For the sample data above, the output is: 12345678+------+------------+-----------+| id | date | people |+------+------------+-----------+| 5 | 2017-01-05 | 145 || 6 | 2017-01-06 | 1455 || 7 | 2017-01-07 | 199 || 8 | 2017-01-08 | 188 |+------+------------+-----------+ Note:Each day only have one row record, and the dates are increasing with id increasing. 答案思路是先找出人数大于100的日期，然后在这些日期附近再找数大于100的日期，保留能够形成连续3天的日期。提示里说表中每一天都有一条记录，而且日期是随id递增，所以我们只需要计算id，而不是日期。用子查询的方法： 12345678910111213select s.id, s.date, s.people from stadium as s where s.people &gt;= 100 and exists(select 'x' from stadium as s1 where s1.people &gt;= 100 and s1.id &gt;= s.id-2 and s1.id &lt;= s.id+2 and s1.id&lt;&gt;s.id having count(s1.id) &gt; 2 or (count(s1.id) = 2 and (sum(s1.id-s.id) not in (-1,1) and sum(abs(s1.id-s.id)) &lt;&gt; 4) ) ); 在当前日期的前2天和后2天找，找到人数大于100的日期个数大于2的话，那么当前日期必定可以形成连续3天人数大于100；找到人数大于100的日期个数等于2，且这两个日期与当前日期的距离和不是1或-1，绝对距离和不是4的话，那么当前日期也是可以形成连续3天人数大于100；其他情况都不行。 用join的方法： 12345678select distinct t1.*from stadium t1, stadium t2, stadium t3where t1.people &gt;= 100 and t2.people &gt;= 100 and t3.people &gt;= 100 and ( (t1.id - t2.id = 1 and t1.id - t3.id = 2 and t2.id - t3.id =1) -- t1, t2, t3 or (t2.id - t1.id = 1 and t2.id - t3.id = 2 and t1.id - t3.id =1) -- t2, t1, t3 or (t3.id - t2.id = 1 and t2.id - t1.id =1 and t3.id - t1.id = 2) -- t3, t2, t1 )order by t1.id; 同样，上面的子查询方法依然比这个join方法效率高。 Trips and Users原题用户取消叫车服务问题：统计一个时间段内每天用户取消叫车服务占所有叫车服务的比例。The Trips table holds all taxi trips. Each trip has a unique Id, while Client_Id and Driver_Id are both foreign keys to the Users_Id at the Users table. Status is an ENUM type of (‘completed’, ‘cancelled_by_driver’, ‘cancelled_by_client’). 1234567891011121314+----+-----------+-----------+---------+--------------------+----------+| Id | Client_Id | Driver_Id | City_Id | Status |Request_at|+----+-----------+-----------+---------+--------------------+----------+| 1 | 1 | 10 | 1 | completed |2013-10-01|| 2 | 2 | 11 | 1 | cancelled_by_driver|2013-10-01|| 3 | 3 | 12 | 6 | completed |2013-10-01|| 4 | 4 | 13 | 6 | cancelled_by_client|2013-10-01|| 5 | 1 | 10 | 1 | completed |2013-10-02|| 6 | 2 | 11 | 6 | completed |2013-10-02|| 7 | 3 | 12 | 6 | completed |2013-10-02|| 8 | 2 | 12 | 12 | completed |2013-10-03|| 9 | 3 | 10 | 12 | completed |2013-10-03| | 10 | 4 | 13 | 12 | cancelled_by_driver|2013-10-03|+----+-----------+-----------+---------+--------------------+----------+ The Users table holds all users. Each user has an unique Users_Id, and Role is an ENUM type of (‘client’, ‘driver’, ‘partner’). 123456789101112+----------+--------+--------+| Users_Id | Banned | Role |+----------+--------+--------+| 1 | No | client || 2 | Yes | client || 3 | No | client || 4 | No | client || 10 | No | driver || 11 | No | driver || 12 | No | driver || 13 | No | driver |+----------+--------+--------+ Write a SQL query to find the cancellation rate of requests made by unbanned clients between Oct 1, 2013 and Oct 3, 2013. For the above tables, your SQL query should return the following rows with the cancellation rate being rounded to two decimal places. 1234567+------------+-------------------+| Day | Cancellation Rate |+------------+-------------------+| 2013-10-01 | 0.33 || 2013-10-02 | 0.00 || 2013-10-03 | 0.50 |+------------+-------------------+ 答案1234select Request_at as "Day", round(1-sum(t.Status="completed")/count(t.id), 2) as "Cancellation Rate"from Trips as t join users as u on u.Users_Id = t.Client_Id and u.Banned = "No"where t.Request_at &gt;='2013-10-01' and t.Request_at&lt;='2013-10-03'group by t.Request_at; Median Employee Salary原题中位薪资问题：查询各家公司中薪资排中位的的员工（薪资）。The Employee table holds all employees. The employee table has three columns: Employee Id, Company Name, and Salary. 123456789101112131415161718192021+-----+------------+--------+|Id | Company | Salary |+-----+------------+--------+|1 | A | 2341 ||2 | A | 341 ||3 | A | 15 ||4 | A | 15314 ||5 | A | 451 ||6 | A | 513 ||7 | B | 15 ||8 | B | 13 ||9 | B | 1154 ||10 | B | 1345 ||11 | B | 1221 ||12 | B | 234 ||13 | C | 2345 ||14 | C | 2645 ||15 | C | 2645 ||16 | C | 2652 ||17 | C | 65 |+-----+------------+--------+ Write a SQL query to find the median salary of each company. Bonus points if you can solve it without using any built-in SQL functions. 123456789+-----+------------+--------+|Id | Company | Salary |+-----+------------+--------+|5 | A | 451 ||6 | A | 513 ||12 | B | 234 ||9 | B | 1154 ||14 | C | 2645 |+-----+------------+--------+ 答案12345678select emp.Id, emp.Company, emp.Salaryfrom Employee as empjoin (select Company, count(*) as EmployeeNum from Employee group by Company) as emp1on emp1.Company = emp.Companywhere exists (select 'x' from Employee as emp2 where emp2.Company = emp.Company and emp2.Salary &lt; emp.Salary having count(emp2.Id) in ( floor((EmployeeNum-1)/2), floor(EmployeeNum/2) ));]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Swoole+Lumen：同步编程风格调用MySQL异步查询]]></title>
    <url>%2Fblog%2Fswoole-lumen-asynchronous-mysql-query-with-synchronous-programming-style.html</url>
    <content type="text"><![CDATA[网络编程一直是PHP的短板，尽管Swoole扩展弥补了这个缺陷，但是其编程风格偏向了NodeJS或GoLang，与原本的同步编程风格迥然相异。目前PHP的大部分主流应用框架依然是同步编程风格，所以一直在探索Swoole与同步编程结合的途径。lumen-swoole-http正是连接同步编程Lumen和异步编程Swoole的一座桥梁，有兴趣可以关注一下。 LNMP的不足LNMP是经典的Web应用架构组合，虽然（Linux、NginX、MySQL和PHP-FPM）四者各种是优秀的系统或软件，但是组合到一起的总体性能并不尽人意，明显的不是1+1+1+1&gt;4，而是4+3+2+1&lt;1。Linux系统无可厚非，主要问题出现在： 从NginX到PHP-FPMNginX利用IO多路复用机制epoll，极大地减少了IO阻塞等待，可以轻松应对C10K。可是每次NginX将用户请求传递给PHP-FPM时，PHP-FPM总是需要从新加载PHP项目代码：创建执行环境，读取PHP文件和代码解析、编译等操作一次又一次的重复执行，造成不小的消耗。 从PHP-FPM到MySQL由于PHP代码本身是同步执行，PHP-FPM连接MySQL查询数据时，只能空闲等待MySQL返回查询结果。一个查询语句执行时间可能会需要几秒钟，期间PHP-FPM若是能暂时放下当前用户慢查询请求，而去处理其他用户请求，效率必然有所提高。 Swoole HTTP服务器Swoole HTTP服务器也采用了epoll机制，运行性能与NginX相比，虽不及，犹未远。不过Swoole HTTP服务器嵌入PHP中作为其一部分，可以直接运行PHP，完全可以取代NginX + PHP-FPM组合。 以目前流行的为框架Lumen（Laravel的子框架）为例，用Swoole HTTP服务器运行Lumen项目十分简单，只需要在$worker-&gt;onRequest($request, $response)（收到用户请求）时将$request传给Lumen处理，$response再将Lumen的处理结果返回给用户，而且$worker的整个生命周期里只会加载一次Lumen项目代码，没有多余的磁盘IO和PHP代码编译的开销。 压力测试在4GB+4Core的虚拟机下，测试HTTP服务器的静态输出： 2000客户端并发500000请求，不开启HTTP Keepalive，平均QPS： 123NginX + HTML QPS：25883.44NginX + PHP-FPM + Lumen QPS：828.36Swoole + Lumen QPS：13647.75 2000客户端并发500000请求，开启HTTP Keepalive，平均QPS： 123NginX + HTML QPS：86843.11NginX + PHP-FPM + Lumen QPS：894.06Swoole + Lumen QPS：18183.43 可以看出，Swoole + Lumen组合的执行效率远高于NginX + PHP-FPM + Lumen组合。 异步MySQL客户端 以上都是铺垫，以下才是整篇文章的重点😂😂😂 一个PHP应用要做的事不会是单纯的数据计算和数据输出，更多的是与数据库数据交互。以MySQL数据库为例，在只有一个PHP进程的情况，有10个用户同时请求执行select sleep(1);（耗时1秒）查询语句，若是使用MySQL同步查询，那么总耗时至少是10秒；若是使用MySQL异步查询，那么总耗时可能压缩到1到2秒内。 在PHP应用中能够实现数据库异步查询，才能更大的突破性能瓶颈。 虽然Swoole提供了异步MySQL客户端，但是其异步编程风格与Lumen这种同步编程风格的项目框架冲突，那么有没有可能在同步编程风格代码中调用异步MySQL客户端呢？ 一开始我觉得这是不可能的，直到看了这篇文章：Cooperative multitasking using coroutines (in PHP!)。当然，我看的是中文版： 在PHP中使用协程实现多任务调度，文中提到了PHP5.5加入的一个新功能：yield。 Yieldyield是个动词，意思是“生成”，PHP中yield生出的东西叫Generator，意思是“生成器”😂😂😂。 个人理解是：yield将当前执行的上下文作为当前函数的结果返回（yield必须在函数中使用）。 在系统层面，各个进程的运行秩序由CPU调度；而有了yield，在PHP进程内，程序员可以自由调度各个代码块的执行顺序。比如，当“发现”当前用户请求的MySQL查询将会花费较多的时间，那么可以将当前执行上下文记录起来，交给异步MySQL客户端处理（与用户请求相关的$request和$response也传递过去），而主进程继续处理下一个用户请求。 约定声明前面用了“发现”这个词，当然程序不可能智能地发现还没执行的查询语句将会是个慢查询，我们需要一些约定和声明。Lumen框架是经典的MVC模式，我们约定C即Controller是处理用户请求的最后一步——Controller接受用户请求$request并返回响应$response。同时我们声明一个类，叫SlowQuery，这个类十分简单（具体请参见SlowQuery.php）： 123456789101112&lt;?phpnamespace BL\SwooleHttp\Database;class SlowQuery&#123; public $sql = ''; public function __construct($sql) &#123; $this-&gt;sql = $sql; &#125;&#125; 比如，Lumen项目中有这么一个Controller： 12345678910111213&lt;?phpnamespace App\Http\Controllers;use App\Http\Controllers\Controller;use DB;class TestController extends Controller&#123; public function test() &#123; $a = DB::select('select sleep(1);'); response()-&gt;json($a); &#125;&#125; 上面的DB::select使用的同步MySQL客户端查询，我们用SlowQuery对象替换它： 12345678910111213&lt;?phpnamespace App\Http\Controllers;use App\Http\Controllers\Controller;use BL\SwooleHttp\Database\SlowQuery;class TestController extends Controller&#123; public function test() &#123; $a = yield new SlowQuery('select sleep(1);'); response()-&gt;json($a); &#125;&#125; 以Swoole HTTP服务器运行Lumen项目时，我们一定会获取Controller的返回结果。Controller的返回结果一般可以直接包装成Lumen响应返回给用户的，但返回结果若是一个生成器Generator对象，而且其当前值是一个慢查询SlowQuery对象的话，那么我们可以取出SlowQuery对象的sql属性，交由异步MySQL客户端执行；在异步查询的回调函数中将查询结果放回Generator对象存储的上下文中运行，得到最后结果才返回给用户；而主进程没有阻塞，可以继续处理其他用户请求。 当然，如果想用Eloquent ORM，那也很简单：我们先继承Lumen的Model，封装成一个新的Model类（具体参见Model.php），应用中的数据模型都继承于新的Model，Controller就可以这样写： 1234567891011121314&lt;?phpnamespace App\Http\Controllers;use App\Http\Controllers\Controller;use App\Models\User;use DB;class TestController extends Controller&#123; public function test() &#123; $a = yield User::select(DB::raw('sleep(1)'))-&gt;yieldGet(); // 注意User须继承自\BL\SwooleHttp\Database\Model response()-&gt;json($a); &#125;&#125; 以上三个Controller最终产出的用户响应都是一样的，不过后两者使用的是异步MySQL客户端，效率更高。 任务调度器当然，我们还需要一个任务调度器来执行这些生成器，任务调度器的实现方法 在PHP中使用协程实现多任务调度文中“多任务协作”章节里有介绍，这里不展开。Lumen框架中的代码保持了同步编程风格，而任务调度器中使用了异步编程风格来调用异步MySQL客户端。任务调度器是在Swoole HTTP服务器层面使用的，具体参见Service.php。 连接限制其实，每开启一个Swoole异步MySQL客户端，主进程就会新建一个线程连接MySQL，若是建立太多连接（线程），会增加自身服务器的压力，也会增加MySQL数据库服务器的压力。这种利用yield来调用异步MySQL客户端处理慢查询而产生的线程，暂且称它为“慢查询协程”。为了限制数据库连接数量，我们可以设置一个全局变量记录可新建慢查询协程的数量MAX_COROUTINE，开启一个异步MySQL客户端时让其减一，关闭一个异步MySQL客户端时让其加一；当用户请求慢查询时，MAX_COROUTINE大于0则由异步MySQL客户端处理，MAX_COROUTINE等于0时则由主进程“硬着头皮”自己处理。 压力测试在4GB+4Core的虚拟机下，测试HTTP服务器与数据库读写： 一般的快速查询和快速写入测试： 200并发50000请求读，利用HTTP Keepalive，平均QPS： 12NginX + PHP-FPM + Lumen + MySQL QPS：521.56Swoole + Lumen + MySQL QPS：7509.99 200并发50000请求写，利用HTTP Keepalive，平均QPS： 12NginX + PHP-FPM + Lumen + MySQL QPS：449.44Swoole + Lumen + MySQL QPS：1253.93 慢查询协程测试： 16worker的Swoole HTTP服务器，并发执行select sleep(1);请求的最大效率是15.72rps； 16worker x 10coroutine的Swoole HTTP服务器，并发执行select sleep(1);请求的最大效率是151.93rps。 这里为什么说最大效率呢？因为当并发量远大于worker数目 x coroutine数目时，可开启慢查询协程的Swoole HTTP服务器的效率会逐渐跌向普通Swoole HTTP服务器。 select sleep(1);查询语句耗时1秒，每个用户请求都需要1秒时间来处理；不过，16进程的、每个进程可开启10个慢查询协程的Swoole HTTP服务器的每秒最多可以处理160个用户请求，而16进程的普通Swoole HTTP服务器每秒最多只能处理16个用户请求。 延伸其实利用yield，我们还可以实现各种各样的“协程”。比如，Swoole2.1版本已经开始支持go函数与通道，后续我们可能还可以将Lumen Controller中一些IO阻塞的操作的上下文移至go函数里执行，这样既保留了同步编程的风格，由达到异步执行的性能。 最后以上理论，已经在lumen-swoole-http项目中实现。lumen-swoole-http是连接同步编程Lumen和异步编程Swoole的一座桥梁，可以帮助原生PHP的Lumen应用项目快速迁移到Swoole HTTP服务器上；当然也可以快速迁移回去😂。有兴趣的同学可以尝试使用： 安装 使用 配置 慢查询协程 …]]></content>
      <categories>
        <category>求索</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>swoole</tag>
        <tag>lumen</tag>
        <tag>think</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在Lumen项目中自定义后置异步协程]]></title>
    <url>%2Fblog%2Fswoole-lumen-define-post-processing-coroutine.html</url>
    <content type="text"><![CDATA[上一篇文章介绍了利用yield特性实现后置的MySQL异步查询协程，按照这种“后置执行”的思路，其实还可以实现更多其他的后置异步协程。这里介绍如何自定义一个后置异步协程，将最大开发自由度交由Lumen框架使用者。 CustomAsyncProcesslumen-swoole-http中已经定义了抽象类CustomAsyncProcess，在处理用户请求时，若是捕获到CustomAsyncProcess类的对象，程序便会按照CustomAsyncProcess对象的指定方法执行。部分代码： 123456789101112&lt;?php ... $current_value = $last_generator-&gt;current(); if ($current_value instanceof CustomAsyncProcess) &#123; if ($worker-&gt;canDoCoroutine()) &#123; $worker-&gt;upCoroutineNum(); return $current_value-&gt;runAsyncTask($request, $response, $worker, $this-&gt;scheduler, $last_generator); &#125; else &#123; return $current_value-&gt;runNormalTask($request, $response, $worker, $this-&gt;scheduler, $last_generator); &#125; &#125; ... 一个简单的后置协程我们先来实现一个简单的后置协程EasyProcess，继承自CustomAsyncProcess，需要实现两个抽象方法： 1234567891011121314151617181920212223242526272829303132&lt;?phpnamespace App\http\AfterCoroutines;use BL\SwooleHttp\Service;use BL\SwooleHttp\Coroutine\SimpleSerialScheduler;use Generator;use swoole_http_request as SwooleHttpRequest;use swoole_http_response as SwooleHttpResponse;class EasyProcess extends \BL\SwooleHttp\Coroutine\CustomAsyncProcess&#123; // 因为有协程数量限制，达到最大协程数量时，会调用runNormalTask方法 public function runNormalTask(SwooleHttpRequest $request, SwooleHttpResponse $response, Service $worker, SimpleSerialScheduler $scheduler, Generator $last_generator) &#123; $value = 2; // 给最后一层生成器，传入$value值，并递归导出整个生成器套层的最终值$final $final = $this-&gt;fullRunScheduler($scheduler, $last_generator, $value); $http_response = $final; // 注意：runNormalTask方法中使用makeNormalResponse方法响应用户请求 $this-&gt;makeNormalResponse($request, $response, $worker, $http_response); &#125; // 没达到最大协程数量时，会调用runAsyncTask方法 public function runAsyncTask(SwooleHttpRequest $request, SwooleHttpResponse $response, Service $worker, SimpleSerialScheduler $scheduler, Generator $last_generator) &#123; $value = 1; // 给最后一层生成器，传入$value值，并递归导出整个生成器套层的最终值$final $final = $this-&gt;fullRunScheduler($scheduler, $last_generator, $value); $http_response = $final; // 注意：runAsyncTask方法中使用makeAsyncResponse方法响应用户请求 $this-&gt;makeAsyncResponse($request, $response, $worker, $http_response); &#125;&#125; 然后就可以在Controller中使用这个后置协程： 12345678910111213&lt;?phpnamespace App\Http\Controllers;use App\http\AfterCoroutines\EasyProcess;use App\Http\Controllers\Controller;class TestController extends Controller&#123; public function test() &#123; $a = yield new EasyProcess(); response()-&gt;json($a); &#125;&#125; 当访问TestController@test对应的路由时，得到的返回结果有可能是1，也有可能是2，视当时协程数量而定。1或2这个结果在TestController@test层面上是未曾知的，是由EasyProcess这个后置协程产出的。 EasyProcess不算一个异步协程，无论runNormalTask方法或者runAsyncTask方法，都是同步执行的。若想实现异步执行，必须使用Swoole提供的异步客户端，详细请查看Swoole官方文档AsyncIO。 下面介绍如何实现一个后置的异步HTTP客户端协程。 一个后置的异步HTTP客户端协程假设我们处理某个用户请求时，需要从远端链接http://www.domain.com/api/data获取一些数据，期间可能需要耗时几秒钟，那么怎样用后置异步协程实现来避免阻塞呢？ 我们先来实现一个简单的后置协程AysncHttpProcess，继承自CustomAsyncProcess，需要实现两个抽象方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;?phpnamespace App\http\AfterCoroutines;use BL\SwooleHttp\Service;use BL\SwooleHttp\Coroutine\SimpleSerialScheduler;use Generator;use swoole_http_request as SwooleHttpRequest;use swoole_http_response as SwooleHttpResponse;use Swoole\Http2\Client as SwooleHttpClient;class AysncHttpProcess extends \BL\SwooleHttp\Coroutine\CustomAsyncProcess&#123; public function $url; public function __construct($url) &#123; $this-&gt;url = $url; &#125; // 因为有协程数量限制，达到最大协程数量时，会调用runNormalTask方法 public function runNormalTask(SwooleHttpRequest $request, SwooleHttpResponse $response, Service $worker, SimpleSerialScheduler $scheduler, Generator $last_generator) &#123; $data = file_get_contents($this-&gt;url); // 给最后一层生成器，传入$value值，并递归导出整个生成器套层的最终值$final $final = $this-&gt;fullRunScheduler($scheduler, $last_generator, $data); $http_response = $final; // 注意：runNormalTask方法中使用makeNormalResponse方法响应用户请求 $this-&gt;makeNormalResponse($request, $response, $worker, $http_response); &#125; // 没达到最大协程数量时，会调用runAsyncTask方法 public function runAsyncTask(SwooleHttpRequest $request, SwooleHttpResponse $response, Service $worker, SimpleSerialScheduler $scheduler, Generator $last_generator) &#123; $client = new SwooleHttpClient(); $caller = $this; $client-&gt;get($this-&gt;url, function ($o) use($client, $caller) &#123; $data = $o-&gt;body; // 给最后一层生成器，传入$value值，并递归导出整个生成器套层的最终值$final $final = $caller-&gt;fullRunScheduler($scheduler, $last_generator, $value); $http_response = $final; // 注意：runAsyncTask方法中使用makeAsyncResponse方法响应用户请求 $caller-&gt;makeAsyncResponse($request, $response, $worker, $http_response); $client-&gt;close(); &#125;); &#125;&#125; 然后就可以在Controller中使用这个后置协程： 12345678910111213&lt;?phpnamespace App\Http\Controllers;use App\http\AfterCoroutines\AysncHttpProcess;use App\Http\Controllers\Controller;class TestController extends Controller&#123; public function test() &#123; $a = yield new AysncHttpProcess('http://www.domain.com/api/data'); response()-&gt;json($a); &#125;&#125; 就这样，在协程数量允许情况下，我们可以使用后置的异步HTTP客户端协程获取远端数据，并且避免了阻塞。 最后三篇文章： 用Swoole HTTP服务器运行Lumen项目的实现方法 在Lumen项目中使用Swoole异步MySQL客户端的实现方法 在Lumen项目中自定义后置异步协程 至此，已经将lumen-swoole-http的设计理念介绍完了，主要是两点： 利用Swoole HTTP服务器运行Lumen项目，提高执行效率； 利用后置异步协程，保持同步编程风格，避免主进程阻塞。 Swoole填补了PHP网络编程的缺陷，引入NodeJS、GoLang等语言的并行执行特性，使用了不同的编程风格。对此，不应该一味抗拒，而是学会融会贯通——学无止境，知识没有界限，PHPer也应该学习其他语言的设计理念，特别是为高并发而生的GoLang。]]></content>
      <categories>
        <category>求索</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>swoole</tag>
        <tag>lumen</tag>
        <tag>think</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在Lumen项目中使用Swoole异步MySQL客户端的实现方法]]></title>
    <url>%2Fblog%2Fswoole-lumen-use-async-mysql-client-in-lumen.html</url>
    <content type="text"><![CDATA[上一篇文章介绍了用Swoole HTTP服务器替代NginX + PHP-FPM来运行Lumen项目的方法，提高运行效率。不过，在处理用户请求过程中还是会存在很多IO阻塞情况，比如MySQL数据查询。有没有可能在Lumen中使用异步MySQL客户端，以此避免IO阻塞呢？ 异步MySQL客户端Swoole1.8.6增加了内置异步MySQL客户端的支持，无需依赖其他第三方库，使用方法也非常简单，（具体参考Swoole官方文档异步MySQL客户端）： 1234567891011121314151617181920212223&lt;?php$db = new \swoole_mysql;$mysql_config = array( 'host' =&gt; '192.168.56.102', 'port' =&gt; 3306, 'user' =&gt; 'test', 'password' =&gt; 'test', 'database' =&gt; 'test', 'charset' =&gt; 'utf8', //指定字符集 'timeout' =&gt; 2,);$db-&gt;connect($mysql_config, function ($db, $r) &#123; if ($r) &#123; $sql = 'show tables'; $db-&gt;query($sql, function($db, $r) &#123; if ($r) &#123; var_dump($r); &#125; $db-&gt;close(); &#125;); &#125;&#125;); 这是典型回调处理的异步编程风格，而Lumen本身是同步编程风格，在编程层面，两者不能融合。比如，有这么一个Controller： 12345678910111213&lt;?phpnamespace App\Http\Controllers;use App\Http\Controllers\Controller;use DB;class TestController extends Controller&#123; public function test() &#123; $a = DB::query('select * from users;'); response()-&gt;json($a); &#125;&#125; 若是改写成： 1234567891011121314151617181920212223&lt;?phpnamespace App\Http\Controllers;use App\Http\Controllers\Controller;class TestController extends Controller&#123; public function test() &#123; $a = null; $db = new \swoole_mysql; $db-&gt;connect($mysql_config, function ($db, $r) use ($a) &#123; if ($r) &#123; $db-&gt;query('select * from users;', function($db, $r) use ($a) &#123; if ($r) &#123; $a = json_decode(json_encode($r)); &#125; $db-&gt;close(); &#125;); &#125; &#125;); response()-&gt;json($a); &#125;&#125; 这样返回的响应永远是null，因为response()-&gt;json($a)会在$db-&gt;query()之前被执行。 一开始我也觉得Lumen项目里永远没办法使用异步MySQL客户端了，直到看了这篇文章：Cooperative multitasking using coroutines (in PHP!)。当然，我看的是中文版： 在PHP中使用协程实现多任务调度，文中提到了PHP5.5加入的一个新功能：yield。 yieldyield是个动词，意思是“生成”，PHP中yield生出的东西叫Generator，译作“生成器”。yield可以做什么呢？yield可以将当前执行的上下文作为当前函数的结果返回（yield必须在函数中使用）。有了yield，又能怎样呢？ 首先，我们声明一个类，叫SlwoQuery： 1234567891011&lt;?phpnamespace BL\SwooleHttp\Database;class SlowQuery&#123; public $sql = ''; public function __construct($sql) &#123; $this-&gt;sql = $sql; &#125;&#125; 结合上一篇文章《用Swoole HTTP服务器运行Lumen项目的实现方法》，我们修改一下Service类的onRequest方法： 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;?php public function onRequest(\swoole_http_request $request,\swoole_http_response $response) &#123; $app = $this-&gt;app; // 处理用户请求 $http_request = $this-&gt;parseRequest($request); $http_response = $app-&gt;dispatch($http_request); if ($http_response instanceof \Generator) &#123; $gen = $http_response-&gt;current(); $gen_queue = new \SplQueue(); while($gen instanceof Generator) &#123; $gen_queue-&gt;push($gen); $gen = $gen-&gt;current(); &#125; $last_gen = $gen_queue-&gt;pop(); $value = $last_gen-&gt;current(); if ($value instanceof \BL\SwooleHttp\Database\SlowQuery) &#123; $db = new \swoole_mysql; $caller = $this; // 关键部分 $db-&gt;connect($mysql_config, function ($db, $r) use ($caller, $request, $response, $gen_queue, $last_gen, $value) &#123; if ($r) &#123; $db-&gt;query($value-&gt;sql, function($db, $r) use ($caller, $request, $response, $gen_queue, $last_gen) &#123; if ($r) &#123; // 关键部分 $r = json_decode(json_encode($r)); $last_gen-&gt;send($r); $ret = $last_gen-&gt;getReturn(); while(!$gen_queue-&gt;isEmpty()) &#123; $gen = $gen_queue-&gt;pop(); $gen-&gt;send($ret); $ret = $gen-&gt;getReturn(); &#125; $caller-&gt;makeResponse($response, $ret); &#125; $db-&gt;close(); &#125;); &#125; &#125;); &#125; &#125; else &#123; // 响应用户请求 $this-&gt;makeResponse($response, $http_response); &#125; &#125; 代码是长了些，因为没做分拆和封装，主要关注$db-&gt;connect()和$caller-&gt;makeResponse()的出现位置。整块代码的意思是： 如果Lumen处理用户请求的返回结果是一个生成器，那么就从这个生成器的函数套层里寻找（SlowQuery）； 如果当前生成器的当前值也是一个生成器，那么就往更深一层里寻找； 如果当前生成器的当前值是一个SlowQuery对象，那么将SlowQuery对象的sql属性，交给异步MySQL客户swoole_mysql查询数据； 将查询数据传入当前生成器，获得当前层函数的返回结果； 将函数返回结果传入上一层生成器，获取上一层函数的返回结果，重复直到没有更高层生成器； 才将最顶层层的函数返回结果作为响应输出给用户。虽然整个过程很绕，但是，在Lumen的Controller层面却是十分的直接了然：12345678910111213&lt;?phpnamespace App\Http\Controllers;use App\Http\Controllers\Controller;use BL\SwooleHttp\Database\SlowQuery;class TestController extends Controller&#123; public function test() &#123; $a = yield new SlowQuery('select * from users;'); response()-&gt;json($a); &#125;&#125; 就这样，实现了在同步编程风格的Lumen项目中使用上了Swoole的异步MySQL客户端。实现的思路，就像后置中间件，保持控制器代码的整洁，脏活累活放在中间件里执行。 效率提升假如用户请求执行一个数据库慢查询语句（可能耗时1秒，如select sleep(1);），单个PHP进程使用同步MySQL客户端处理1个这样的用户请求，至少需要1秒，处理10个，则至少需要10秒；而使用异步MySQL客户端，处理1个，可能需要1秒多，处理10个，可能也只是需要1秒。异步执行带来的效率提升，是不言而喻的。 不过，使用异步MySQL客户端是会消耗系统资源的，不能大量使用；而且非慢查询的查询语句，根本不需要使用异步MySQL客户端来执行，比如select * from users.id = 1;，id有主键索引，查询时间不会太长。 最后yield可以将整个程序的各个代码块的执行秩序交由程序员自行调度，确实可以实现很多意向不到的效果。像以上这种“后置执行”的思路，不仅仅是可以使用异步MySQL客户端，还可以使用异步Redis客户端，异步HTTP客户端，还有更多各种各样的应用。 下一篇文章介绍如何自定义后置异步协程。]]></content>
      <categories>
        <category>求索</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>php</tag>
        <tag>swoole</tag>
        <tag>lumen</tag>
        <tag>think</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用Swoole HTTP服务器运行Lumen项目的实现方法]]></title>
    <url>%2Fblog%2Fswoole-lumen-run-lumen-with-swoole.html</url>
    <content type="text"><![CDATA[LNMP虽是传统的Web应用架构组合，无奈NginX + PHP-FPM的搭配运行效率实在太低；而Swoole HTTP服务器具有NginX级别的性能，且本身嵌入在PHP中，完全可以替代NginX + PHP-FPM。于是一直在探索用Swoole HTTP服务器运行传统PHP应用的途径。这里主要介绍一下Swoole HTTP服务器运行Lumen项目的实现方法： Swoole HTTP服务器Swoole1.7.7增加了内置HTTP服务器的支持，使用了跟NginX一样的IO多路复用机制epoll，可以达到NginX级别的性能，并且只需几行代码即可写出一个异步非阻塞多进程的HTTP服务器（epoll属于同步非阻塞，这里说“异步非阻塞”主要是因为“多进程”，单个进程内部依然是同步非阻塞）。 开启一个Swoole HTTP服务器的面向对象编程代码样板大致如下（具体参考Swoole官方文档HttpServer）： 123456789101112131415161718192021222324252627282930313233343536&lt;?phpclass Service &#123; public $app; public $server; public function __construct($host, $port) &#123; $this-&gt;server = new \swoole_http_server($host, $port); &#125; public function start() &#123; // $this-&gt;server-&gt;on('start', array($this, 'onStart')); // $this-&gt;server-&gt;on('shutdown', array($this, 'onShutdown')); // $this-&gt;server-&gt;on('workerStop', array($this, 'onWorkerStop')); $this-&gt;server-&gt;on('workerStart', array($this, 'onWorkerStart')); $this-&gt;server-&gt;on('request', array($this, 'onRequest')); $this-&gt;server-&gt;start(); &#125; public function onWorkerStart($serv, $worker_id) &#123; // 应用初始化 $this-&gt;app = 1; &#125; public function onRequest(\swoole_http_request $request,\swoole_http_response $response) &#123; $app = $this-&gt;app; // 处理用户请求 $get = json_encode($request-&gt;get); // 响应用户请求 $response-&gt;end("App is &#123;$app&#125;. Get &#123;$get&#125;"); &#125;&#125;$s = new Service("127.0.0.1", 9080);$s-&gt;start(); 直接用php命令执行以上代码，浏览器访问http://127.0.0.1:9080，会得到： 1App is 1. Get null 浏览器访问http://127.0.0.1:9080/?user=guest，会得到： 1App is 1. Get &#123;&quot;user&quot;:&quot;guest&quot;&#125; 就是这么简单。 加载Lumen项目Lumen项目的入口文件是项目路径下的public/index.php，里面只有简单的两行代码： 123&lt;?php$app = require __DIR__.'/../bootstrap/app.php';$app-&gt;run(); 第一行代码就是加载整个Lumen框架代码，第二行代码则是处理请求，生成响应。 所以，在Swoole HTTP服务器中加载Lumen项目，也很简单，只需修改onWorkerStart方法： 12345&lt;?php public function onWorkerStart($serv, $worker_id) &#123; // 应用初始化 $this-&gt;app = require '/THE/FULL/PATH/TO/bootstrap/app.php'; &#125; 处理用户请求虽然可以加载Lumen框架，但是要怎样才能用Lumen框架来处理用户请求呢？ 由于Lumen框架的解耦程度非常高，我们可以很轻松地将swoole_http_request对象$request，转换成Lumen框架熟悉的Illuminate\Http\Request对象，这样Lumen框架就能处理用户请求了。这里实现一个parseRequest方法，接收swoole_http_request类参数，返回\Illuminate\Http\Request类结果： 12345678910111213141516171819202122232425&lt;?php protected function parseRequest(\swoole_http_request $request) &#123; $get = isset($request-&gt;get) ? $request-&gt;get : array(); $post = isset($request-&gt;post) ? $request-&gt;post : array(); $cookie = isset($request-&gt;cookie) ? $request-&gt;cookie : array(); $server = isset($request-&gt;server) ? $request-&gt;server : array(); $header = isset($request-&gt;header) ? $request-&gt;header : array(); $files = isset($request-&gt;files) ? $request-&gt;files : array(); $fastcgi = array(); $new_server = array(); foreach ($server as $key =&gt; $value) &#123; $new_server[strtoupper($key)] = $value; &#125; foreach ($header as $key =&gt; $value) &#123; $new_server['HTTP_' . strtoupper($key)] = $value; &#125; $content = $request-&gt;rawContent() ?: null; $http_request = new \Illuminate\Http\Request($get, $post, $fastcgi, $cookie, $files, $new_server, $content); return $http_request; &#125; 生成请求响应Lumen框架处理用户请求，十分方便，只需调用应用的dispatch方法即可。不过dispatch方法返回结果一般是Symfony\Component\HttpFoundation\Response对象，需要做一些转化才能交由swoole_http_response对象给用户输出响应。这里实现一个makeResponse方法： 12345678910111213141516171819202122232425262728&lt;?php protected function parseRequest(\swoole_http_response $request, \Symfony\Component\HttpFoundation\Response $http_response) &#123; // status $response-&gt;status($http_response-&gt;getStatusCode()); // headers foreach ($http_response-&gt;headers-&gt;allPreserveCase() as $name =&gt; $values) &#123; foreach ($values as $value) &#123; $response-&gt;header($name, $value); &#125; &#125; // cookies foreach ($http_response-&gt;headers-&gt;getCookies() as $cookie) &#123; $response-&gt;rawcookie( $cookie-&gt;getName(), $cookie-&gt;getValue(), $cookie-&gt;getExpiresTime(), $cookie-&gt;getPath(), $cookie-&gt;getDomain(), $cookie-&gt;isSecure(), $cookie-&gt;isHttpOnly() ); &#125; // content $content = $http_response-&gt;getContent(); // send content $response-&gt;end($content); &#125; 有了parseRequest方法和makeResponse方法，要实现以Swoole HTTP服务器运行Lumen项目来处理用户请求只要几行代码。onRequest方法这样修改： 123456789&lt;?php public function onRequest(\swoole_http_request $request,\swoole_http_response $response) &#123; $app = $this-&gt;app; // 处理用户请求 $http_request = $this-&gt;parseRequest($request); $http_response = $app-&gt;dispatch($http_request); // 响应用户请求 $this-&gt;makeResponse($response, $http_response); &#125; 最后就这样，不需要修改Lumen项目原本任何代码，就能让其运行在Swoole HTTP服务器上。当然，用户请求各种各样，有请求文件上传，有请求静态资源等等；响应类型也是各种各样，有Gzip压缩，有JSON格式，有设置Cookie等待。要实现一个健全的Swoole+Lumen网关服务，以上代码还须更多优化，具体可以参考Service.php。 按照以上思路，要实现以Swoole HTTP服务器运行Laravel项目也不难，不过，为了效率选择Swoole，自然会为了效率选择Lumen而不是Laravel。 下一篇文章介绍如何在Lumen中使用异步MySQL客户端，减少IO阻塞。]]></content>
      <categories>
        <category>求索</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>swoole</tag>
        <tag>lumen</tag>
        <tag>think</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建Docker Registry私有镜像仓库]]></title>
    <url>%2Fblog%2Fpractice-docker-registry.html</url>
    <content type="text"><![CDATA[Docker Store是Docker官方提供的公共的镜像仓库，但有时会需要在局部内共享镜像，那么可以利用Docker Registry工具搭建一个私有的镜像仓库。 直接运行官方registry镜像，即可开启镜像仓库服务： 1$ docker run -d -p 5000:5000 --restart=always --name registry registry 若要定制使用，还需更多配置。 Docker安装简单介绍一下Docker的安装： 123456$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -$ sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"$ sudo apt-get update$ sudo apt-get install -y docker-ce$ sudo apt-get install -y docker-compose$ sudo usermod -aG docker $&#123;USER&#125; Docker Compose安装Docker Compose的安装： 12$ sudo curl -L https://github.com/docker/compose/releases/download/1.18.0/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose$ sudo chmod +x /usr/local/bin/docker-compose Docker Compose编排进入工作目录，编辑docker-compose.yml： 123$ cd ~/workspace$ cd docker/registry$ vi docker-compose.yml 基于官方镜像registry制作，/etc/docker/registry是容器内配置信息路径，映射到本地./config；/var/lib/registry是容器内数据保存路径，映射到本地./data： 123456789version: "3"services: registry: image: registry ports: - "5000:5000" volumes: - "./config:/etc/docker/registry" - "./data:/var/lib/registry" Docker Registry配置设置HTTP认证： 123$ mkdir -p config/auth$ htpasswd -Bbn $USERNAME $PASSWORD &gt; ./config/auth/htpasswd # or$ docker run --rm --entrypoint htpasswd registry -Bbn $USERNAME $PASSWORD &gt; ./config/auth/htpasswd 配置Registry： 1$ vi config/config.yml config/config.yml： 12345678910111213141516171819202122version: 0.1log: fields: service: registrystorage: cache: blobdescriptor: inmemory filesystem: rootdirectory: /var/lib/registryauth: htpasswd: realm: basic-realm path: /etc/docker/registry/auth/htpasswdhttp: addr: :5000 headers: X-Content-Type-Options: [nosniff]health: storagedriver: enabled: true interval: 10s threshold: 3 运行与测试12345678$ docker-compose up -d$ docker login 127.0.0.1:5000$ docker pull ubuntu:16.04$ docker tag ubuntu:16.04 127.0.0.1/username/ubuntu:16.04$ docker push 127.0.0.1/username/ubuntu:16.04$ docker pull 127.0.0.1/username/ubuntu:16.04$ docker logout$ docker push 127.0.0.1/username/ubuntu:16.04 *HTTPS虽然Docker Registry默认监听端口是5000，但实际上服务是基于HTTP，可以通过HTTPS保障传输数据安全。Docker默认不允许非HTTPS连接下推送镜像（127.0.0.1本地网络地址例外），要取消这个限制须修改Docker配置——比如连接192.168.1.1:5000服务，在/etc/default/docker文件中添加DOCKER_OPTS=&quot;--insecure-registries=192.168.1.1:5000&quot;，然后重启Docker： 1$ sudo service docker restart 当然，最好还是给Docker Registry设置HTTPS：可以用NginX代理本地5000端口，然后在NginX上设置HTTPS；也可以在Docker Registry内部设置HTTPS，详细过程请阅读《私有仓库高级配置》。 参考 Deploy a registry server Configuring a registry]]></content>
      <categories>
        <category>实践</category>
      </categories>
      <tags>
        <tag>practice</tag>
        <tag>docker</tag>
        <tag>registry</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[源码安装GitLab（MySQL & HTTPS）]]></title>
    <url>%2Fblog%2Fpractice-gitlab-installation-from-source.html</url>
    <content type="text"><![CDATA[介绍一下在Ubuntu16.04系统下源码安装GitLab10.04且以MySQL作为数据库、SSL加密传输的步骤： 开始Dependencies安装依赖： 1$ sudo apt-get install -y build-essential zlib1g-dev libyaml-dev libssl-dev libgdbm-dev libre2-dev libreadline-dev libncurses5-dev libffi-dev curl openssh-server checkinstall libxml2-dev libxslt-dev libcurl4-openssl-dev libicu-dev logrotate rsync python-docutils pkg-config cmake 为GitLab创建一个系统用户git： 1$ sudo adduser --disabled-login --gecos 'GitLab' git $ sudo apt-get install -y postfix Git安装最新版Git： 123$ sudo add-apt-repository ppa:git-core/ppa$ sudo apt-get update$ sudo apt-get install git Ruby安装最新版Ruby： 1234$ sudo apt-add-repository ppa:brightbox/ruby-ng$ sudo apt-get update$ sudo apt-get install ruby$ sudo apt-get install ruby-dev 安装Bundler： 1$ sudo gem install bundler --no-ri --no-rdoc Go安装Go1.9.2： 1234$ curl --remote-name --progress https://dl.google.com/go/go1.9.2.linux-amd64.tar.gz$ sudo tar -C /usr/local -xzf go1.9.2.linux-amd64.tar.gz$ sudo ln -sf /usr/local/go/bin/&#123;go,godoc,gofmt&#125; /usr/local/bin/$ rm go1.9.2.linux-amd64.tar.gz Node安装NodeJS8.x： 12$ curl --location https://deb.nodesource.com/setup_8.x | sudo bash -$ sudo apt-get install -y nodejs 安装yarn： 1234$ curl --silent --show-error https://dl.yarnpkg.com/debian/pubkey.gpg | sudo apt-key add -echo "deb https://dl.yarnpkg.com/debian/ stable main" | sudo tee /etc/apt/sources.list.d/yarn.list$ sudo apt-get update$ sudo apt-get install yarn MySQL安装MySQL5.7，先从MySQL官网下载APT配置器(mysql-apt-config_0.8.9-1_all.deb)[https://dev.mysql.com/downloads/file/?id=474129]，然后： 123$ sudo dpkg -i mysql-apt-config_0.8.9-1_all.deb$ sudo apt-get update$ sudo apt-get install -y mysql-server mysql-client libmysqlclient-dev MySQL安全配置： 123$ $ mysql --version$ sudo mysql_secure_installation 创建GitLab用户和数据库： 1234567891011$ mysql -u root -pmysql&gt; CREATE USER &apos;git&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;$password&apos;;# Create the GitLab production databasemysql&gt; CREATE DATABASE IF NOT EXISTS `gitlabhq_production` DEFAULT CHARACTER SET `utf8` COLLATE `utf8_general_ci`;# Grant the GitLab user necessary permissions on the databasemysql&gt; GRANT SELECT, INSERT, UPDATE, DELETE, CREATE, CREATE TEMPORARY TABLES, DROP, INDEX, ALTER, LOCK TABLES, REFERENCES, TRIGGER ON `gitlabhq_production`.* TO &apos;git&apos;@&apos;localhost&apos;;# Quit the database sessionmysql&gt; \q 测试用户是否可以访问数据库： 1$ sudo -u git -H mysql -u git -p -D gitlabhq_production Redis安装Redis3.0.6： 1$ sudo apt-get install redis GitLab克隆GitLab源码克隆GitLab源码，并配置GitLab（修改域名等等）： 12345$ cd /home/git$ sudo -u git -H git clone https://gitlab.com/gitlab-org/gitlab-ce.git -b 10-4-stable gitlab$ cd /home/git/gitlab$ sudo -u git -H cp config/gitlab.yml.example config/gitlab.yml$ sudo -u git -H vi config/gitlab.yml 配置GitLab配置密钥文件： 12$ sudo -u git -H cp config/secrets.yml.example config/secrets.yml$ sudo -u git -H chmod 0600 config/secrets.yml 配置Unicorn（修改监听端口等等）： 12$ sudo -u git -H cp config/unicorn.rb.example config/unicorn.rb$ sudo -u git -H vi config/unicorn.rb 设置目录权限： 1234567891011121314$ sudo chown -R git log/$ sudo chown -R git tmp/$ sudo chmod -R u+rwX,go-w log/$ sudo chmod -R u+rwX tmp/$ sudo chmod -R u+rwX tmp/pids/$ sudo chmod -R u+rwX tmp/sockets/$ sudo -u git -H mkdir public/uploads/$ sudo chmod 0700 public/uploads$ sudo chmod -R u+rwX builds/$ sudo chmod -R u+rwX shared/artifacts/$ sudo chmod -R ug+rwX shared/pages/ 配置Rack Attack： 1$ sudo -u git -H cp config/initializers/rack_attack.rb.example config/initializers/rack_attack.rb 配置Resque（修改Redis链接等等）： 12$ sudo -u git -H cp config/resque.yml.example config/resque.yml$ sudo -u git -H vi config/resque.yml 配置Git用户： 123456789101112# Configure Git global settings for git user# 'autocrlf' is needed for the web editor$ sudo -u git -H git config --global core.autocrlf input# Disable 'git gc --auto' because GitLab already runs 'git gc' when needed$ sudo -u git -H git config --global gc.auto 0# Enable packfile bitmaps$ sudo -u git -H git config --global repack.writeBitmaps true# Enable push options$ sudo -u git -H git config --global receive.advertisePushOptions true 数据库设置配置MySQL（修改账户密码等等）： 123$ sudo -u git cp config/database.yml.mysql config/database.yml$ sudo -u git -H chmod o-rwx config/database.yml$ sudo -u git -H vi config/database.yml 安装Gems安装Gems： 123# If you use MySQL (note, the option says "without ... postgres")# If you want to use Kerberos for user authentication, then omit kerberos in the --without option$ sudo -u git -H bundle install --deployment --without development test postgres aws kerberos 安装GitLab Shell安装GitLab Shell，并配置（修改GitLab链接等等）： 123456# Run the installation task for gitlab-shell (replace `REDIS_URL` if needed):$ sudo -u git -H bundle exec rake gitlab:shell:install RAILS_ENV=production SKIP_STORAGE_VALIDATION=true# By default, the gitlab-shell config is generated from your main GitLab config.# You can review (and modify) the gitlab-shell config as follows:$ sudo -u git -H vi /home/git/gitlab-shell/config.yml 安装Gitlab Workhorse安装Gitlab Workhorse： 123$ sudo -u git -H bundle exec rake "gitlab:workhorse:install[/home/git/gitlab-workhorse]" RAILS_ENV=production$ sudo -u git -H bundle exec rake gitlab:setup RAILS_ENV=production GITLAB_ROOT_PASSWORD='$root_password' GITLAB_ROOT_EMAIL='$root_email' secrets.yml/home/git/gitlab/config/secrets.yml文件存储着各类数据加密的钥匙，应备份在一个安全的地方。 安装启动脚本安装在系统中启动GitLab服务的脚步： 123$ sudo cp lib/support/init.d/gitlab /etc/init.d/gitlab$ sudo cp lib/support/init.d/gitlab.default.example /etc/default/gitlab$ sudo update-rc.d gitlab defaults 21 安装Gitaly安装Gitaly，并配置： 1234$ sudo -u git -H bundle exec rake "gitlab:gitaly:install[/home/git/gitaly]" RAILS_ENV=production$ sudo chmod 0700 /home/git/gitlab/tmp/sockets/private$ sudo chown git /home/git/gitlab/tmp/sockets/private$ sudo -u git -H vi /home/git/gitaly/config.toml 设置Logrotate1$ sudo cp lib/support/logrotate/gitlab /etc/logrotate.d/gitlab 编译GetText PO1$ sudo -u git -H bundle exec rake gettext:compile RAILS_ENV=production MySQL字符串限制1$ sudo -u git -H bundle exec rake add_limits_mysql RAILS_ENV=production 编译前端资源12$ sudo -u git -H yarn install --production --pure-lockfile$ sudo -u git -H bundle exec rake gitlab:assets:compile RAILS_ENV=production NODE_ENV=production 启动GitLab服务启动或重启GitLab服务： 123$ sudo service gitlab start# or$ sudo /etc/init.d/gitlab restart 获取服务配置1$ sudo -u git -H bundle exec rake gitlab:env:info RAILS_ENV=production 检测服务状态1$ sudo -u git -H bundle exec rake gitlab:check RAILS_ENV=production Nginx安装最新版NginX： 123$ sudo add-apt-repository ppa:nginx/stable$ sudo apt-get update$ sudo apt-install nginx 配置NginX代理（修改域名等等）： 123$ sudo cp lib/support/nginx/gitlab /etc/nginx/sites-available/gitlab$ sudo ln -s /etc/nginx/sites-available/gitlab /etc/nginx/sites-enabled/gitlab$ sudo vi /etc/nginx/sites-available/gitlab 重启NginX服务： 1$ sudo service nginx start *Letsencrypt安装Letsencrypt： 1$ sudo apt-get install letsencrypt 申请密钥和证书： 1$ sudo letsencrypt sudo letsencrypt certonly --webroot -w /home/git/gitlab/public -d '$domainname' 配置NginX代理（修改域名、密钥位置、证书位置等等）： 123sudo cp lib/support/nginx/gitlab-ssl /etc/nginx/sites-available/gitlabsudo ln -s /etc/nginx/sites-available/gitlab /etc/nginx/sites-enabled/gitlabsudo vi /etc/nginx/sites-available/gitlab 重启NginX服务： 1$ sudo service nginx start 参考 Installation from source Database MySQL]]></content>
      <categories>
        <category>实践</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>practice</tag>
        <tag>gitlab</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Web页面中滚动穿透的解决方法]]></title>
    <url>%2Fblog%2Fhack-scroll-event-propagation.html</url>
    <content type="text"><![CDATA[最近做一个移动端的Web应用，因为是单页模式，所以少不了各种各样的弹出框，侧边栏，结果发现这些元素在滚动到边界时，滚动事件会传递给父元素，导致父元素开始滚动（在PC端也是一样存在这样的问题，而在移动端更为突出，有时即使不在边界也会导致父元素滚动，自身却不动）。 在网上搜寻一番后，找到很多关于这个问题的讨论，解决方法大致可以分为两类： （JS）监听元素el滚动事件event，当el.scrollTop或者el.scrollLeft到达边界值的时候，用event.preventDefault()方法取消浏览器默认操作和用event.preventDefault()方法停止事件往上传播； （CSS）在表层元素（弹出框，侧边栏等等）显示时，修改底层元素（一般是网页主体body）的样式，如position:fixed、overflow:hidden等等，使其不可滚动。 具体可以参考移动端滚动穿透问题，其中提到的“终极完美解决方案”便属上面的第二类。 疑虑虽说是“终极完美解决方案”，但其实我是不相信的，因为修改了元素定位方式，元素需要重绘，内容显示位置也会改变，即使记录内容位置后续恢复，画面也少不免抖动，所以怎么可能是“完美”呢？ 实践尽管有所疑虑，还是要实践一下。于是简单地写一个测试样例了： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Test&lt;/title&gt; &lt;style type="text/css"&gt; html, body &#123;width: 100%;&#125; body &#123;background-color: #9e9e9e; height: 9000px; margin: 0; padding: 0; z-index: 1;&#125; .main &#123;background-color: #00bcd4; height: 6000px; margin: 0;&#125; .nav &#123;background-color: #2196f3; width: 200px; position: fixed; top: 0; bottom: 0; right: 0; overflow: scroll; display: none; z-index: 9;&#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="main"&gt; &lt;div&gt; &lt;li&gt;testing testing&lt;/li&gt; &lt;li&gt;testing testing&lt;/li&gt; &lt;li&gt;testing testing&lt;/li&gt; &lt;li&gt;testing testing&lt;/li&gt; &lt;li&gt;testing testing&lt;/li&gt; &lt;!-- more and more --&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="nav"&gt; &lt;div style="height: 2000px"&gt; &lt;li&gt;testing testing&lt;/li&gt; &lt;li&gt;testing testing&lt;/li&gt; &lt;li&gt;testing testing&lt;/li&gt; &lt;li&gt;testing testing&lt;/li&gt; &lt;li&gt;testing testing&lt;/li&gt; &lt;!-- more and more --&gt; &lt;/div&gt; &lt;/div&gt; &lt;script type="text/javascript"&gt; var main = document.querySelector('.main'); var nav = document.querySelector('.nav'); var flag = 0; main.addEventListener('click', function () &#123; nav.style.display = 'block'; flag = document.body.scrollTop; document.body.style.position = 'fixed'; document.body.style.top = -flag + 'px'; &#125;); nav.addEventListener('click', function () &#123; document.body.style.position = 'static'; document.body.style.top = 'auto'; document.body.scrollTop = flag; nav.style.display = 'none'; &#125;); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 样例页面中，点击.main时，将.nav设为可见，且将body的定位设为fixed，向上偏移到body本来的滚动高度，这样.nav可以滚动而.main不能滚动，就不会出现滚动穿透的问题；再点击.nav，将.nav设为不可见，且将body的定位设为static，取消body的向上偏移并滚回本来的滚动高度。 有个问题样例页面在Safari浏览器中运行正常，在Chrome浏览器中却有问题，因为Safari浏览器认为body元素是滚动主体，而Chrome浏览器认为html元素才是滚动主体。document中获取body元素的键值是body，而获取html元素的键值是documentElement，所以要在Chrome浏览器中运行正常的脚步代码应该是： 123456789101112131415var main = document.querySelector('.main');var nav = document.querySelector('.nav');var flag = 0;main.addEventListener('click', function () &#123; nav.style.display = 'block'; flag = document.documentElement.scrollTop; document.documentElement.style.position = 'fixed'; document.documentElement.style.top = -flag + 'px';&#125;);nav.addEventListener('click', function () &#123; document.documentElement.style.position = 'static'; document.documentElement.style.top = 'auto'; document.documentElement.scrollTop = flag; nav.style.display = 'none';&#125;); 运行效果在.nav出现或消失时，认真看可以开到.main有些小抖动，但并不明显，在今天移动端硬件（CPU，内存）和软件（浏览器）优化足够的情况下，这个滚动穿透的解决方法确实是可以放心使用的。 最后开卷有疑，实践证明。]]></content>
      <categories>
        <category>方案</category>
      </categories>
      <tags>
        <tag>js</tag>
        <tag>html5</tag>
        <tag>css</tag>
        <tag>scheme</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Redis的任务调度设计方案]]></title>
    <url>%2Fblog%2Fscheme-redis-task-queue.html</url>
    <content type="text"><![CDATA[一个网关服务器就跟快餐店一样，总是希望客人来得快、去得也快，这样在相同时间内才可以服务更多的客人。如果快餐店的服务员在一个顾客点餐、等餐和结账时都全程跟陪的话，那么这个服务员大部分时间都是在空闲的等待。应该有专门的服务员负责点餐，专门的服务员负责送餐，专门的服务员负责结账，这样才能提高效率。同样道理，网关服务器中也需要分工明确。举个例子： 假设有一个申请发送重置密码邮件的网关接口，须知道发送一封邮件可能会花费上好几秒钟，如果网关服务器直接在线上给用户发送重置密码邮件，高并发的情况下就很容易造成网络拥挤。但实际上，网关服务器并非一定要等待邮件发送成功后才能响应用户，完全可以先告知用户邮件会发送的，而后再在线下把邮件发送出去（就像快餐店里点餐的服务员跟顾客说先去找位置坐，饭菜做好后会有人给他送过去）。 那么是谁来把邮件发送出去呢？ 任务队列为了网关接口能够尽快响应用户请求，无需即时知道结果的耗时操作可以交由任务队列机制来处理。任务队列机制中包含两种角色，一个是任务生产者，一个是任务消费者，而任务队列是两者之间的纽带： 生产者往队列里放入任务； 消费者从队列里取出任务。 任务队列的整体运行流程是：任务生产者把当前操作的关键信息（后续可以根据这些信息还原出当前操作）抽象出来，比如发送重置密码的邮件，我们只需要当前用户邮箱和用户名就可以了；任务生产者把任务放进队列，实际就是把任务的关键信息存储起来，这里会用到MySQL、Redis之类数据存储工具，常用的是Redis；而任务消费者就不断地从数据库中取出任务信息，逐一执行。 任务生产者的工作是任务分发，一般由线上的网关服务程序执行；任务消费者的工作是任务调度，一般由线下的程序执行，这样即使任务耗时再多，也不阻塞网关服务。 这里主要讨论的是任务调度（任务消费者）的程序设计。 简单直接假设我们用Redis列表List存储任务信息，列表键名是queues:default，任务发布就是往列表queues:default后追加数据： 123&lt;?php// PHP伪代码 Redis::rpush('queues:default', serialize($task)); 那么任务调度可以这样简单直接的实现： 1234567891011121314151617181920212223&lt;?php// PHP伪代码Class Worker &#123; public function schedule() &#123; while(1) &#123; $seri = Redis::lpop('queues:default'); if($seri) &#123; $task = unserialize($seri); $this-&gt;handle($task); continue; &#125; sleep(1); &#125; &#125; public function handle($task) &#123; // do something time-consuming &#125;&#125;$worker = new Worker;$worker-&gt;schedule(); 意外保险上面代码是直接从queues:default列表中移出第一个任务（lpop），因为handle($task)函数是一个耗时的操作，过程中若是遇到什么意外导致了整个程序退出，这个任务可能还没执行完成，可是任务信息已经完全丢失了。保险起见，对schedule()函数进行以下修改： 123456789101112131415&lt;?php... public function schedule() &#123; while(1) &#123; $seri = Redis::lindex('queues:default', 0); if($seri) &#123; $task = unserialize($seri); $this-&gt;handle($task); Redis::lpop('queues:default'); continue; &#125; sleep(1); &#125; &#125;... 即在任务完成后才将任务信息从列表中移除。 延时执行queues:default列表中的任务都是需要即时执行的，但是有些任务是需要间隔一段时间后或者在某个时间点上执行，那么可以引入一个有序集合，命名为queues:default:delayed，来存放这些任务。任务发布时需要指明执行的时间点$time： 123&lt;?php// PHP伪代码 Redis::zadd('queues:default:delayed', $time, serialize($task)); 任务调度时，如果queues:default列表已经空了，就从queues:default:delayed集合中取出到达执行时间的任务放入queues:default列表中： 1234567891011121314151617181920&lt;?php... public function schedule() &#123; while(1) &#123; $seri = Redis::lindex('queues:default', 0); if($seri) &#123; $task = unserialize($seri); $this-&gt;handle($task); Redis::lpop('queues:default'); continue; &#125; $seri_arr = Redis::zremrangebyscore('queues:default:delayed', 0, time()); if($seri_arr) &#123; Redis::rpush('queues:default', $seri_arr); continue; &#125; sleep(1); &#125; &#125;... 任务超时预估任务正常执行所需的最大时间值，若是任务执行超过了这个时间，可能是过程中遇到一些意外，如果任由它继续卡着，那么后面的任务就会无法被执行了。首先我们给任务设定一个时限属性timeout，然后在执行任务前先给进程本身设置一个闹钟信号，timeout后收到信号说明任务执行超时，需要退出当前进程（用supervisor守护进程时，进程自身退出，supervisor会自动再拉起）。注意：pcntl_alarm($timeout)会覆盖之前闹钟信号，而pcntl_alarm(0)会取消闹钟信号；任务超时后，当前任务放入queues:default:delayed集合中延时执行，以免再次阻塞队列。 12345678910111213141516171819202122232425262728293031323334&lt;?php... public function schedule() &#123; while(1) &#123; $seri = Redis::lindex('queues:default', 0); if($seri) &#123; $task = unserialize($seri); $this-&gt;timeoutHanle($task); $this-&gt;handle($task); Redis::lpop('queues:default'); continue; &#125; $seri_arr = Redis::zremrangebyscore('queues:default:delayed', 0, time()); if($seri_arr) &#123; Redis::rpush('queues:default', $seri_arr); continue; &#125; pcntl_alarm(0); sleep(1); &#125; &#125; public function timeoutHanle($task) &#123; $timeout = (int)$task-&gt;timeout; if ($timeout &gt; 0) &#123; pcntl_signal(SIGALRM, function () &#123; $seri = Redis::lpop('queues:default'); Redis::zadd('queues:default:delayed', time()+10), $seri); posix_kill(getmypid(), SIGKILL); &#125;); &#125; pcntl_alarm($timeout); &#125;... 并发执行上面代码，直观上没什么问题，但是在多进程并发执行的时候，有些任务可能会被重复执行，是因为没能及时将当前执行的任务从queues:default列表中移出，其他进程也可以读取到。为了避免重复执行的问题，我们需要引入一个有序集合SortedSet存放正在执行的任务，命名为queues:default:reserved。首先任务是从queues:default列表中直接移出，然后开始执行任务前先把任务放进queues:default:reserved集合中，任务完成了再从queues:default:reserved集合中移出。再结合任务超时，假设一个任务执行时间不可能超过60*60秒（可以按需调整），在queues:default列表为空的时候，queues:default:reserved集合中有任务已经存放超过了60*60秒，那么有可能是某些进程在执行任务是意外退出了，所以把这些任务放到queues:default:delayed集合中稍后执行。 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;?php... public function schedule() &#123; while(1) &#123; $seri = Redis::lpop('queues:default', 0); if($seri) &#123; Redis::zadd('queues:default:reserved', time()+10, $seri); $task = unserialize($seri); $this-&gt;timeoutHanle($task); $this-&gt;handle($task); Redis::zrem('queues:default:reserved', $seri); continue; &#125; $seri_arr = Redis::zremrangebyscore('queues:default:delayed', 0, time()); if($seri_arr) &#123; Redis::rpush('queues:default', $seri_arr); continue; &#125; $seri_arr = Redis::zremrangebyscore('queues:default:reserved', 0, time()-60*60); if($seri_arr) &#123; foreach($seri_arr as $seri) &#123; Redis::zadd('queues:default:delayed', time()+10, $seri); &#125; &#125; sleep(1); &#125; &#125; public function timeoutHanle($task) &#123; $timeout = (int)$task-&gt;timeout; if ($timeout &gt; 0) &#123; pcntl_signal(SIGALRM, function () use ($task) &#123; $seri = serialize($task); Redis::zrem('queues:default:reserved', $seri); Redis::zadd('queues:default:delayed', time()+10), $seri); posix_kill(getmypid(), SIGKILL); &#125;); &#125; pcntl_alarm($timeout); &#125;... 其他失败重试以上代码没有检验任务是否执行成功，应该有任务失败的处理机制：比如给任务设定一个最多重试次数属性retry_times，任务每执行一次retry_times，任务执行失败时，若是retry_times等于0，则将任务放入queues:default:failed列表中不再执行；否则放入放到queues:default:delayed集合中稍后执行。 休眠时间以上代码是进程忙时连续执行，闲时休眠一秒，可以按需调整优化。 事件监听若是需要在任务执行成功或失败时进行某些操作，可以给任务设定成功操作方法afterSucceeded()或失败操作方法afterFailed()，在相应的时候回调。 最后以上讲述了一个任务调度程序的逐步演变，设计方案很大程度上参考了Laravel Queue。用工具，知其然，知其所以然。]]></content>
      <categories>
        <category>方案</category>
      </categories>
      <tags>
        <tag>scheme</tag>
        <tag>php</tag>
        <tag>redis</tag>
        <tag>queue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态更新时效性缓存的一个解决方案]]></title>
    <url>%2Fblog%2Fscheme-refresh-timeliness-cache.html</url>
    <content type="text"><![CDATA[最近看到一篇文章一张优惠券引发的血案，文章作者实现一个获取优惠券列表的RPC接口，接口中的执行流程大概是先在缓存里获取优惠券列表，有则返回，没有则在数据库里获取，将结果写入缓存再返回。然而，在高并发请求的情况下，缓存优惠券列表中出现大量的重复数据。主要原因是： 程序只适应单例执行，没有考虑到多例并发的情况； 优惠券列表在缓存中存储结构是数组，而更新方法是直接追加； 直接在RPC接口中执行更新缓存。 文章作者最后通过反复判断来解决这个问题，但并不是一个好办法。其实这样需要动态更新缓存场景在开发中十分常见，所以在这里探讨一下相对完善的解决方案。 场景假设有一些时效性的数据（比如最新资讯、今日天气等等），这些数据在一定时间内不会改变，用户经常会获取，而直接从数据库中读取相对耗时，那么这些数据很应该放在缓存中。因为这些数据具有时效性，所以需要及时更新。用定时更新的话（一般都不会每个1秒更新一次），会有一些间隔；用动态更新的话（由用户触发更新），在用户请求获取这些数据的时候检查是否需要更新，是则更新并将新的数据返回给用户。 实现数据结构在缓存中存储数据时，应该选择合适的数据结构。 如果数据本身是有规则元素的集合，可以考虑采用数组结构存储，方便扩展； 如果数据本身是有规则元素的集合且元素各有主键，采用映射结构存储，可以单独对元素进行更新； 如果数据本身毫无规则，可以封装成JSON格式，采用字符串结构存储，更新时是全量更新。 另外，需要记录数据上一次更新的时间戳，即将这个时间戳也放进缓存，以此来判断数据是否有效，是否需要更新。当然，像Redis这类成熟的存储工具，可以直接利用其提供的TTL（time to live）来判断。 任务队列首先先实现一个更新数据的任务，这里更新是指全量更新，伪代码如下： 1234567891011public static function updateTheDataTask() &#123; $ttl = Redis::getTheDataTTL(); if($ttl &gt; NEED_TO_UPDATE) &#123; return false; &#125; $data = MySQL::getTheData(); Redis::setTheData($data); // update expires of the data at the same time sleep(2); Queue::cancelOtherUpdateTheDataTasks(); return true;&#125; 然后，运行一个执行数据更新任务的队列进程，注意须是单进程，而非多进程，这样可以确保在一个时间点上只执行一个数据更新任务。其中做TTL判断，是为了过滤没必要任务执行；更新成功后休眠两秒（其实可以休眠更久点），主要等待Redis同步，以免后续任务获取到旧的数据；取消掉后续的数据更新任务是因为根本没必要执行了。 任务队列可以用gearman实现，而队列进程可以用supervisord来守护，这里不展开介绍。 网关接口有了上面的任务队列，下面实现面向用户的获取数据接口就容易多了，伪代码如下： 12345678910public function theData() &#123; $data = Redis::getTheData(); if($data) &#123; return $data; &#125; else &#123; $data = MySQL::getTheData(); Queue::pushUpdateTheDataTask(); return $data; &#125;&#125; Queue::pushUpdateTheDataTask()只是将数据更新任务放入队列，由队列处理进程去执行。这里强调一下，数据更新虽然是由用户触发，但是绝不在面向用户的网关接口里执行，因为面向用户的网关接口可能会有大量并发请求，接口内不应该做耗时操作，所以才建立任务队列来执行数据更新，减轻网关压力。 效果这个方案在大量并发访问网关接口的情况下，缓存的数据可以保持准确，过程没有过多的无用操作，也节省了执行时间。 最后《一张优惠券引发的血案》图文并茂，文中作者对进程、代码块、分布式锁等方面进行了讨论，最后也提供解决方法，然而读者更需要的是独立思考——同样的问题，可以有不同的、更好的解决方法。 开卷有益，贵在思考。]]></content>
      <categories>
        <category>方案</category>
      </categories>
      <tags>
        <tag>scheme</tag>
        <tag>mysql</tag>
        <tag>php</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用Docker搭建RabbitMQ高可用集群]]></title>
    <url>%2Fblog%2Fpractice-rabbitmq-ha-docker-compose.html</url>
    <content type="text"><![CDATA[RabbitMQ是基于高级消息队列协议（AMQP）实现的开源消息代理软件，主要提供消息队列服务。这里介绍用Docker Compose搭建RabbitMQ高可用集群的过程。 RabbitMQ自身提供部署集群的功能，通过命令： 123$ rabbitmqctl -n rabbit@rmqha_node1 stop_app$ rabbitmqctl -n rabbit@rmqha_node1 join_cluster --ram rabbit@rmqha_node0$ rabbitmqctl -n rabbit@rmqha_node1 start_app 就可以很容易的将节点rabbit@rmqha_node1加入到集群rabbit@rmqha_node0中。--ram选项表示节点以内存存储方式运行，读写速度快，重启后内容会丢失；不加--ram选项，节点则以磁盘存储方式运行，虽然读写速度慢，但是内容一般可以持久保持。 在同一个RabbitMQ集群中，节点之间并没有主从之分，所有节点会同步相同的队列结构，队列内容（消息）则各自不同，不过消息会在节点间传递。这样的集群只是提高了应对大量并发请求的能力，整体可用性还是很低，因为某个节点宕机后，寄存在该节点上的消息不可用，而在其他节点上也没有这些消息的备份，若是该节点无法恢复，那么这些消息就丢失了。 为了解决这个问题，RabbitMQ提供镜像队列功能，通过命令： 1$ rabbitmqctl set_policy ha-all "^" '&#123;"ha-mode":"all"&#125;' 可以设置镜像队列，&quot;^&quot;表示匹配所有队列，即所有队列在各个节点上都会有备份。在集群中，只需要在一个节点上设置镜像队列，设置操作会同步到其他节点。 Docker Compose编排这个编排主要实现一个磁盘节点、两个内存节点的RabbitMQ集群和一个HAProxy代理。 目录结构12345678910L--rabbitmq-ha-docker //主目录 L--scripts //本地（Docker宿主）使用的一些脚本 L--rmqha_set_policy.sh //设置各个数据库账号和开启主从复制 L--volumes //各个容器的挂载数据卷 L--rmqha_proxy L--haproxy.cfg //HAProxy配置 L--rmqha_slave L--cluster_entrypoint.sh //入口文件 L--parameters.env //账号密码等环境参数 L--docker-compose.yml //编排配置 docker-compose.yml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101version: "2"services: master: image: rabbitmq:3.6-management container_name: rmqha_node0 restart: always mem_limit: 256m networks: net1: ipv4_address: 10.9.0.10 hostname: rmqha_node0 ports: - "55672:15672" - "56720:5672" env_file: - ./parameters.env environment: - CONTAINER_NAME=rmqha_node0 - RABBITMQ_HOSTNAME=rmqha_node0 - RABBITMQ_NODENAME=rabbit slave1: image: rabbitmq:3.6-management container_name: rmqha_node1 restart: always depends_on: - master mem_limit: 256m networks: net1: ipv4_address: 10.9.0.11 hostname: rmqha_node1 # ports: # - "56721:5672" volumes: - "./volumes/rmqha_slave/cluster_entrypoint.sh:/usr/local/bin/cluster_entrypoint.sh" entrypoint: "/usr/local/bin/cluster_entrypoint.sh" command: "rabbitmq-server" env_file: - ./parameters.env environment: - CONTAINER_NAME=rmqha_node1 - RABBITMQ_HOSTNAME=rmqha_node1 - RABBITMQ_NODENAME=rabbit - RMQHA_RAM_NODE=true slave2: image: rabbitmq:3.6-management container_name: rmqha_node2 restart: always depends_on: - master mem_limit: 256m networks: net1: ipv4_address: 10.9.0.12 hostname: rmqha_node2 # ports: # - "56722:5672" volumes: - "./volumes/rmqha_slave/cluster_entrypoint.sh:/usr/local/bin/cluster_entrypoint.sh" entrypoint: "/usr/local/bin/cluster_entrypoint.sh" command: "rabbitmq-server" env_file: - ./parameters.env environment: - CONTAINER_NAME=rmqha_node2 - RABBITMQ_HOSTNAME=rmqha_node2 - RABBITMQ_NODENAME=rabbit - RMQHA_RAM_NODE=true haproxy: image: haproxy:1.8 container_name: rmqha_proxy restart: always depends_on: - master - slave1 - slave2 mem_limit: 256m networks: net1: ipv4_address: 10.9.0.19 hostname: rmqha_proxy ports: - "56729:5672" - "51080:1080" volumes: - "./volumes/rmqha_proxy/haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro" - "./volumes/rmqha_proxy:/root/rmqha_proxy" environment: - CONTAINER_NAME=rmqha_proxynetworks: net1: driver: bridge ipam: config: - subnet: 10.9.0.0/16 gateway: 10.9.0.1 这里配置了四个容器服务，一个haproxy，负责代理各个RabbitMQ服务；三个rabbitmq，组成RabbitMQ集群。每个容器服务都指定了静态IP，即使服务重启也不会出现IP错乱问题，特殊的网络端口映射后面会介绍。 环境参数parameters.env 123456RMQHA_MASTER_NODE=rabbitRMQHA_MASTER_HOST=rmqha_node0RABBITMQ_DEFAULT_USER=guestRABBITMQ_DEFAULT_PASS=guestRABBITMQ_NODENAME=rabbitRABBITMQ_ERLANG_COOKIE=myerlangcookie RabbitMQ启动这里RabbitMQ容器是使用Docker官方镜像生成的，节点rmqha_node0可以直接启动；而节点rmqha_node1和rmqha_node2需要加入到rmqha_node0集群里，所以需要需改入口文件。volumes/rmqha_slave/cluster_entrypoint.sh 1234567891011121314151617#!/bin/bashset -eif [ -e "/root/is_not_first_time" ]; then exec "$@"else /usr/local/bin/docker-entrypoint.sh rabbitmq-server -detached # 先按官方入口文件启动且是后台运行 rabbitmqctl -n "$RABBITMQ_NODENAME@$RABBITMQ_HOSTNAME" stop_app # 停止应用 rabbitmqctl -n "$RABBITMQ_NODENAME@$RABBITMQ_HOSTNAME" join_cluster $&#123;RMQHA_RAM_NODE:+--ram&#125; "$RMQHA_MASTER_NODE@$RMQHA_MASTER_HOST" # 加入rmqha_node0集群 rabbitmqctl -n "$RABBITMQ_NODENAME@$RABBITMQ_HOSTNAME" start_app # 启动应用 rabbitmqctl stop # 停止所有服务 touch /root/is_not_first_time sleep 2s exec "$@"fi HAProxy配置这里HAProxy容器也是使用Docker官方镜像生成的，启动前需要先准备配置文件。volumes/rmqha_proxy/haproxy.cfg 12345678910111213141516171819202122232425262728293031323334353637383940global log 127.0.0.1 local0 maxconn 4096defaults log global mode tcp option tcplog retries 3 option redispatch maxconn 2000 timeout connect 5000 timeout client 50000 timeout server 50000# ssl for rabbitmq# frontend ssl_rabbitmq # bind *:5673 ssl crt /root/rmqha_proxy/rmqha.pem # mode tcp # default_backend rabbitmqlisten stats bind *:1080 # haproxy容器1080端口显示代理统计页面，映射到宿主51080端口 mode http stats enable stats hide-version stats realm Haproxy\ Statistics stats uri / stats auth admin:adminlisten rabbitmq bind *:5672 # haproxy容器5672端口代理多个rabbitmq服务，映射到宿主56729端口 mode tcp balance roundrobin timeout client 1h timeout server 1h option clitcpka # server rmqha_node0 rmqha_node0:5672 check inter 5s rise 2 fall 3 server rmqha_node1 rmqha_node1:5672 check inter 5s rise 2 fall 3 server rmqha_node2 rmqha_node2:5672 check inter 5s rise 2 fall 3 实际运行在主目录下执行docker-compose up -d构建并运行整个Docker服务。 镜像队列，在主目录下执行： 1$ sh ./scripts/rmqha_set_policy.sh 实际上是执行了： 1$ docker exec -it rmqha_node0 rabbitmqctl set_policy ha-all &apos;^&apos; &apos;&#123;&quot;ha-mode&quot;:&quot;all&quot;&#125;&apos; 即在rmqha_node0集群中将所有队列设置为镜像队列，这个命令只需执行一次，除非重新构建整个Docker服务。 测试用两个PHP脚本可以对RabbitMQ进行简单的测试，不过需要用到php-amqplib库。 1$ composer require php-amqplib/php-amqplib 发送消息脚本： 123456789101112131415161718&lt;?php// send.phprequire_once __DIR__ . '/vendor/autoload.php';use PhpAmqpLib\Connection\AMQPStreamConnection;use PhpAmqpLib\Message\AMQPMessage;$connection = new AMQPStreamConnection('127.0.0.1', 56729, 'guest', 'guest', '/'); // 连接rmqha_proxy$channel = $connection-&gt;channel();$channel-&gt;queue_declare('task_queue', false, true, false, false);$data = "Hello World!";$msg = new AMQPMessage($data, array('delivery_mode' =&gt; AMQPMessage::DELIVERY_MODE_PERSISTENT));$channel-&gt;basic_publish($msg, '', 'task_queue');echo " [x] Sent ", $data, "\n";$channel-&gt;close();$connection-&gt;close(); 接受消息脚本： 1234567891011121314151617181920212223&lt;?php// receive.phprequire_once __DIR__ . '/vendor/autoload.php';use PhpAmqpLib\Connection\AMQPStreamConnection;$connection = new AMQPStreamConnection('127.0.0.1', 56720, 'guest', 'guest', '/'); // 连接rmqha_node0$channel = $connection-&gt;channel();$channel-&gt;queue_declare('task_queue', false, true, false, false);echo ' [*] Waiting for messages. To exit press CTRL+C', "\n";$callback = function ($msg) &#123; echo " [x] Received ", $msg-&gt;body, "\n"; sleep(1); echo " [x] Done", "\n"; $msg-&gt;delivery_info['channel']-&gt;basic_ack($msg-&gt;delivery_info['delivery_tag']);&#125;;$channel-&gt;basic_qos(null, 1, null);$channel-&gt;basic_consume('task_queue', '', false, false, false, false, $callback);while (count($channel-&gt;callbacks)) &#123; $channel-&gt;wait();&#125;$channel-&gt;close();$connection-&gt;close(); SSL设置为了RabbitMQ服务在网络传输中不泄漏信息，可以给HAProxy设置SSL传输（比对各个RabbitMQ服务设置SSL传输的性能消耗要小），这里简单的介绍一下自签证书： 12345$ cd ./volumes/rmqha_proxy/$ openssl genrsa -out rmqha.key 1024 # 随机生成一个私钥$ openssl req -new -key rmqha.key -out rmqha.csr # 根据私钥生成证书签署请求$ openssl x509 -req -days 365 -in rmqha.csr -signkey rmqha.key -out rmqha.crt # 自己签署证书$ cat rmqha.crt rmqha.key|tee rmqha.pem # 将私钥和证书合并到一个文件中 注意：生成证书签署请求时，需要填写一些信息，Common Name (eg, fully qualified host name)应该写127.0.0.1。HAProxy配置中添加： 12345# ssl for rabbitmqfrontend ssl_rabbitmq bind *:5673 ssl crt /root/rmqha_proxy/rmqha.pem # haproxy容器5673端口代理rabbitmq服务，需要映射到宿主端口 mode tcp default_backend rabbitmq PHP中通过SSL连接HAProxy代理服务示例： 12345&lt;?phprequire_once __DIR__ . '/vendor/autoload.php';use PhpAmqpLib\Connection\AMQPSSLConnection;$connection = new AMQPSSLConnection('127.0.0.1', 56730, 'guest', 'guest', '/', ['cafile'=&gt;'./rmqha.crt']); // 假设SSL的监听端口是56730，rmqha.crt是上面生成的自签证书$channel = $connection-&gt;channel(); 最后建议 消息生产者可以通过HAProxy代理连接RabbitMQ服务，实现负载均衡； 消息处理者应该直接连接RabbitMQ服务主机，并且跟随RabbitMQ服务主机启动服务、停止服务。 扩展阅读 Rabbitmq高可用-镜像队列模式 Rabbitmq集群高可用测试]]></content>
      <categories>
        <category>实践</category>
      </categories>
      <tags>
        <tag>practice</tag>
        <tag>docker</tag>
        <tag>rabbitmq</tag>
        <tag>haproxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JS实现人脸换妆和页面截图]]></title>
    <url>%2Fblog%2Fpractice-js-face-makeup-and-html2canvas.html</url>
    <content type="text"><![CDATA[最近要做一个H5活动页面，大概功能是给图片人脸换妆，自然也少不了上传原始图片和导出最终图片等功能。如果图片加工（即人脸换妆）放在服务器处理，那么并发量高的时候，肯定产生大量阻塞。于是想把图片加工放在客户端处理，用HTML堆砌出图片的最终效果，但是怎样把HTML导出成图片呢？ 图片上传图片上传可以参考HTTP文件上传的一个后端完善方案（NginX），或者使用现有的云存储服务，如七牛等等。 五官定位人脸识别和五官定位可以利用OpenVC自行实现，或者使用成熟的云识别服务，如Face++等等。这里使用腾讯云的人脸识别服务。 人脸换妆假设有一张图片，识别结果如下： 图片来源：万象优图-腾讯云 根据五官定位点，在适当位置给人脸添上妆饰，比如小胡子： 源码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Demo&lt;/title&gt;&lt;/head&gt;&lt;body style="padding: 0; margin: 0;"&gt; &lt;div style="width: 100%; text-align: center;"&gt; &lt;div style="width: 336px; margin-left: auto; margin-right: auto; position: relative;" id="div1"&gt; &lt;img src="./face.png" style="width: 100%;" id="face" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;script type="text/javascript"&gt; var FACE = &#123; "session_id":"", "face_shape":[ &#123; "face_profile":[&#123;"x":49,"y":231&#125;,&#123;"x":59,"y":249&#125;,&#123;"x":71,"y":267&#125;,&#123;"x":84,"y":284&#125;,&#123;"x":100,"y":298&#125;,&#123;"x":118,"y":310&#125;,&#123;"x":138,"y":318&#125;,&#123;"x":158,"y":324&#125;,&#123;"x":178,"y":329&#125;,&#123;"x":198,"y":329&#125;,&#123;"x":217,"y":323&#125;,&#123;"x":232,"y":309&#125;,&#123;"x":239,"y":291&#125;,&#123;"x":244,"y":271&#125;,&#123;"x":249,"y":252&#125;,&#123;"x":252,"y":232&#125;,&#123;"x":253,"y":213&#125;,&#123;"x":251,"y":194&#125;,&#123;"x":247,"y":175&#125;,&#123;"x":240,"y":157&#125;,&#123;"x":232,"y":142&#125;], "left_eye":[&#123;"x":89,"y":209&#125;,&#123;"x":100,"y":210&#125;,&#123;"x":110,"y":207&#125;,&#123;"x":120,"y":202&#125;,&#123;"x":128,"y":196&#125;,&#123;"x":117,"y":190&#125;,&#123;"x":105,"y":191&#125;,&#123;"x":95,"y":198&#125;], "right_eye":[&#123;"x":209,"y":153&#125;,&#123;"x":204,"y":161&#125;,&#123;"x":196,"y":167&#125;,&#123;"x":186,"y":170&#125;,&#123;"x":176,"y":172&#125;,&#123;"x":179,"y":161&#125;,&#123;"x":187,"y":154&#125;,&#123;"x":198,"y":150&#125;], "left_eyebrow":[&#123;"x":58,"y":190&#125;,&#123;"x":72,"y":180&#125;,&#123;"x":89,"y":175&#125;,&#123;"x":106,"y":172&#125;,&#123;"x":122,"y":167&#125;,&#123;"x":105,"y":161&#125;,&#123;"x":86,"y":165&#125;,&#123;"x":68,"y":174&#125;], "right_eyebrow":[&#123;"x":214,"y":120&#125;,&#123;"x":200,"y":125&#125;,&#123;"x":187,"y":133&#125;,&#123;"x":175,"y":143&#125;,&#123;"x":162,"y":150&#125;,&#123;"x":169,"y":135&#125;,&#123;"x":182,"y":123&#125;,&#123;"x":198,"y":115&#125;], "mouth":[&#123;"x":149,"y":279&#125;,&#123;"x":165,"y":290&#125;,&#123;"x":184,"y":294&#125;,&#123;"x":202,"y":289&#125;,&#123;"x":215,"y":276&#125;,&#123;"x":219,"y":258&#125;,&#123;"x":219,"y":239&#125;,&#123;"x":208,"y":241&#125;,&#123;"x":196,"y":246&#125;,&#123;"x":189,"y":253&#125;,&#123;"x":178,"y":256&#125;,&#123;"x":163,"y":266&#125;,&#123;"x":165,"y":282&#125;,&#123;"x":181,"y":281&#125;,&#123;"x":197,"y":277&#125;,&#123;"x":207,"y":266&#125;,&#123;"x":214,"y":254&#125;,&#123;"x":209,"y":245&#125;,&#123;"x":200,"y":252&#125;,&#123;"x":191,"y":258&#125;,&#123;"x":177,"y":266&#125;,&#123;"x":163,"y":273&#125;], "nose":[&#123;"x":180,"y":231&#125;,&#123;"x":155,"y":187&#125;,&#123;"x":154,"y":201&#125;,&#123;"x":154,"y":216&#125;,&#123;"x":153,"y":230&#125;,&#123;"x":152,"y":247&#125;,&#123;"x":170,"y":248&#125;,&#123;"x":186,"y":245&#125;,&#123;"x":196,"y":235&#125;,&#123;"x":203,"y":219&#125;,&#123;"x":190,"y":211&#125;,&#123;"x":178,"y":203&#125;,&#123;"x":167,"y":195&#125;] &#125; ], "image_height":430, "image_width":336 &#125;; // 人脸识别结果 var BEARD = &#123; "src":"./beard.png", "image_height":222, "image_width":567 &#125;; // 胡子图片信息 function parseEyesData(leye, reye)&#123; var lx = ly = 0; var rx = ry = 0; for(var i in leye) &#123; lx += leye[i]['x']; ly += leye[i]['y']; &#125; lx = lx/leye.length; ly = ly/leye.length; for(var i in reye) &#123; rx += reye[i]['x']; ry += reye[i]['y']; &#125; rx = rx/leye.length; ry = ry/leye.length; return &#123; angle: Math.atan((ly-ry)/(lx-rx))/Math.PI*(180), span: Math.sqrt(Math.pow(lx-rx, 2)+Math.pow(ly-ry, 2)) &#125; &#125; // 根据眼睛数据，获取脸倾角和眼心距 var div1 = document.getElementById('div1'); var edata = parseEyesData(FACE['face_shape'][0]['left_eye'], FACE['face_shape'][0]['right_eye']); var beard = document.createElement('img'); var scale = div1.offsetWidth/FACE['image_width']; var point1 = FACE['face_shape'][0]['nose'][0]; // 鼻尖 var point2 = FACE['face_shape'][0]['nose'][7]; // 鼻低 var point3 = FACE['face_shape'][0]['mouth'][9]; //上唇上中点 var beardx = ((point1['x']+point2['x'])/2+point3['x'])/2*scale; // 大概算出人中X坐标 var beardy = ((point1['y']+point2['y'])/2+point3['y'])/2*scale; // 大概算出人中Y坐标 var beardw = edata['span']*scale; // 胡子长度取眼心距值 beard.width = beardw; beard.src = './beard.png'; beard.style.transform = 'rotate('+edata['angle']+'deg)'; beard.style.position = 'absolute'; beard.style.top = (beardy-beardw/2/(BEARD['image_width']/BEARD['image_height']))+'px'; beard.style.left = (beardx-beardw/2)+'px'; div1.appendChild(beard); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 最终效果： 这只是HTML，怎样保存成图片呢？ 导出图片把HTML保存成图片，在服务器上可以用PhantomJS实现，在浏览器上呢？其实也是可以实现的，首先将HTML（DOM结构）写入Canvas，Canvas再导出DataURL，最后DataURL赋予img标签的src属性，便得到最终图片，详情请阅读Drawing DOM objects into a canvas。 这里使用插件html2canvas来实现HTML写入Canvas功能，类似的插件还有rasterizeHTML.js等等。 源码： 12345678910111213141516171819202122232425262728293031323334353637&lt;script type="text/javascript" src="./html2canvas.min.js"&gt;&lt;/script&gt;&lt;script type="text/javascript"&gt; ... var can1 = document.createElement('canvas'); var img1 = document.createElement('img'); var ctxt = can1.getContext('2d'); var level = 2; can1.width = document.body.offsetWidth*level; can1.height = div1.offsetHeight*level; can1.style.width = can1.width + 'px'; can1.style.height = can1.height + 'px'; ctxt.scale(level, level); // 使用两倍图，保持清晰度 setTimeout(function () &#123; html2canvas(div1, &#123;canvas:can1&#125;).then(function(can1) &#123; var can2 = document.createElement('canvas'); var face = document.getElementById('face'); var ctxt = can1.getContext('2d'); var level = 2; can2.width = face.offsetWidth*level; can2.height = face.offsetHeight*level; can2.style.width = face.offsetWidth + 'px'; can2.style.height = face.offsetWidth + 'px'; ctxt.scale(level, level); can2.getContext('2d').drawImage(can1, div1.offsetLeft*level, 0, face.offsetWidth*level, face.offsetHeight*level, 0, 0, face.offsetWidth*level, face.offsetHeight*level ); // 使用can2是为了裁掉与人脸图片无关的边缘 var data = can2.toDataURL(); img1.src = data; document.body.appendChild(img1); // 把图片放入当前页面中 can2 = null; can1 = null; &#125;); &#125;, 2000); // 需要等待人脸图片加载完成再执行&lt;/script&gt; 在PC端可以用a标签下载图片，href属性值应该是canvas导出的DataURL： 1&lt;a href="DataURL" download="最终效果" id="a1"&gt;下载&lt;/a&gt; 在移动端则需要显示图片，并引导用户长按保存图片。 最后注意：如果最终图片未能写入canvas，可能是图片跨域问题，或者图片未加载完就开始写了。另外：可以分析图片人脸的表情、姿态、年纪、心情等属性，搭配更合适的妆饰，效果更佳；原始图片与妆饰图片可能会有色调、分辨率等不相配的问题，可以使用CSS3滤镜调整，使得最终画面更融洽。]]></content>
      <categories>
        <category>实践</category>
      </categories>
      <tags>
        <tag>js</tag>
        <tag>practice</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用Docker搭建MySQL MHA高可用集群]]></title>
    <url>%2Fblog%2Fpractice-mysql-mha-docker-compose.html</url>
    <content type="text"><![CDATA[MySQL MHA（Master High Availability）是目前相对成熟的一个MySQL高可用解决方案。这篇文章主要介绍用Docker Compose编排MySQL MHA高可用集群的实践过程。Docker Compose编排中使用了两个现有镜像，分别是breeze2/mha4mysql-manager和breeze2/mha4mysql-node，这两个镜像的相关信息可以查看《制作mha4mysql的Docker镜像》。本次实践源码上传在GitHub的breeze2/mysql-mha-docker。 Docker Compose编排这个编排主要实现一主一备一从的MySQL MHA高可用集群。 目录结构123456789101112131415L--mysql-mha-docker //主目录 L--scripts //本地（Docker宿主）使用的一些脚本 L--mha_check_repl.sh L--... L--services //需要build的服务（目前是空） L--volumes //各个容器的挂载数据卷 L--mha_manager L--mha_node0 L--mha_node1 L--mha_node2 L--mha_share //各个容器共享的目录 L--scripts //各个容器共用的一些脚本 L--sshkeys //各个容器的ssh public key L--parameters.env //账号密码等环境参数 L--docker-compose.yml //编排配置 docker-compose.yml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091version: "2"services: master: image: breeze2/mha4mysql-node:0.57 container_name: mha_node0 restart: always mem_limit: 256m networks: net1: ipv4_address: 10.5.0.10 ports: - "33060:3306" volumes: - "./volumes/mha_share/:/root/mha_share/" - "./volumes/mha_node0/lib/:/var/lib/mysql/" - "./volumes/mha_node0/conf/:/etc/mysql/conf.d/" env_file: - ./parameters.env environment: - CONTAINER_NAME=mha_node0 slave1: image: breeze2/mha4mysql-node:0.57 container_name: mha_node1 restart: always depends_on: - master mem_limit: 256m networks: net1: ipv4_address: 10.5.0.11 ports: - "33061:3306" volumes: - "./volumes/mha_share/:/root/mha_share/" - "./volumes/mha_node1/lib/:/var/lib/mysql/" - "./volumes/mha_node1/conf/:/etc/mysql/conf.d/" env_file: - ./parameters.env environment: - CONTAINER_NAME=mha_node1 slave2: image: breeze2/mha4mysql-node:0.57 container_name: mha_node2 depends_on: - master restart: always mem_limit: 256m networks: net1: ipv4_address: 10.5.0.12 ports: - "33062:3306" volumes: - "./volumes/mha_share/:/root/mha_share/" - "./volumes/mha_node2/lib/:/var/lib/mysql/" - "./volumes/mha_node2/conf/:/etc/mysql/conf.d/" env_file: - ./parameters.env environment: - CONTAINER_NAME=mha_node2 manager: image: breeze2/mha4mysql-manager:0.57 container_name: mha_manager depends_on: - master - slave1 - slave2 restart: always mem_limit: 256m networks: net1: ipv4_address: 10.5.0.9 volumes: - "./volumes/mha_share/:/root/mha_share/" - "./volumes/mha_manager/conf:/etc/mha" - "./volumes/mha_manager/work:/usr/local/mha" entrypoint: "tailf /dev/null" env_file: - ./parameters.env environment: - CONTAINER_NAME=mha_managernetworks: net1: driver: bridge ipam: config: - subnet: 10.5.0.0/16 gateway: 10.5.0.1 这里配置了四个容器服务，一个breeze2/mha4mysql-manager，负责管理各个数据库结点；三个breeze2/mha4mysql-node，其中一个是主库，一个是备用主库（兼作从库），还有一个是（纯）从库。每个容器服务都指定了静态IP，即使服务重启也不会出现IP错乱问题。 环境参数parameters.env 1234567ROOT_PASSWORD=123456MYSQL_ROOT_PASSWORD=123456MYSQL_DATABASE=testingMYSQL_User=testingMYSQL_PASSWORD=testingMHA_SHARE_SCRIPTS_PATH=/root/mha_share/scriptsMHA_SHARE_SSHKEYS_PATH=/root/mha_share/sshkeys 数据库配置这里简单的配置一下各个数据库数据复制备份相关的参数主库，mha_node0/conf/my.cnf 12345678910[mysqld]server-id=1log-bin=mysql-binbinlog-do-db=testingbinlog-ignore-db=mysqlreplicate-do-db=testingreplicate-ignore-db=mysqlauto_increment_increment=2auto_increment_offset=1expire_logs_days=7 备库，mha_node1/conf/my.cnf 12345678910[mysqld]server-id=2log-bin=mysql-binbinlog-do-db=testingbinlog-ignore-db=mysqlreplicate-do-db=testingreplicate-ignore-db=mysqlauto_increment_increment=2auto_increment_offset=2expire_logs_days=7 从库，mha_node2/conf/my.cnf 12345[mysqld]server-id=3replicate-do-db=testingreplicate-ignore-db=mysqlexpire_logs_days=7 MHA配置manager/conf/app1.conf 12345678910111213141516171819[server default]user=rootpassword=123456ssh_user=rootmanager_workdir=/usr/local/mharemote_workdir=/usr/local/mharepl_user=myslaverepl_password=myslave[server0]hostname=10.5.0.10[server1]hostname=10.5.0.11[server2]hostname=10.5.0.12 实际运行在主目录下执行docker-compose up -d构建并运行整个Docker服务。 SSH设置MHA要求各个主机能够相互SSH登录，所以整体服务首次启动成功后，在主目录下先执行一些命令： 12$ sh ./scripts/ssh_start.sh$ sh ./scripts/ssh_share.sh ssh_start.sh作用是在各个容器上开启SSH服务，ssh_share.sh作用是在容器内生成SSH公密钥，再把公钥共享到其他容器。常用命令调用的脚本在scripts和volumes/mha_share/scripts下，这些脚本都很简单，一看就明。若是整体服务重新启动，只需重新开启SSH服务即可： 1$ sh ./scripts/ssh_start.sh 在manager容器上检测SSH是否配置成功： 12$ docker exec -it mha_manager /bin/bashroot@mha_manager# masterha_check_ssh --conf=/etc/mha/app1.conf 若是成功，会显示 12Mon Oct 16 14:53:59 2017 - [debug] ok.Mon Oct 16 14:53:59 2017 - [info] All SSH connection tests passed successfully. 开启数据主从复制首先对主库、备考创建和授权复制账号，对备库、从库设置主库信息和开始复制，以下命令会完成这些操作： 1$ sh ./scripts/mysql_set_mbs.sh 可以在主库上的testing数据库里创建一张表，写入一些数据，看看备库、从库会不会同步。 在manager容器上检测REPL是否配置成功： 12$ docker exec -it mha_manager /bin/bashroot@mha_manager# masterha_check_repl --conf=/etc/mha/app1.conf 若是成功，会显示 123Mon Oct 16 15:01:35 2017 - [info] Got exit code 0 (Not master dead).MySQL Replication Health is OK. 开启MHA监控SSH和REPL检测没问题后，可以在manager容器上开启MHA监控： 12$ docker exec -it mha_manager /bin/bashroot@mha_manager# masterha_manager --conf=/etc/mha/app1.conf masterha_manager进程会一直监视主库状态是否可用，若是主库宕机，masterha_manager会将备库与从库的Relay Log进行比较，把最新的数据整合到备库，然后把备库提升为新主库，从库跟随复制新主库，最后masterha_manager进程会退出，不再监控。 我们可以在本地（Docker宿主）暂停主库（mha_node0容器）： 1$ docker pause mha_node0 然后，manager容器上masterha_manager确认主库失联后，开始切换主库，成功后会显示： 1234567891011121314151617----- Failover Report -----app1: MySQL Master failover 10.5.0.10(10.5.0.10:3306) to 10.5.0.11(10.5.0.11:3306) succeededMaster 10.5.0.10(10.5.0.10:3306) is down!Check MHA Manager logs at 3d2d8185510b for details.Started automated(non-interactive) failover.The latest slave 10.5.0.11(10.5.0.11:3306) has all relay logs for recovery.Selected 10.5.0.11(10.5.0.11:3306) as a new master.10.5.0.11(10.5.0.11:3306): OK: Applying all logs succeeded.10.5.0.12(10.5.0.12:3306): This host has the latest relay log events.Generating relay diff files from the latest slave succeeded.10.5.0.12(10.5.0.12:3306): OK: Applying all logs succeeded. Slave started, replicating from 10.5.0.11(10.5.0.11:3306)10.5.0.11(10.5.0.11:3306): Resetting slave info succeeded.Master failover to 10.5.0.11(10.5.0.11:3306) completed successfully. 可以到从库（mha_node2容器），查看复制状态，可以看到跟随主库是10.5.0.11，即新主库（原备库）： 1234567$ docker exec -it mha_manager /bin/bashroot@mha_manager# mysql -u root -p$MYSQL_ROOT_PASSWORDmysql&gt; show slave status;*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 10.5.0.11 Master_User: myslave 最后在数据库服务器集群中，使用MHA，可以在主库宕机后快速切换新主库，可是应用服务器并不知道主库已经被切换。所以，masterha_manager进程切换主库成功后应该通知应用服务器新的主库IP，或者使用虚拟IP静默过渡。若是应用与数据库通过中间件（比如ProxySQL）来连接的，那么只需在中间件上修改主库IP，对应用影响不大。 注意：因为本compose中MySQL服务与SSH服务没有同一启动（SSH服务是容器启动后才开启的），所以本compose只能当作线下模拟练习，未能在正式线上应用。比如其中某个结点容器重启，SSH服务并没有自动重启，进而整个MHA集群不可用。]]></content>
      <categories>
        <category>实践</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>practice</tag>
        <tag>docker</tag>
        <tag>mha4mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[制作mha4mysql的Docker镜像]]></title>
    <url>%2Fblog%2Fpractice-make-mha4mysql-docker-image.html</url>
    <content type="text"><![CDATA[本来想记录一下用Docker构建MySQL MHA集群的实践过程的，但是整个篇幅有点长，所以这里先来介绍一下怎样制作mha4mysql的Docker镜像。 mha4mysql是日本工程师Yoshinori Matsunobu开发的一款MySQL高可用软件。mha4mysql分为两部分，一是管理器部分mha4mysql-manager，二是结点部分mha4mysql-node。mha4mysql-node要运行在每台受管理的MySQL服务器上；而mha4mysql-manager所在服务器则不需要MySQL，但需要mha4mysql-node。因为mha4mysql-manager依赖mha4mysql-node，即安装mha4mysql-manager前必须先安装mha4mysql-node。 下面讲解一下，基于debian:jessie制作mha4mysql-manager的Docker镜像和基于mysql:5.7制作mha4mysql-node的Docker镜像。 mha4mysql-managermha4mysql-manager的Dockerfile: 123456789101112131415161718192021FROM debian:jessieCOPY ./mha4mysql-manager.tar.gz /tmp/COPY ./mha4mysql-node.tar.gz /tmp/RUN build_deps='ssh sshpass perl libdbi-perl libmodule-install-perl libdbd-mysql-perl libconfig-tiny-perl liblog-dispatch-perl libparallel-forkmanager-perl make' \ &amp;&amp; apt-get update \ &amp;&amp; apt-get -y --force-yes install $build_deps \ &amp;&amp; tar -zxf /tmp/mha4mysql-node.tar.gz -C /opt \ &amp;&amp; cd /opt/mha4mysql-node \ &amp;&amp; perl Makefile.PL \ &amp;&amp; make \ &amp;&amp; make install \ &amp;&amp; tar -zxf /tmp/mha4mysql-manager.tar.gz -C /opt \ &amp;&amp; cd /opt/mha4mysql-manager \ &amp;&amp; perl Makefile.PL \ &amp;&amp; make \ &amp;&amp; make install \ &amp;&amp; cd /opt \ &amp;&amp; rm -rf /opt/mha4mysql-* \ &amp;&amp; apt-get clean 注释： 基于debian:jessie镜像二次制作； 将mha4mysql-manager和mha4mysql-node的当前最新版本（v0.57）打包，复制到镜像内； build_deps是mha4mysql-manager和mha4mysql-node的安装依赖、运行依赖； 先拆包安装mha4mysql-node，安装命令：perl Makefile.PL &amp;&amp; make &amp;&amp; make install； 才能拆包安装mha4mysql-manager，安装命令：perl Makefile.PL &amp;&amp; make &amp;&amp; make install； 清理一些无用文件。 mha4mysql-nodemha4mysql-node的Dockerfile: 123456789101112131415FROM mysql:5.7COPY ./mha4mysql-node.tar.gz /tmp/RUN build_deps='ssh sshpass perl libdbi-perl libmodule-install-perl libdbd-mysql-perl make' \ &amp;&amp; apt-get update \ &amp;&amp; apt-get -y --force-yes install $build_deps \ &amp;&amp; tar -zxf /tmp/mha4mysql-node.tar.gz -C /opt \ &amp;&amp; cd /opt/mha4mysql-node \ &amp;&amp; perl Makefile.PL \ &amp;&amp; make \ &amp;&amp; make install \ &amp;&amp; cd /opt \ &amp;&amp; rm -rf /opt/mha4mysql-* \ &amp;&amp; apt-get clean 注释： 基于mysql:5.7镜像二次制作； 将mha4mysql-node的当前最新版本（v0.57）打包，复制到镜像内； build_deps是mha4mysql-node的安装依赖、运行依赖； 拆包安装mha4mysql-manager，安装命令：perl Makefile.PL &amp;&amp; make &amp;&amp; make install； 清理一些无用文件。 注意v0.57 bug目前mha4mysql-manager和mha4mysql-node的v0.57并不兼容，新版的libdbd-mysql-perl的调用语法，比如新版要求连接数据库格式是：my $dsn = &quot;DBI:mysql:;host=$opt{host};port=$opt{port}&quot;;而v0.57源码是：my $dsn = &quot;DBI:mysql:;host=[$opt{host}];port=$opt{port}&quot;;多了一对中括号会导致连接数据库失败。这里镜像中的mha4mysql-manager和mha4mysql-node的源码包是已经对上面问题进行修正的。 单容器多服务按照Docker的思想，是一个容器只做一件事，但是mha4mysql结点需要mysql服务和ssh服务，这里的临时解决办法是容器先运行mysql服务，之后执行docker exec -it $CONTAINER_NAME /bin/bash service ssh start。目前实现Dokcer单容器多服务的hack方法是利用supervisor，只做supervisor这一件事，而supervisor做多件事。如果后期真的需要使用supervisor，也可以基于本镜像进行二次制作。 最后mha4mysql-manager和mha4mysql-node的Dockerfile分别放在GitHubbreeze2/mha4mysql-manager-docker和breeze2/mha4mysql-node-docker上；镜像可以用docker命令直接拉取： 12$ docker pull breeze2/mha4mysql-manager:0.57$ docker pull breeze2/mha4mysql-node:0.57]]></content>
      <categories>
        <category>实践</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>practice</tag>
        <tag>docker</tag>
        <tag>mha4mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用Docker实现MySQL ProxySQL读写分离]]></title>
    <url>%2Fblog%2Fpractice-mysql-proxysql-docker-compose.html</url>
    <content type="text"><![CDATA[ProxySQL是一个高性能的MySQL中间件，能够代理数百台MySQL服务器，支持数十万的并发连接。ProxySQL代理MySQL并提供读写分离，查询重写和数据分片等功能。这篇文章主要介绍用Docker Compose编排用ProxySQL实现MySQL集群上读写分离的实践过程。Docker Compose编排中使用了一个现有镜像，就是breeze2/proxysql。本次实践源码上传在GitHub的breeze2/mysql-proxy-docker。 Docker Compose编排这个编排主要实现一主两从的一个MySQL集群和一个ProxySQL代理，ProxySQL代理MYSQL集群的数据请求并且进行读写分离。 目录结构1234567891011121314L--mysql-proxy-docker //主目录 L--scripts //本地（Docker宿主）使用的一些脚本 L--mysql_set_users_and_repls.sh //设置各个数据库账号和开启主从复制 L--... L--services //需要build的服务（目前是空） L--volumes //各个容器的挂载数据卷 L--mysql_node0 L--mysql_node1 L--mysql_node2 L--proxysql L--share //各个容器共享的目录 L--scripts //各个容器共用的一些脚本 L--parameters.env //账号密码等环境参数 L--docker-compose.yml //编排配置 docker-compose.yml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485version: "2"services: master: image: mysql:5.7 container_name: mysql_node0 restart: always mem_limit: 256m networks: net1: ipv4_address: 10.6.0.10 ports: - "3306" volumes: - "./volumes/share/:/root/share/" - "./volumes/mysql_node0/lib/:/var/lib/mysql/" - "./volumes/mysql_node0/conf/:/etc/mysql/conf.d/" env_file: - ./parameters.env slave1: image: mysql:5.7 container_name: mysql_node1 restart: always depends_on: - master mem_limit: 256m networks: net1: ipv4_address: 10.6.0.11 ports: - "3306" volumes: - "./volumes/share/:/root/share/" - "./volumes/mysql_node1/lib/:/var/lib/mysql/" - "./volumes/mysql_node1/conf/:/etc/mysql/conf.d/" env_file: - ./parameters.env slave2: image: mysql:5.7 container_name: mysql_node2 depends_on: - master restart: always mem_limit: 256m networks: net1: ipv4_address: 10.6.0.12 ports: - "3306" volumes: - "./volumes/share/:/root/share/" - "./volumes/mysql_node2/lib/:/var/lib/mysql/" - "./volumes/mysql_node2/conf/:/etc/mysql/conf.d/" env_file: - ./parameters.env proxy: image: breeze2/proxysql:1.4.3 container_name: proxysql depends_on: - master - slave1 - slave2 restart: always mem_limit: 256m networks: net1: ipv4_address: 10.6.0.9 ports: - "127.0.0.1:60320:6032" - "60330:6033" volumes: - "./volumes/proxysql/conf:/etc/proxysql" entrypoint: "proxysql -f -c /etc/proxysql/pr.cnf" env_file: - ./parameters.envnetworks: net1: driver: bridge ipam: config: - subnet: 10.6.0.0/16 gateway: 10.6.0.1 这里配置了四个容器服务，一个breeze2/proxysql，负责代理各个数据库；三个mysql，其中一个是主库，另外两个是从库。每个容器服务都指定了静态IP，即使服务重启也不会出现IP错乱问题。proxysql容器的6032是提供管理服务的端口，只对Docker宿主机本地IP开放，而6033是代理数据请求的端口，可以对Docker宿主机网络IP开放。 环境参数parameters.env 1234MYSQL_ROOT_PASSWORD=123456MYSQL_DATABASE=testingMYSQL_User=testingMYSQL_PASSWORD=testing 数据库配置这里简单的配置一下各个数据库数据复制备份相关的参数主库，mysql_node0/conf/my.cnf 12345678910[mysqld]server-id=1gtid-mode=onenforce-gtid-consistency=truelog-bin=mysql-binbinlog-do-db=testingbinlog-ignore-db=mysqlreplicate-do-db=testingreplicate-ignore-db=mysqlexpire_logs_days=7 从库，mysql_node1/conf/my.cnf 12345678910[mysqld]server-id=2gtid-mode=onenforce-gtid-consistency=truelog-bin=mysql-binbinlog-do-db=testingbinlog-ignore-db=mysqlreplicate-do-db=testingreplicate-ignore-db=mysqlexpire_logs_days=7 从库，mysql_node2/conf/my.cnf 12345678910[mysqld]server-id=3gtid-mode=onenforce-gtid-consistency=truelog-bin=mysql-binbinlog-do-db=testingbinlog-ignore-db=mysqlreplicate-do-db=testingreplicate-ignore-db=mysqlexpire_logs_days=7 ProxySQL配置proxysql/conf/pr.cnf 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990datadir=&quot;/tmp&quot;# 管理平台参数admin_variables =&#123; admin_credentials=&quot;admin2:admin2&quot; mysql_ifaces=&quot;0.0.0.0:6032&quot; refresh_interval=2000&#125;# mysql全局参数mysql_variables =&#123; threads=4 max_connections=2048 default_query_delay=0 default_query_timeout=36000000 have_compress=true poll_timeout=2000 # interfaces=&quot;0.0.0.0:6033;/tmp/proxysql.sock&quot; interfaces=&quot;0.0.0.0:6033&quot; default_schema=&quot;information_schema&quot; stacksize=1048576 server_version=&quot;5.5.30&quot; connect_timeout_server=3000 # make sure to configure monitor username and password # https://github.com/sysown/proxysql/wiki/Global-variables#mysql-monitor_username-mysql-monitor_password monitor_username=&quot;pr_muser&quot; monitor_password=&quot;pr_mpass&quot; monitor_history=600000 monitor_connect_interval=60000 monitor_ping_interval=10000 monitor_read_only_interval=1500 monitor_read_only_timeout=500 ping_interval_server_msec=120000 ping_timeout_server=500 commands_stats=true sessions_sort=true connect_retries_on_failure=10&#125;# mysql用户参数mysql_users = ( &#123; username = &quot;pr_auser&quot; password = &quot;pr_apass&quot; default_hostgroup = 0 &#125;)# mysql服务器参数，10.6.0.10是主库放在0组，其他是从库放在1组mysql_servers =( &#123; address = &quot;10.6.0.10&quot; port = 3306 weight = 1 hostgroup = 0 max_connections = 50 &#125;, &#123; address = &quot;10.6.0.11&quot; port = 3306 weight = 2 hostgroup = 1 max_connections = 100 &#125;, &#123; address = &quot;10.6.0.12&quot; port = 3306 weight = 2 hostgroup = 1 max_connections = 150 &#125;)# mysql请求规则，以下配置是读时加锁的请求发给0组，普通读取的请求发给1组，其他默认发给0组（上面的default_hostgroup）mysql_query_rules:( &#123; rule_id=1 active=1 match_pattern=&quot;^SELECT .* FOR UPDATE$&quot; destination_hostgroup=0 apply=1 &#125;, &#123; rule_id=2 active=1 match_pattern=&quot;^SELECT&quot; destination_hostgroup=1 apply=1 &#125;) 实际运行在主目录下执行docker-compose up -d构建并运行整个Docker服务。 开启主从复制在主目录下执行： 1$ sh ./scripts/mysql_set_users_and_repls.sh 实际上是调用了挂载在数据库容器里的一些脚本： 123volumes/share/scripts/msyql_grant_proxysql_users.sh #设置给proxysql用的账号，pr_auser和pr_muservolumes/share/scripts/msyql_grant_slave.sh #主库设置给从库用的账号volumes/share/scripts/msyql_grant_slave.sh #从库开始数据复制 脚本里的执行命令都很简单，一看就明。 开启ProxySQL代理构建整个服务的时候，proxysql会先挂载主目录下的./volumes/proxysql/conf/pr.cnf到容器内/etc/proxysql/pr.cnf，然后执行proxysql -f -c /etc/proxysql/pr.cnf，所以这里的ProxySQL是按照pr.cnf里面的配置开启MySQL代理服务的，请仔细阅读上面ProxySQL配置。若有需要在ProxySQL运行的过程中修改配置，可以登录ProxySQL的管理系统操作。 ProxySQL管理系统在Docker宿主机上登录ProxySQL管理系统（Docker宿主机需要装有MySQL Client）： 1$ mysql -u admin2 -padmin2 -h 127.0.0.1 -P60320 在ProxySQL管理系统上添加一个mysql_user（注意这个testing账号是各个数据库都已建立的，具体查看上面环境参数）： 1mysql&gt; INSERT INTO mysql_users(username, password, default_hostgroup) VALUES ('testing', 'testing', 2); 确认是否已添加： 12345678mysql&gt; SELECT * FROM mysql_users;+----------+----------+--------+---------+-------------------+----------------+---------------+------------------------+--------------+---------+----------+-----------------+| username | password | active | use_ssl | default_hostgroup | default_schema | schema_locked | transaction_persistent | fast_forward | backend | frontend | max_connections |+----------+----------+--------+---------+-------------------+----------------+---------------+------------------------+--------------+---------+----------+-----------------+| pr_auser | pr_apass | 1 | 0 | 0 | | 0 | 0 | 0 | 1 | 1 | 10000 || testing | testing | 1 | 0 | 2 | NULL | 0 | 1 | 0 | 1 | 1 | 10000 |+----------+----------+--------+---------+-------------------+----------------+---------------+------------------------+--------------+---------+----------+-----------------+2 rows in set (0.00 sec) 把当前修改（MEMORY层）加载到正在运行的ProxySQL（RUNTIME层）： 1mysql&gt; LOAD MYSQL USERS TO RUNTIME; 在Docker宿主机上确认ProxySQL是否已加载最新配置： 1234567$ mysql -u testing -ptesting -h 127.0.0.1 -P60330mysql: [Warning] Using a password on the command line interface can be insecure.Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 7Server version: 5.5.30 (ProxySQL Admin Module)... 若想ProxySQL重启后依然是当前配置，要把当前修改（MEMORY层）保存到ProxySQL的Sqlite数据库里（DISK层）： 1mysql&gt; SAVE MYSQL USERS TO DISK; ProxySQL配置系统分三层，分别是MEMORY层、RUNTIME层和DISK层。ProxySQL管理系统操作的是MEMORY层，当前ProxySQL运行的是RUNTIME层，保存在ProxySQL本地Sqlite数据库里的是DISK层，详情请阅读文档ProxySQL Configuration。 SysBench测试工具SysBench是一个脚本化、多线程的基准测试工具，经常用于评估测试各种不同系统参数下的数据库负载情况。SysBench的使用教程可以参考sysbench 0.5使用手册。这里使用SysBench-v1.0.9来对ProxySQL进行测试。 SysBench Test Prepare首先，做测试准备： 12345678$ sysbench /usr/local/Cellar/sysbench/1.0.9/share/sysbench/oltp_read_write.lua --threads=5 --max-requests=0 --time=36 --db-driver=mysql --mysql-user=pr_auser --mysql-password=&apos;pr_apass&apos; --mysql-port=60330 --mysql-host=127.0.0.1 --mysql-db=testing --report-interval=1 preparesysbench 1.0.9 (using bundled LuaJIT 2.1.0-beta2)Initializing worker threads...Creating table &apos;sbtest1&apos;...Inserting 10000 records into &apos;sbtest1&apos;Creating a secondary index on &apos;sbtest1&apos;... 注意，/usr/local/Cellar/sysbench/1.0.9/share/sysbench/oltp_read_write.lua文件可以在SysBench安装包里找到，执行命令后，会在主库testing数据库里生成一个sbtest1表并插入一些数据，在从库里一样可以看到testing数据库下有sbtest1表，说明主从复制已生效。 SysBench Test Run然后，开始读写测试： 123456789101112131415161718$ sysbench /usr/local/Cellar/sysbench/1.0.9/share/sysbench/oltp_read_write.lua --threads=5 --max-requests=0 --time=36 --db-driver=mysql --mysql-user=pr_auser --mysql-password=&apos;pr_apass&apos; --mysql-port=60330 --mysql-host=127.0.0.1 --mysql-db=testing --report-interval=1 runsysbench 1.0.9 (using bundled LuaJIT 2.1.0-beta2)Running the test with following options:Number of threads: 5Report intermediate results every 1 second(s)Initializing random number generator from current timeInitializing worker threads...Threads started![ 1s ] thds: 5 tps: 51.66 qps: 1087.83 (r/w/o: 769.92/209.62/108.29) lat (ms,95%): 144.97 err/s: 0.00 reconn/s: 0.00[ 2s ] thds: 5 tps: 61.26 qps: 1229.13 (r/w/o: 862.60/243.01/123.52) lat (ms,95%): 142.39 err/s: 1.00 reconn/s: 0.00[ 3s ] thds: 5 tps: 60.85 qps: 1237.04 (r/w/o: 867.92/247.41/121.71) lat (ms,95%): 121.08 err/s: 0.00 reconn/s: 0.00[ 4s ] thds: 5 tps: 67.07 qps: 1332.44 (r/w/o: 931.01/267.29/134.15) lat (ms,95%): 127.81 err/s: 0.00 reconn/s: 0.00... 查看结果登录ProxySQL管理系统，查看统计结果： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152$ mysql -u admin2 -padmin2 -h 127.0.0.1 -P60320mysql&gt; select * from stats_mysql_query_digest limit\G;*************************** 1. row *************************** hostgroup: 0 schemaname: testing username: pr_auser digest: 0xE365BEB555319B9Edigest_text: DELETE FROM sbtest1 WHERE id=? count_star: 2564 first_seen: 1508313300 last_seen: 1508313336 sum_time: 1923227 min_time: 149 max_time: 39773*************************** 2. row *************************** hostgroup: 0 schemaname: testing username: pr_auser digest: 0xFB239BC95A23CA36digest_text: UPDATE sbtest1 SET c=? WHERE id=? count_star: 2566 first_seen: 1508313300 last_seen: 1508313336 sum_time: 2016454 min_time: 158 max_time: 53514...*************************** 13. row *************************** hostgroup: 1 schemaname: testing username: pr_auser digest: 0xDBF868B2AA296BC5digest_text: SELECT SUM(k) FROM sbtest1 WHERE id BETWEEN ? AND ? count_star: 2570 first_seen: 1508313300 last_seen: 1508313336 sum_time: 7970660 min_time: 216 max_time: 56153*************************** 14. row *************************** hostgroup: 1 schemaname: testing username: pr_auser digest: 0xAC80A5EA0101522Edigest_text: SELECT c FROM sbtest1 WHERE id BETWEEN ? AND ? ORDER BY c count_star: 2570 first_seen: 1508313300 last_seen: 1508313336 sum_time: 10148202 min_time: 272 max_time: 5803214 rows in set (0.00 sec) 可以看到读操作都发送给了hostgroup=1组，写操作都发送给了hostgroup=0组，说明读写分离已生效，读写分离配置请仔细阅读上面ProxySQL配置mysql_query_rules部分。 此致到此，用Docker实现MySQL ProxySQL读写分离已完成。另外ProxySQL提供的查询重写功能，其实是利用mysql_query_rules配置，对接收到的查询语句进行正则替换，再传递给数据库服务器，详情请阅读文档ProxySQL Configuration中的“MySQL Query Rules”部分；而数据分片功能，在真实数据分片的基础上，再结合mysql_query_rules配置，重写query到正确的主机、数据库或表上，详细内容可以阅读MySQL Sharding with ProxySQL。]]></content>
      <categories>
        <category>实践</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>practice</tag>
        <tag>docker</tag>
        <tag>proxysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OAuth2.0的授权模式和应用]]></title>
    <url>%2Fblog%2Foauth2-types-and-applications-of-the-grants.html</url>
    <content type="text"><![CDATA[OAuth（开放授权）是一个标准协议，为用户资源的鉴权问题提供了一个安全、开放而又简易的解决方案。OAuth 2.0定义了四种鉴权模式： 授权码准许（Authorization Code Grant） 隐式准许（Implicit Grant） 客户端准许（Client Credentials Grant） 密码准许（Resource Owner Password Credentials Grant） 这里只介绍这四种鉴权模式，即获取有效令牌（Token）的四种过程，关于OAuth 2.0的其他更多内容建议阅读《理解OAuth 2.0》及 The OAuth 2.0 Authorization Framework。 首先，OAuth 2.0鉴权是用户（Resource Owner）、第三方应用（Third-Party Application）和鉴权服务器（Authorization Server）三方面共同实现的，单靠其中之一不能做到。第三方应用对于鉴权服务器，必须是可信的，彼此约定client_id和client_secret、redirect_uri等数据。所谓鉴权，实质是第三方应用向鉴权服务器申请有效令牌（Token），能获取到有效令牌，则说明鉴权通过，反之，不通过。 授权码准许实现流程授权码准许是基于链接跳转实现的鉴权模式，假设，第三方应用地址：https://client.com鉴权服务器地址：https://server.com那么大概的鉴权流程是： 第三方应用要申请令牌，首先带着client_id等参数跳转到鉴权服务器鉴权链接，用户在鉴权服务器上选择是否同意授权于第三方应用（用户要先在鉴权服务器上登录）； 用户同意授权，鉴权服务器带着授权码code跳转到原本指定的第三方应用回调链接； 第三方应用用授权码和client_secret等参数跟鉴权服务器换取令牌。 注释： 链接跳转a形式一般是（$开头表示是变量）： https://server.com/oauth/authorize?client_id=$CLIENT_ID&amp;response_type=code&amp;redirect_uri=$REDIRECT_URI&amp;scope=$SCOPE&amp;state=$STATE； 链接跳转b形式一般是： https://client.com/oauth/callback?code=$CODE&amp;state=$STATE； post请求c形式一般是：https://server.com/oauth/token，参数形式： 1234567&#123; grant_type: 'authorization_code', client_id: $CLIENT_ID, client_secret: $CLIENT_SECRET, redirect_uri: $REDIRECT_URI, code: $CODE&#125; post响应d形式一般是： 123456&#123; token_type: 'Bearer', expires_in: $EXPIRES_IN, access_token: $ACCESS_TOKEN, refresh_token: $REFRESH_TOKEN&#125; 应用场景授权码准许的鉴权模式是四种模式当中功能最完整、流程最严密的。使用授权码准许的第三方应用，一般是B/S结构（浏览器/服务器结构）。服务提供商（HTTP Service）给第三方应用颁发client_id和client_secret，第三方应用的后台服务器据此与服务提供商的鉴权服务器进行互动。比如，微信公众号开发中，获取当前访问用户信息就采用了授权码准许的鉴权模式，详见微信网页授权。 隐式准许实现流程隐式准许是授权码准许的简化，因为用户同意授权就可以直接发放令牌，不需要用授权码来再次请求令牌。大概的鉴权流程是： 第三方应用要申请令牌，首先带着client_id等参数跳转到鉴权服务器鉴权链接，用户在鉴权服务器上选择是否同意授权于第三方应用（用户要先在鉴权服务器上登录）； 用户同意授权，鉴权服务器带着令牌等参数跳转到原本指定的第三方应用回调链接。 注释： 链接跳转a形式一般是（$开头表示是变量）： https://server.com/oauth/authorize?client_id=$CLIENT_ID&amp;response_type=code&amp;redirect_uri=$REDIRECT_URI&amp;scope=$SCOPE&amp;state=$STATE； 链接跳转b形式一般是： https://client.com/oauth/callback#token_type=Bearer&amp;expires_in=$EXPIRES_IN&amp;access_token=$ACCESS_TOKEN&amp;state=$STATE； 这里解释一下，鉴权服务器跳回到第三方应用时，为什么传递参数是以hash形式而不是query形式？因为链接的hash数据只在本地浏览器里传播，再结合HTTPS，整个网络传输过程中，链接hash中令牌等信息并没有暴露；而链接的query数据是必然会暴露的。 应用场景隐式准许的鉴权模式最终是以链接的hash形式传递令牌，整个操作流程只能在浏览器环境中进行。但换个角度看，第三方应用不需要经过自身后台服务器，直接可以在浏览器中向鉴权服务器申请令牌，所以隐式准许的鉴权模式十分适用于当下流行的前后分离的单页应用或者基于Webview的手机应用。隐式准许的鉴权模式不检验client_secret，不过鉴权服务器只会回跳到可信的第三方应用回调链接（初始约定），所以鉴权过程依然是安全的，再说client_secret放在前端JavaScript代码中很容易暴露。 客户端准许实现流程客户端准许，注意这里说的客户端说的是第三方应用，但它不是一个PC程序或者手机应用，把它理解为一个机器或者服务器可能更为合理。整个鉴权流程只有第三方应用（Third-Party Application）和鉴权服务器（Authorization Server）参与，不需要用户（Resource Owner）同意授权。 大概的鉴权流程是： 第三方应用用client_id和client_secret等参数向鉴权服务器申请令牌； 鉴权服务器给第三方应用发放令牌。 注释： 申请令牌时，post请求链接一般是：https://server.com/oauth/token，参数形式： 123456&#123; grant_type: 'client_credentials', client_id: $CLIENT_ID, client_secret: $CLIENT_SECRET, scope: $SCOPE&#125; 发放令牌时，post响应一般是： 12345&#123; token_type: 'Bearer', expires_in: $EXPIRES_IN, access_token: $ACCESS_TOKEN&#125; 应用场景客户端准许不需要经过用户同意授权，相当于服务提供商直接将资源分享给可信的第三方应用，令牌只是第三方应用访问服务提供商接口所需的一个凭证。比如，微信公众号开发中，公众号服务器调用微信接口前需要经过客户端准许，详见获取access_token。 密码准许实现流程密码准许是用户将自己的用户名和密码交与第三方应用，第三方应用据此向鉴权服务器申请令牌。大概的鉴权流程是： 用户在第三方应用上输入自己的用户名和密码，第三方应用据此向鉴权服务器申请令牌； 鉴权服务器给第三方应用发放令牌。 注释： 申请令牌时，post请求链接一般是：https://server.com/oauth/token，参数形式： 12345678&#123; grant_type: 'password', client_id: $CLIENT_ID, client_secret: $CLIENT_SECRET, username: $USERNAME, password: $PASSWORD, scope: $SCOPE&#125; 发放令牌时，post响应一般是： 123456&#123; token_type: 'Bearer', expires_in: $EXPIRES_IN, access_token: $ACCESS_TOKEN, refresh_token: $REFRESH_TOKEN&#125; 应用场景密码准许的鉴权模式适用于没有浏览器环境、没有后台服务器的第三方应用，这种应用是一个纯客户端，比如PC程序或者手机应用（区别客户端准许）。鉴权服务器一般不会对第三方应用做密码准许，因为涉及到用户的密码，除非第三方应用十分可信。比如，Facebook原本是一个Web网站，后来要开发手机应用Facebook App，那么Facebook Web可以对Facebook App做密码准许，因为Facebook App是Facebook自家产品，不是真正意义上的第三方应用。即使第三方应用非常可信，第三方应用在功能设计上也不能存储用户输入的密码，万一被破解，用户的密码就会暴露。 最后最后总结一下： 授权码准许和隐式准许中用户同意授权的操作是首次必须，用户同意后下次默认直接同意（当然也可以设置有效期）； 授权码准许和密码准许会返回refresh_token，令牌过期时，第三方应用可以用refresh_token隐式刷新令牌； 客户端准许和隐式准许不会返回refresh_token，令牌过期时，要求第三方应用重新申请令牌，客户端准许模式重新申请令牌对用户无干扰，而隐式准许模式可以利用隐形iframe重新申请令牌来减少对用户的干扰； 对于B/S结构的Web应用，建议使用授权码准许的鉴权模式； 对于前后分离的Web单页应用，建议使用隐式准许的鉴权模式； 对于共享资源，与用户意愿无关的应用，建议使用客户端准许的鉴权模式； 对于自家PC或手机应用产品，建议使用密码准许的鉴权模式。]]></content>
      <categories>
        <category>知道</category>
      </categories>
      <tags>
        <tag>oauth2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单点登录的实现]]></title>
    <url>%2Fblog%2Fpractice-single-sign-on.html</url>
    <content type="text"><![CDATA[单点登录（Single Sign-On），是指一次登录，多站复用登录态。这里主要讲解一下基于共享session实现的单点登录。 对于大多数B/S结构（浏览器/服务器结构）的Web网站，用户登录态都是存储在session中的，而sessionID（session的唯一识别号）记录在前端的cookie中，只要同步各个网站的sessionID，各个网站便能共享同一个session，进而共用用户的登录态。需要共享session的情况主要有三种： 同域名下不同路径； 同父域名下不同子域名； 不同域名； 下面会根据这三种情况，借用Laravel和JQuery代码，逐一实现单点登录（共享session）。 同域名下不同路径假设一个网站下有两条路径： https://www.a.site/path1 https://www.a.site/path2 若想这两条路径同步sessionID，十分简单，比如用户在https://www.a.site/path1路径下登录后，将记录sessionID的cookie设置成根路径’/‘有效，这样网站https://www.a.site下的所有路径都能使用这个cookie。代码实现： 1234567&lt;?php // after login // raw php setcookie(session_name(), session_id(), time()+3600, '/'); // use laravel \Cookie::queue(config('session.cookie'), session()-&gt;getId(), 60, '/'); 同父域名下不同子域名假设有两个网站： https://www.a.site https://mob.a.site 若想这两个网站同步sessionID，其实也不难。首先，这两个网站可能不在同一个主机上，所以session不能直接保存到本地文件中，而是要保存到同一数据库中，且两个网站都能访问这个数据库。然后，用户在https://www.a.site网站下登录后，将记录sessionID的cookie设置成父域名.a.site有效，这样a.site域名下的所有网站都能使用这个cookie。代码实现： 1234567&lt;?php // after login // raw php setcookie(session_name(), session_id(), time()+3600, '/', '.a.site'); // use laravel \Cookie::queue(config('session.cookie'), session()-&gt;getId(), 60, '/', '.a.site'); 不同域名JSONP+链接query假设有两个网站： https://www.a.site https://www.b.site 若想这两个网站同步sessionID，就不是那么容易了。这里涉及了前端跨域通信问题。本来想着用JSONP+链接query来实现的——比如，用户在https://www.a.site网站下登录后，便在网页HTML中插入一个script标签，其src属性设为另一个网站的动态链接，sessionID放在链接query中，形如&lt;script type=&quot;text/javascript&quot; src=&quot;https://www.b.site/set-cookie?session_id=$SESSION_ID&quot;&gt;&lt;/script&gt;而https://www.b.site/set-cookie的处理脚本大概是 1234567&lt;?php // set cookie // raw php setcookie(session_name(), $_GET['session_id'], time()+3600); // use laravel \Cookie::queue(config('session.cookie'), request()-&gt;input('session_id'), 60); 但是，这样一来，在网络传输过程中，sessionID就会暴露了，整个网站就不安全了。为了保护用户的sessionID，两个网站之间前端跨域通信采用iframe+链接hash来实现。 iframe+链接hash（其实这里才是整篇文章的重点）首先，cookie取消HttpOnly限制。Laravel框架里，记录sessionID的cookie默认HttpOnly，因为后面需要在前端修改cookie，所以先取消HttpOnly： 123456&lt;?php// config/session.php return [ ... 'http_only' =&gt; false; ]; 当然，即使cookie是HttpOnly，也能被修改，不过需要在后端操作（步骤相对会繁琐），这里为了方便采用前端操作。然后，登录操作使用异步请求。异步请求登录成功后，可以在回调函数里同步其他网站的sessionID。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// login.js var sites = ['https://www.a.site', 'https://www.b.site']; var session_name = 'laravel_session'; var sync_num = 0; function afterLogin() &#123; window.location.href = '/home'; &#125; function afterSync() &#123; if(sync_num === sites.length) setTimeout(afterLogin, 800); &#125; function makeFrame(url) &#123; var $iframe = $('&lt;iframe style="display:none" class="sync-session-id"&gt;&lt;/iframe&gt;').appendTo('body'); $iframe.on('load', function () &#123; sync_num++; afterSync(); &#125;); $iframe.prop('src', url); &#125; function getCookie(name) &#123; var cookie_str = window.document.cookie; if (cookie_str.length&gt;0) &#123; var start = cookie_str.indexOf(name + '='); if (start!=-1) &#123; start = start + name.length + 1; var end=cookie_str.indexOf(';', start) if (end==-1) end=cookie_str.length; return unescape(cookie_str.substring(start, end)) &#125; &#125; return ''; &#125; ... $.post('/paht/to/login', &#123;username: username, password:password&#125;).done(function (rst) &#123; if(rst.code==0) &#123; // login successful var session_id = getCookie(session_name); // 获取登录成功后的sessionID $.each(sites, function(i, e) &#123; if(window.location.href.indexOf(e)==0) &#123; sync_num++; return true; &#125; makeFrame(e+'/set-cookie.html'+'#'+'name='+session_name+'&amp;value='+session_id); // 访问网站e的set-cookie.html来同步sessionID &#125;); &#125; &#125;); 每个网站都放置一个可访问的set-cookie.html(名字可以自取)，set-cookie.html里面的脚本会将链接的hash信息记录到自身网站的cookie里。 123456789101112131415161718192021222324252627282930313233&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;set cookie&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;script type="text/javascript"&gt; function setCookie(name, value, expires) &#123; var date = new Date(); date.setTime(date.getTime()+expires*1000); var cookie = name + '=' + escape(value) + ((expires==null)? '' : ';expires='+date.toGMTString()) + ';path=/'; window.document.cookie = cookie; &#125; var hash = window.location.hash; if(hash) &#123; var data_str = hash.substring(1); var data_arr = data_str.split('&amp;'); var data = &#123;&#125;; for(var i=0; i&lt;data_arr.length; i++) &#123; var str = data_arr[i]; var arr = str.split('='); if(arr[0]) data[arr[0]] = arr[1] ? arr[1]: ''; &#125; if(data.name &amp;&amp; data.value) &#123; setCookie(data.name, data.value, 3600); &#125; &#125; &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 这样用户在一个网站登录后，到另一个网站也能共享登录态。 继续优化更多的网站当有更多的网站时，如： https://www.a.site https://www.b.site https://www.c.site https://www.d.site https://www.e.site … 安装上面的代码，只需要在登录页面上把所有的网站地址添加到sites数组里即可： 123456// login.js var sites = ['https://www.a.site', 'https://www.b.site', 'https://www.c.site', 'https://www.d.site', 'https://www.e.site']; var session_name = 'laravel_session'; var sync_num = 0; ... 或者，取一个网站作为其他网站的登录代理。假设是代理网站是https://www.x.site，而其他网站都有一个唯一识别码site_id。比如https://www.a.site的唯一识别码site_id是1，则用户访问https://www.a.site的登录页面时，网站带着site_id跳转到https://www.x.site/login?site_id=1，而https://www.x.site/login的后端处理方法大概是： 1234567891011121314151617&lt;?php // pseudo code // use laravel public function getLogin(Request $request) &#123; // get request $site_id = $request-&gt;input('site-id'); $site_url = get_site_url_by_id($site_id); if($isLogined) &#123; // has logined in www.x.site return redirect($site_url)-&gt;withCookie(\Cookie::make(config('session.cookie'), session()-&gt;getId(), 60)); &#125; else &#123; return view('x.login'); &#125; &#125; public function postLogin(Request $request) &#123; // post request &amp; ajax only ... &#125; 若是用户未曾登录过，则在https://www.x.site/login?site_id=$SITE_ID页面上用异步请求登录，登录成功后前端脚本刷新当前页面，就会带着cookie跳回到site_id对应的网站；用户在https://www.x.site登录过，在登录其他网站的时候，直接跳到https://www.x.site/login?site_id=$SITE_ID，继而带着cookie跳回到site_id对应的网站。 后端设置cookie之前说过的后端跨域设置cookie，方法就是如上面代码那样带cookie跳转链接： 1234567&lt;?php // raw php setcookie(session_name(), session_id(), time()+3600, '/'); header('Location: '.$site_url); // use laravel redirect($site_url)-&gt;withCookie(\Cookie::make(config('session.cookie'), session()-&gt;getId(), 60)); 共享token如果网站使用token来维持用户登录态，而不是session，那么怎样实现单点登录呢？其实思路是一样的，利用iframe+链接hash，将token放到链接hash里面，传递给其他网站，其他网站接收后把token保存到LocalStorage就行了。 最后前后结合，可以实现很多hack操作。最后说说，QQ怎样将客户端里的用户登录态共享给浏览器：QQ客户端登录后会监听一些本地端口，各个QQ系网站通过JSONP方式访问这些端口，进而获取用户登录信息。]]></content>
      <categories>
        <category>实践</category>
      </categories>
      <tags>
        <tag>js</tag>
        <tag>php</tag>
        <tag>practice</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Swoole连接池在Laravel中的使用]]></title>
    <url>%2Fblog%2Fpractice-swoole-connection-pool-in-laravel.html</url>
    <content type="text"><![CDATA[Swoole php-cpphp-cp是Swoole组织开发的一个PHP扩展，可以本地代理MySQL、Redis连接，提供连接池，读写分离，负载均衡，慢查询日志，大数据块日志等功能。相比原生PHP的数据库连接，php-cp连接池可以缓存连接，免去一些重复新建、回收数据库连接带来的时间消耗和IO消耗；并且php-cp连接定时ping数据库，使得连接不会太久没活动而被回收；在连接数超过限额时，php-cp提供了排队机制，而不是直接拒绝，所以php-cp是值得高并发的PHP项目引入使用的。php-cp提供了代替PDO的类：pdoProxy，所以在主流PHP框架中引入php-cp是十分简便的。在php-cp的README中，提供了Yii、CI和ThinkPHP等框架的集成样例，但是少了Laravel，所以这里介绍一下在Laravel项目中怎样集成php-cp。 安装php-cp扩展首先，下载php-cp源码，编译安装： 1234567$ cd tmp $ git clone https://github.com/swoole/php-cp.git$ cd php-cp$ phpize$ ./configure$ make$ sudo make install 编译成功后，将extension=connect_pool.so添加到php-cli和php-fpm的php.ini配置文件中，这样PHP启动的时候就会加载connect_pool扩展。 启动pool-serverphp-cp提供了现成的连接池脚本，只需要按照以下配置，便能启动pool-server连接池服务： 123456789$ sudo cp ./config.ini.example /etc/pool.ini #根据需求修改配置内容$ sudo mkdir -m 755 /var/log/php-connection-pool #创建日志目录 目录文件夹不存在或没权限会导致日志写不起$ chmod +x ./pool_server #x权限git已经设置 为稳妥再设置一次 pool_server为php脚本 可自行修改$ [ -f /bin/env ] || sudo ln -s /usr/bin/env /bin/env #deb系的系统(如debian、ubuntu)env的路径为/usr/bin/env做软链接兼容处理$ sudo cp ./pool_server /usr/local/bin/pool_server$ sudo pool_server start #启动服务 如果配置文件的daemonize开启则后台运行 否则为前台运行 Ctrl+c结束服务$ sudo pool_server stop #停止服务$ sudo pool_server restart #重启服务$ sudo pool_server status #查看服务状态 /etc/pool.ini是pool_server脚本指定的配置路径，大家可以根据自己的需求，调整/etc/pool.ini里面的配置参数。比如，PDO数据源，Laravel的连接格式一般是： 1[&apos;mysql:host=127.0.0.1;port=3306;dbname=forge&apos;] 若是请求的连接在配置中找不到对应的数据源，pool_server会自动新建一个数据源，新的数据源信息可以通过sudo pool_server status查看。 Laravel集成Laravel集成php-cp的代码我已经上传到github，laravel-swoole-cp，主要是三个文件： laravel/framework/src/Illuminate/Database/MySqlSwooleProxyConnection.php laravel/framework/src/Illuminate/Database/Connectors/MySqlSwooleProxyConnector.php laravel/framework/src/Illuminate/Database/Connectors/ConnectionFactory.php 只要将这三个文件放到Laravel项目的vendor文件夹下便可。MySqlSwooleProxyConnection.php和MySqlSwooleProxyConnector.php是模仿Laravel框架自有的MySqlConnection.php和MySqlConnector.php新增编写的；而ConnectionFactory.php则是在Laravel框架原有的基础上修改的，主要是调用MySqlSwooleProxyConnection和MySqlSwooleProxyConnector这两个新增类。 ConnectionFactory.php修改的地方： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&lt;?phpnamespace Illuminate\Database\Connectors;use Illuminate\Database\MySqlSwooleProxyConnection;...class ConnectionFactory&#123; ... public function createConnector(array $config) &#123; if (! isset($config['driver'])) &#123; throw new InvalidArgumentException('A driver must be specified.'); &#125; if ($this-&gt;container-&gt;bound($key = "db.connector.&#123;$config['driver']&#125;")) &#123; return $this-&gt;container-&gt;make($key); &#125; switch ($config['driver']) &#123; case 'mysql-cp': return new MySqlSwooleProxyConnector; case 'mysql': return new MySqlConnector; case 'pgsql': return new PostgresConnector; case 'sqlite': return new SQLiteConnector; case 'sqlsrv': return new SqlServerConnector; &#125; throw new InvalidArgumentException("Unsupported driver [&#123;$config['driver']&#125;]"); &#125; protected function createConnection($driver, $connection, $database, $prefix = '', array $config = []) &#123; if ($resolver = Connection::getResolver($driver)) &#123; return $resolver($connection, $database, $prefix, $config); &#125; switch ($driver) &#123; case 'mysql-cp': return new MySqlSwooleProxyConnection($connection, $database, $prefix, $config); case 'mysql': return new MySqlConnection($connection, $database, $prefix, $config); case 'pgsql': return new PostgresConnection($connection, $database, $prefix, $config); case 'sqlite': return new SQLiteConnection($connection, $database, $prefix, $config); case 'sqlsrv': return new SqlServerConnection($connection, $database, $prefix, $config); &#125; throw new InvalidArgumentException("Unsupported driver [$driver]"); &#125;&#125; 注意，这里将php-cp的数据库连接驱动命名为mysql-cp，所以在Laravel项目的数据库配置config/database.php里应该这样配置php-cp的连接驱动： 12345678910111213141516171819202122232425&lt;?php// config/database.phpreturn [ 'default' =&gt; env('DB_CONNECTION', 'mysql-cp'), 'connections' =&gt; [ 'mysql-cp' =&gt; [ 'driver' =&gt; 'mysql-cp', 'host' =&gt; env('DB_HOST', '127.0.0.1'), 'port' =&gt; env('DB_PORT', '3306'), 'database' =&gt; env('DB_DATABASE', 'forge'), 'username' =&gt; env('DB_USERNAME', 'forge'), 'password' =&gt; env('DB_PASSWORD', ''), 'unix_socket' =&gt; env('DB_SOCKET', ''), 'charset' =&gt; 'utf8mb4', 'collation' =&gt; 'utf8mb4_unicode_ci', 'prefix' =&gt; '', 'strict' =&gt; true, 'engine' =&gt; null, ], ... ],] 问题来了一切准备就绪，执行一句DB::table(&#39;users&#39;)-&gt;find();，却报错了（我好像明白了为什么没人提供php-cp的Laravel连接驱动）： 解决办法经过排查，发现当数据获取模式设为PDO::FETCH_OBJ，pool_server的worker就会退出，其他获取模式就运行正常，那么应该是变量序列化传输的问题。原来php-cpV1.5.0版本（目前最新版）针对PHP7环境，使用自家的swoole_serialize序列化方法，而我的系统正好装的是PHP7，于是想：用相对主流的序列化方法msgpack-php替换swoole_serialize的话可能会解决这个问题。 替换后，重新编译安装php-cp，果然问题解决了。替换后的php-cp源码我已经上传到github，breeze2/php-cp，若有需要可以下载安装。 最后php-cp主要作用是应对高并发，假设MySQL数据库的最大连接数max_connections是100，当请求连接超过100的时候，若是PHP直接访问数据库，MySQL会直接拒绝多出来的连接；而通过php-cp访问数据库，php-cp有排队机制应对多出来的连接，php-cp的连接池可以长驻内存，也免去了大量的数据库连接线程新建、回收带来的消耗。综合来说，一般并发量不高的网站也用不上php-cp；而对于大型高并发的网站，使用数据库中间件更为合理，因为php-cp是本地代理，有些限制了单机效能。只是看到php-cp没有相应的Laravel连接驱动，强迫症发作，写了一个而已。]]></content>
      <categories>
        <category>实践</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>practice</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自动化工具Nightmare的一次实践]]></title>
    <url>%2Fblog%2Fpractice-nightmare-weiyun-operation.html</url>
    <content type="text"><![CDATA[事情是这样的，一个线上的参赛活动网站要收集参赛选手提交的微云分享链接，但是普通微云账号的分享链接只有7天期效。那该怎么办呢？只好把所有选手的微云分享链接转存到一个高级微云账号上，再由高级微云账号分享出来，以此增长分享时间。如果靠人工操作，那工作量太大，也难免会出错，所以写了一个自动化脚本来执行这个工作。（后来微云取消了分享期效限制，这个脚本没有正式用上😊） NightmareNightmare是一个高级的浏览器自动化工具库，出自Segment。它提供了一些模拟用户操作（比如click、input和goto等等）的API，主要用于UI测试和网页爬虫。Nightmare内置了Electron，一个类似PhantomJS的浏览器（或者说webview吧），但是比PhantomJS更快，更现代化。 引入Nightmare十分简单，初始化一个NodeJS项目后，执行yarn add nightmare或者npm install nightmare即可。 下面介绍收录微云分享链接以及再分享的具体实现。 具体实现整个流程大概是在自己的云盘上新建一个文件夹，然后将别人的分享链接存到这个文件夹里，多个链接依此循环；再把这个文件夹里面的内容分享出去，记录自己的分享链接，多个文件夹依此循环。为了避免文件夹重名，每条分享链接配备一个唯一id。 最终效果： 实现起来并不难，只要研究页面的DOM结构，然后安排好各个操作流程，再用Nightmare提供的接口实现这些操作就行了。 主要问题实现过程中主要碰到两个问题，一个是跨域iframe通讯问题，另一个是获取Electron内部js变量问题。 跨域iframe由于Electron浏览器的同源安全策略，主页面不能操作跨域iframe里的元素，但是云盘登录的时候需要操作qq.com域iframe里面的登录按钮。解决办法是，引用nightmare-iframe-manager扩展，禁用Electron安全模式： 1234567891011// yarn add nightmare// yarn add nightmare-iframe-managervar Nightmare = require('nightmare')require('nightmare-iframe-manager')(Nightmare)var nightmare = Nightmare(&#123; show: true, dock: true, webPreferences: &#123; webSecurity:false &#125;&#125;) 获取Electron内部js变量在Electron内部运行js代码时，有时需要取出一些变量值做记录，比如，取出自己的云盘分享链接。天真的我以为设一个全局变量，既能在自己的脚本里使用，也能在Electron内部使用，结果是根本就不起效。最后解决办法是引入vo，再结合ES6的新特性yield，获取Electron内部变量值： 123456789101112131415161718192021222324// yarn add nightmare// yarn add vovar vo = require('vo')var Nightmare = require('nightmare')var run = function* () &#123; var nightmare = Nightmare(&#123; show: true, dock: true, webPreferences: &#123; webSecurity:false &#125; &#125;) nightmare.goto('https://xxxxx') var link = yield nightmare.evaluate(function () &#123; var el = window.document.querySelector('#_disk_share_pop_container') return el.querySelector('span a.link').href &#125;)&#125;vo(run)(function(err, result) &#123; console.log(err, result) // console.log(JSON.stringify(result))&#125;) vo是一个能完全控制js执行流的工具库，而yield能“暂停”执行流，取出想要的某个变量值，再继续往下执行。JS的东西日新月异，没看一段时间就完全跟不上了😢。 最后其实，研究网盘页面的DOM结构，再设计有效的执行流程，花费时间不少；不过能替代大量重复性的人工操作，也是值得的。]]></content>
      <categories>
        <category>实践</category>
      </categories>
      <tags>
        <tag>js</tag>
        <tag>practice</tag>
        <tag>nightmare</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于LNMP的优化]]></title>
    <url>%2Fblog%2Fthink-about-the-optimization-of-lnmp.html</url>
    <content type="text"><![CDATA[线上有一个用LNMP构架的网站，有一天看到它出现了“502 Bad Gateway”错误，于是就开始思考优化问题了。首先，明确一下HTTP各个状态码的含义： 1XX 临时消息 2XX 返回成功 3XX 重新定向 4XX 客户端错误 5XX 服务端错误 基于LNMP的网站上，当HTTP请求返回的状态码是5XX的时候，说明是服务端出了问题；但问题不一定是出在NginX，因为NginX本身十分轻量，不做太多的复杂逻辑处理，所以很少会出错；除了静态资源的请求，其他大部分请求NginX都会转给PHP-FPM来处理，所以一般问题是更多地出在PHP。比如，开篇说那个网站出现的502错误，查看NginX日志发现大量的connect() to unix:/PATH/TO/PHP-FPM-SOCK failed (11: Resource temporarily unavailable)，其实原因是系统最大连接数过小。 Linux的内核优化按照《高性能Linux服务器构建实战：运维监控、性能调优与集群应用》里的介绍，配置系统参数如下： 123456789101112131415# /etc/sysctl.confnet.ipv4.tcp_max_tw_buckets = 6000net.ipv4.ip_local_port_range = 1024 65000net.ipv4.tcp_tw_recycle = 1net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_syncookies = 1net.core.somaxconn = 262144net.core.netdev_max_backlog = 262144net.ipv4.tcp_max_orphans = 262144net.ipv4.tcp_max_syn_backlog = 262144net.ipv4.tcp_synack_retries = 1net.ipv4.tcp_syn_retries = 1net.ipv4.tcp_fin_timeout = 1net.ipv4.tcp_keepalive_time = 30 个人保守起见，参数略有调整： 12345678910111213141516# /etc/sysctl.confnet.core.somaxconn = 262144 # 表示系统同时发起的最大连接数，默认128net.core.netdev_max_backlog = 262144 # 表示当每个网络接口接收数据包的速率比内核处理这些包的速率快时，允许发送到队列的数据包的最大数目，默认1000net.ipv4.ip_local_port_range = 32768 60999 # 表示允许系统随机打开的端口范围，默认32768 60999net.ipv4.tcp_max_tw_buckets = 6000 # 表示系统同时保持timewait的最大数量，默认524288net.ipv4.tcp_tw_recycle = 0 # 开启TCP连接中timewait sockets的快速回收，默认不开启net.ipv4.tcp_tw_reuse = 1 # 开启TCP连接中timewait sockets重新用于新的TCP连接，默认不开启net.ipv4.tcp_max_orphans = 262144 # 表示系统中不被关联到任何一个用户文件句柄上的TCP sockets的最大数目，可以防止简单的DoS攻击，默认262144net.ipv4.tcp_max_syn_backlog = 262144 # 表示记录尚未收到客户端确认信息的连接请求的最大数目，默认128net.ipv4.tcp_syncookies = 1 # 开启syncookies功能，可以防止部分SYN攻击，默认开启net.ipv4.tcp_synack_retries = 1 # 表示系统放弃连接之前发送SYN+ACK包的数量net.ipv4.tcp_syn_retries = 1 # 表示系统放弃连接之前发送SYN包的数量net.ipv4.tcp_fin_timeout = 3 # 表示TCP sockets保持在FIN-WAIT-2状态的时间，默认60秒net.ipv4.tcp_keepalive_time = 30 # 表示当启用keepalive的时候，TCP发送keepalive消息的频度，默认7200秒 以上参数主要为了配合NginX、PHP-FPM和MySQL致发挥更佳效能，各个参数的数值应该根据实际主机硬件条件自行调整。将配置参数追加到/etc/sysctl.conf文件后，执行以下命令，让系统重载参数： 1$ sudo sysctl -p NginX的配置优化大致配置如下： 123456789101112131415161718192021# /etc/nginx/nginx.confuser www-data; # 指定用户worker_processes 8; # woker进程数，一般设置为CPU核数*线程数worker_cpu_affinity 00000001 00000010 00000100 00001000 00010000 0010000001000000 10000000; # 为每个进程分配到指定的CPU，配合worker_processes使用worker_rlimit_nofile 204800; # 每个woker能打开的最多文件描述符数目pid /run/nginx.pid; # 进程号存放位置events &#123; use epoll; # 设置用于复用客户端线程的轮询方法 worker_connections 204800; # 每个woker的最多连接数目，不要大于worker_rlimit_nofile multi_accept on; # 启用收到一个新连接通知后接受尽可能多的连接&#125;http &#123; keepalive_timeout 30; # server &#123; listen 80 backlog=204800; # &#125;&#125; 实际上NginX的worker_connections参数会受到系统的net.core.somaxconn参数限制，而net.core.somaxconn参数也是有限制的（可以用ulimit -Hn命令查看），理论上worker_connections应该设为net.core.somaxconn除以worker_processes。在配合PHP-FPM使用的时候，如果想NginX支持1000并发请求，那么worker_connections取值不能低于2000，因为每个请求里，NginX与客户端需要一个连接，与PHP-FPM也需要一个连接。 PHP-FPM的配置优化Unix socket VS TCP socketPHP-FPM提供两种通信方式与NginX对接数据，一种是Unix socket，另一种是TCP socket。Unix socket是同一操作系统上的两个或多个进程进行数据通信的编程接口，这种通信方式是发生在系统内核里而不会在网络里传播；TCP socket则是基于TCP/IP协议，进程间的通信是通过网络传输的，可以跨系统、跨主机。两者相较之下，Unix socket更低层，执行效率更高；而TCP socket封装性更高，安全性更好。如果NginX和PHP-FPM不在同一主机上，那么只能选择TCP socket；否则，建议考虑Unix socket。 最大进程数假设一个PHP-FPM进程占用10MB内存，且打算分配1GB内存给PHP-FPM用，那么PHP-FPM的pm.pm.max_children可以设为100。当然，实际的每个PHP-FPM进程平均所需内存要根据实际情况计算。但PHP-FPM进程多不一定有用，有用是指PHP-FPM与NginX之间有连接，而连接数也是受到系统的net.core.somaxconn参数限制（连接数不是进程数，一个进程可以处理多个连接）。 MySQL的配置优化最大连接数首先，与NginX、PHP-FPM不同，MySQL是多线程方式工作。一般MySQ处理连接的方式（thread_handling）有每个连接一个线程（one-connection-per-thread）和所有连接一个线程（no-threads）。no-threads模式大多用在调试，而正式线上环境普遍采用的是one-connection-per-thread模式。 一般情况下，一个PHP-FPM进程最多只会跟MySQL建立一个连接，MySQL的最大连接数（max_connections）不应该少于PHP-FPM进程数，否则并发的时候有的PHP-FPM会连接不上MySQL。对于越来越大的并发量，不能一味提高MySQL的最大连接数，合理的方式是，设定一个MySQL连接数界限，超出的连接请求需等待。 短连接和长连接PHP-FPM与MySQL之间的连接有两种形式，分短连接和长连接。 MySQL在one-connection-per-thread模式下，PHP-FPM需要请求操作数据库时：如果PHP-FPM使用短连接形式，那么MySQL都会新建一个线程来支持这个连接，数据操作结束后，PHP-FPM会回收这个连接，MySQL也会回收对应的线程，这里就会有一定的时间消耗和的IO消耗；如果PHP-FPM使用长连接形式，在没有相同的长连接的情况下，PHP-FPM才会新建一个连接，数据操作结束后这个线程不会被回收，而是等待被复用，这样虽然会节省一些开销，但是在高并发的情况下，大量的长连接建立不回收，MySQL也管理同样多的线程，大量的上下文切换和资源竞争，会使得MySQL执行效率下降。 如果PHP-FPM采用动态进程管理模式，且所有进程都与MySQL长连接的话，那么空闲时，部分PHP-FPM进程被回收（与MySQL的连接也会被回收），部分PHP-FPM进程被保留下来（与MySQL的连接也会被保留下来）；高并发时，保留下来的PHP-FPM进程可以复用已有的MySQL连接，其他的重新建立，这就相当于极端长连接和极端短连接的折中。 一般的LNMP网站应用使用短连接访问数据库就足够了，用完就回收，减轻系统负担；中大型的可能需要使用长连接，因为操作数据库的请求不断发起，把时间和IO花费在建立新连接和回收旧连接就很浪费，但是MySQL的线程数（连接数）必须维持在合理范围内。 线程池和连接池要在高并发中，控制MySQL的线程数（连接数），一般的解决方案是设置线程池或者连接池。 线程池是在数据服务端建立有限数量的线程，来处理所有应用客户端的连接。MySQL企业版（收费）提供了线程池机制（thread_handling=pool-of-threads），详细配置可以参考官方文档MySQL Enterprise Thread Pool。 连接池是在应用客户端与数据服务端之间，设置一个中间代理，这个中间代理会与数据服务端建立有限数量的连接，来处理所有应用客户端的数据请求。连接池可以使用开源的数据库中间件atlas来搭建，也可以使用PHP扩展swoole来自己写一个。 php-cp是Swoole组织开发的一个PHP扩展，可以本地代理MySQL、Redis连接，提供连接池，读写分离，负载均衡，慢查询日志，大数据块日志等功能，在主流php框架引入使用也十分简便，具体可以参考。 其他 平时要多留意LNMP的日志信息，根据提示优化配置，比如： NginX(24: Too many open files)说明work_rlimit_nofile参数需要增大； NginX(worker_connections are not enough while connecting to upstream)说明worker_connections参数需要增大； NginX(11: Resource temporarily unavailable)一般是并发连接超过来系统的net.core.somaxconn限制； MySQL(too many connections)说明max_connections参数需要增大； MySQL(too many open files)说明open_files_limit参数需要增大，当然系统的fs.file-max也不能过小； MySQL(has gone away)是连接太久没活动被MySQL回收了，MySQL的wait_timeout也不能过小。 最后此文的LNMP优化主要是针对高并发情况，其他方面优化有机会会继续补充。]]></content>
      <categories>
        <category>求索</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>php</tag>
        <tag>nginx</tag>
        <tag>think</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[腾讯云COS的一次实践]]></title>
    <url>%2Fblog%2Fpractice-qcloud-cos.html</url>
    <content type="text"><![CDATA[很多网站都会需要文件上传、下载的功能，但是服务器本身配置（如容量、带宽等等）可能扛不住大量的上传、下载，这时候，利用一些现成的云存储服务来分担一下服务器的压力。这里主要介绍一下腾讯云COS的使用，大概的功能流程是： 前端（JS）实现文件上传功能； 后端（PHP）给前端发放签名，使前端可以直接访问COS； 根据COS生成的文件链接访问文件。 PHP后端签名机制以Laravel项目为例：首先，在项目目录下，新建目录app/Plugins/Qcloud/Cos；然后，下载COS的PHP SDK，将SDK中src/qcloud/cos下所有文件复制到项目的app/Plugins/Qcloud/Cos下，这里只用到Auth.php。大概代码： routes/web.php 1234&lt;?phpRoute::post('/qcloud/cos/sign', 'QcloudController@postCosSign');Route::post('/qcloud/cos/sign-once', 'QcloudController@postCosSignOnce'); app/Plugins/Qcloud/Cos/Auth.php 1234567891011&lt;?php/** * Signature create related functions for authenticating with cos system. */namespace App\Plugins\QCloud\Cos;// 加上命名空间/** * Auth class for creating reusable or nonreusable signature. */class Auth &#123; ...&#125; config/web.php 12345678910&lt;?php return [ 'qcloud_cos' =&gt; [ 'app_id' =&gt; '1234567890', 'secret_id' =&gt; '************************************', 'secret_key' =&gt; '********************************', 'region' =&gt; 'gz', //广州 'timeout' =&gt; 60 ],]; QcloudController.php 123456789101112131415161718192021222324&lt;?phpuse App\Plugins\QCloud\Cos\Auth as CosAuth;class QcloudController extends Controller &#123;... // 多次复用的签名 public function postQcloudCosSign(Request $request) &#123; $team = $this-&gt;getAuthUser(); $bucket = $request-&gt;input('bucket'); $timeout = time()+2*60*60; $config = config('web.qcloud_cos'); $cos_auth = new CosAuth($config['app_id'], $config['secret_id'], $config['secret_key']); $sign = $cos_auth-&gt;createReusableSignature($timeout, $bucket); return $this-&gt;responseJSON(['sign'=&gt;$sign]); &#125; // 单次使用的签名 public function postQcloudCosSignOnce(Request $request) &#123; $bucket = $request-&gt;input('bucket'); $timeout = time()+2*60*60; $config = config('web.qcloud_cos'); $cos_auth = new CosAuth($config['app_id'], $config['secret_id'], $config['secret_key']); $sign = $cos_auth-&gt;createNonreusableSignature($bucket, '/'); return $this-&gt;responseJSON(['sign'=&gt;$sign]); &#125;&#125; JS前端上传文件下载COS的JS SDK，将SDK中dist/cos-js-sdk-v4.js复制到项目的public/js下，注意使用SDK需要浏览器支持HTML 5。大概代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Demo&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div&gt; &lt;input type="file" name="upload_file" id="upload_file" /&gt; &lt;button id="do_upload"&gt;请上传&lt;/button&gt; &lt;span&gt;&lt;/span&gt; &lt;/div&gt; &lt;script type="text/javascript" src="/js/jquery.js"&gt;&lt;/script&gt; &lt;script type="text/javascript" src="/js/cos-js-sdk-v4.js"&gt;&lt;/script&gt; &lt;script type="text/javascript"&gt; var USERID = $('#user').data('id') var PREFIX = Date.now()+'_'+USERID+'_' var COS = new CosCloud(&#123; appid: '1234567890', bucket: 'public', region: 'gz', getAppSign: function (callback) &#123; $.post('/qcloud/cos/sign').done(function (data) &#123; var sign = data.sign callback(sign) &#125;).fail(function () &#123; B.alert('请求失败，稍后再试') &#125;) &#125;, getAppSignOnce: function (callback) &#123; $.post('/qcloud/cos/sign-once').done(function (data) &#123; var sign = data.sign callback(sign) &#125;).fail(function () &#123; B.alert('请求失败，稍后再试') &#125;) &#125; &#125;) $('#do_upload').click(function () &#123; var $this = $(this) var files = document.getElementById('upload_file').files if(!files.length || !files[0]) &#123; return 0 &#125; var file = files[0] if(file.size &amp;&amp; file.size &lt; 50*1024*1024) &#123; $this.prop('disabled', true) $this.text('开始上传 ') COS.uploadFile(function (result) &#123; // successCallBack setTimeout(function() &#123; $this.prop('disabled', true) $this.text('请上传 ') &#125;, 1800) $this.text('上传成功 ') &#125;, function (result) &#123; // errorCallBack setTimeout(function() &#123; $this.prop('disabled', true) $this.text('请上传 ') &#125;, 1800) $this.text('上传失败 ') &#125;, function (current) &#123; // progressCallBack $this.text('正在上传 '+ (current*100).toFixed(1)+'%') &#125;, COS.bucket, PREFIX+file.name, file, 0) &#125; else &#123; B.alert('文件不能大于50MB') &#125; &#125;) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 其他防盗链如果不想存在COS上的文件，被其他网站盗用，那么可以在COS后台上给对应的存储痛（Bucket）设置Referer白名单，防止被恶意盗链。当然，伪造Referer的请求应该也防不了。 定时清理因为前端可以直接与COS连接，上传的文件没有经过后端检验，所以有效的上传文件信息都应该记录在数据库里，然后在每天空闲时段将昨天上传的文件都遍历一遍（文件名前缀设为日期就可以据此检索），不记录在库的、类型不匹配的，体积过大的等此类文件都可以删除。 最后一个网站本身要实现文件上传、下载功能并不难，但是总是会有各样的隐患（可参考HTTP文件上传的一个后端完善方案（NginX））。于此，借用现成的云存储服务来实现文件上传、下载功能，也是一个不错的可行方案。]]></content>
      <categories>
        <category>实践</category>
      </categories>
      <tags>
        <tag>js</tag>
        <tag>php</tag>
        <tag>practice</tag>
        <tag>qcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP文件上传的一个后端完善方案（NginX）]]></title>
    <url>%2Fblog%2Fscheme-nginx-php-js-upload-process.html</url>
    <content type="text"><![CDATA[很多网站都会有上传文件的功能，比如上传用户头像，上传个人简历等等，除非是网盘类的网站，一般上传文件不会作为网站的主要功能；而且，如今大众的网速已经是足够的快，上传几百KB的文件，几乎可以秒内完成。所以，大多数网站，对于上传文件的处理，都是简单的前端POST上传，后端验证存放然后返回访问地址。毕竟，文件小，网速快，一瞬间的事情谁会多在意呢？ 存在问题假设我们有一个网站，基于NginX+PHP+JS构架，网站允许用户上传一些小视频、音乐或者PPT等文件在线上展示，单个文件大小限制不超过30MB，那么我们要怎样实现这个上传功能呢？ 限制上传文件的大小首先，NginX要能接受最大32MB的请求（除了最大文件本身30MB，再预留一些给其他请求参数），我们会修改网站的虚拟主机配置： 12345# website.confserver&#123; client_max_body_size 32M; ...&#125; 然后，PHP也要修改配置，接受最大30MB的文件上传和最大32MB的POST请求： 123# php.iniupload_max_filesize = 30M;post_max_size = 32M; 其实，单凭client_max_body_size，NginX是不能真正限制上传文件大小的，因为NginX会先让客户端（一般是浏览器）开始上传请求，直到上传的内容大小超过了限制，NginX才会中止上传，报413 Request Entity Too Large错误，没超过限制则交给PHP处理。于是，PHP的upload_max_filesize和post_max_size就更没用了，因为PHP获取到文件信息的时候，上传过程已经结束了（这时当然是上传成功，NginX中止请求的话PHP不会进场）。在NginX传递请求结果前，PHP什么（比如验证用户，验证权限等等）都做不了。 如果用户上传了一个大于32MB的时候，直到上传到32MB的时候才能告诉用户文件过大了，那么前面的时间用户不就白等了吗？而且服务器的带宽还是一样被消耗了。我们更希望在上传开始前就能告诉用户文件过大了。很多网站开发，都会把这一步交给JS处理，在新型浏览器(支持HTML5)里，JS的确可以获取input文件的大小；在旧的IE里，也可以通过ActiveX来实现。但是JS的限制处理很容易被绕过去，只要知道上传地址，一个form标签就能把文件传过去： 1234&lt;form id=&quot;upload_form&quot; action=&quot;/path/to/upload&quot; enctype=&quot;multipart/form-data&quot; method=&quot;post&quot;&gt; &lt;input type=&quot;file&quot; name=&quot;upload_file&quot; value=&quot;/path/of/big/big/file&quot; /&gt; &lt;input type=&quot;submit&quot; value=&quot;Upload&quot; /&gt;&lt;/form&gt; 正常的用户当然不会这样做，但是有意攻击网站的人会。 限制上传文件的速度如果服务器的入口带宽是100mbps，用户的上行带宽是10mbps，用户上传一个30MB的文件至少需要30秒，那么在30秒内，服务器的带宽只能满足10个用户上传文件，带宽被占满后，服务器就很难再处理其他请求了。所以，限制用户上传文件的速度就很有必要。目前，JS做不到限制上传文件的速度，PHP也做不到。 上传文件的进度用户上传一个30MB的文件至少需要30秒，那么30秒内应该告知用户上传的进度，不能让用户无感知的等待。HTML5改进了XMLHttpRequest对象，在支持HTML5的新型浏览器里，JS可以获取XMLHttpRequest上传文件的进度；在旧的浏览器的也可以通过Flash与JS结合（比如SWFUpload），从而获取上传文件的进度。但是新型浏览器里，Flash已经被摒弃了，因而要支持新旧浏览器，JS就要写成两套代码。在这里PHP也是帮不上忙，因为PHP拿到传文件信息的时候，上传已经结束了。 解决方案网站是NginX+PHP+JS构架的，PHP和JS解决不了的问题，那应该在NginX上解决它。NginX虽然是一个现成的软件，但是它还是可以继续扩展和修改的。NginX本身没有提供上传文件的复杂处理功能，而在NginX官方认可的第三方扩展模块里，有两个模块可以帮助我们实现复杂的上传文件功能，分别是nginx-upload-module和nginx-upload-progress-module。 要将nginx-upload-module和nginx-upload-progress-module编译进NginX，首先要下载NginX源码和nginx-upload-module、nginx-upload-progress-module这两个模块的源码，然后在NginX源码目录中，在configure参数中加入这两个这两个模块，最后make install，大概的执行命令： 1234567891011$ cd ~$ mkdir tmp$ cd tmp$ wget http://nginx.org/download/nginx-1.11.3.tar.gz$ tar -xvzf nginx-1.11.3.tar.gz$ git clone https://github.com/vkholodkov/nginx-upload-module.git$ git clont https://github.com/masterzen/nginx-upload-progress-module.git$ cd nginx-1.11.3$ ./configure --add-module=~/tmp/nginx-upload-module --add-module~/tmp/nginx-upload-progress-module ...$ make$ make install 如果系统上已经安装过NginX并且所安装NginX版本支持动态模块，那么可以考虑将nginx-upload-module和nginx-upload-progress-module编译成动态模块，这样就不需要重新安装NginX。nginx-module-libs上有Ubuntu系统上主线NginX版本的一些动态模块，可以上面下载适配你的nginx-upload-module和nginx-upload-progress-module。 下面主要介绍一下两个模块的用法： nginx-upload-module当上传文件的体积小于client_max_body_size时， nginx-upload-module可以帮助我们限制上传速度，使用方法见下。NginX的站点配置： 1234567891011121314151617181920212223242526272829303132333435# website.confserver &#123; ... client_max_body_size 32m; # 限制上传速度最大2Mbps upload_limit_rate 256k; location /upload &#123; # 限制上传文件最大30MB upload_max_file_size 30m; # 后续交给 upload.php 处理 upload_pass /upload.php; # 指定上传文件存放目录，1表示按1位散列，将上传文件随机存到指定目录下的0、1、2、...、8、9目录中（这些目录要手动建立） upload_store /tmp 1; # 上传文件的访问权限，user:r表示用户只读 upload_store_access user:r; # 设置请求体的字段 upload_set_form_field "$&#123;upload_field_name&#125;_name" "$upload_file_name"; upload_set_form_field "$&#123;upload_field_name&#125;_content_type" "$upload_content_type"; upload_set_form_field "$&#123;upload_field_name&#125;_path" "$upload_tmp_path"; # 指示后端关于上传文件的md5值和文件大小 upload_aggregate_form_field "$&#123;upload_field_name&#125;_md5" "$upload_file_md5"; upload_aggregate_form_field "$&#123;upload_field_name&#125;_size" "$upload_file_size"; upload_pass_form_field "^submit$|^description$"; # 若出现如下错误码则删除上传的文件 upload_cleanup 400 404 499 500-505; &#125;&#125; 上传文件的页面： 1234&lt;form id="upload" enctype="multipart/form-data" action="/upload" method="post" &gt; &lt;input name="upload_file" type="file" label="fileupload" /&gt; &lt;input type="submit" value="Upload File" /&gt;&lt;/form&gt; 处理上传结果的脚本： 123&lt;?php// upload.phpprint_r($_REQUEST); 如果对PHP解析使用了优雅链接，比如Laravel，那么应该这样使用： NginX的站点配置： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# website.confserver &#123; ... client_max_body_size 32m; # 限制上传速度最大2Mbps upload_limit_rate 256k; location / &#123; try_files $uri $uri/ /index.php?$query_string; &#125; location ~ \.php$ &#123; include snippets/fastcgi-php.conf; fastcgi_param HTTP_PROXY ""; fastcgi_pass unix:/run/php/php-fpm.sock; &#125; location @upload_handle &#123; rewrite ^ /index.php last; &#125; location /upload &#123; # 限制上传文件最大30MB upload_max_file_size 30m; # 后续交给 index.php 处理 upload_pass @upload_handle; # 指定上传文件存放目录，1表示按1位散列，将上传文件随机存到指定目录下的0、1、2、...、8、9目录中（这些目录要手动建立） upload_store /tmp 1; # 上传文件的访问权限，user:r表示用户只读 upload_store_access user:r; # 设置请求体的字段 upload_set_form_field "$&#123;upload_field_name&#125;_name" "$upload_file_name"; upload_set_form_field "$&#123;upload_field_name&#125;_content_type" "$upload_content_type"; upload_set_form_field "$&#123;upload_field_name&#125;_path" "$upload_tmp_path"; # 指示后端关于上传文件的md5值和文件大小 upload_aggregate_form_field "$&#123;upload_field_name&#125;_md5" "$upload_file_md5"; upload_aggregate_form_field "$&#123;upload_field_name&#125;_size" "$upload_file_size"; upload_pass_form_field "^submit$|^description$"; # 若出现如下错误码则删除上传的文件 upload_cleanup 400 404 499 500-505; &#125;&#125; 上传文件的页面： 12345&lt;!-- laravel blade.php --&gt;&lt;form id="upload?_token=&#123;&#123;csrf_token()&#125;&#125;" enctype="multipart/form-data" action="/upload" method="post" &gt; &lt;input name="upload_file" type="file" label="fileupload" /&gt; &lt;input type="submit" value="Upload File" /&gt;&lt;/form&gt; Laravel路由配置： 123&lt;?php// routes/web.phpRoute::post('/upload', 'Web\IndexController@upload')-&gt;name('upload'); Laravel控制器中处理上传的方法： 12345&lt;?php// Web/IndexController.phpfunction upload() &#123; dump(request());&#125; nginx-upload-progress-modulenginx-upload-progress-module可以帮助我们跟踪上传的进度，使用方法见下。 NginX的站点配置： 123456789101112131415161718# website.confserver &#123; ... client_max_body_size 32m; # 开辟一个空间proxied来存储跟踪上传的信息1MB upload_progress proxied 1m; location ^~ /progress &#123; # 报告上传的信息 report_uploads proxied; &#125; location /upload &#123; ... # 上传完成后，仍然保存上传信息5s track_uploads proxied 5s; &#125;&#125; 上传文件的页面和每隔一秒查询一下上传进度的脚本： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;form id="upload" enctype="multipart/form-data" action="/upload" method="post" onsubmit="openProgressBar(); return true;"&gt; &lt;input name="userfile" type="file" label="fileupload" /&gt; &lt;input type="submit" value="Upload File" /&gt;&lt;/form&gt;&lt;div&gt; &lt;div id="progress" style="width: 400px; border: 1px solid black"&gt; &lt;div id="progressbar" style="width: 1px; background-color: black; border: 1px solid white"&gt;&amp;nbsp;&lt;/div&gt; &lt;/div&gt; &lt;div id="tp"&gt;(progress)&lt;/div&gt;&lt;/div&gt;&lt;script type="text/javascript"&gt; var interval = null; var uuid = ""; function openProgressBar() &#123; for (var i = 0; i &lt; 32; i++) &#123; uuid += Math.floor(Math.random() * 16).toString(16); &#125; document.getElementById("upload").action = "/upload?X-Progress-ID=" + uuid; /* 每隔一秒查询一下上传进度 */ interval = window.setInterval(function () &#123; fetch(uuid); &#125;, 1000); &#125; function fetch(uuid) &#123; var req = new XMLHttpRequest(); req.open("GET", "/progress", 1); req.setRequestHeader("X-Progress-ID", uuid); req.onreadystatechange = function () &#123; if (req.readyState == 4) &#123; if (req.status == 200) &#123; var upload = eval(req.responseText); document.getElementById('tp').innerHTML = upload.state; /* 更新进度条 */ if (upload.state == 'done' || upload.state == 'uploading') &#123; var bar = document.getElementById('progressbar'); var w = 400 * upload.received / upload.size; bar.style.width = w + 'px'; &#125; /* 上传完成，不再查询进度 */ if (upload.state == 'done') &#123; window.clearTimeout(interval); &#125; if (upload.state == 'error') &#123; window.clearTimeout(interval); alert('something wrong'); &#125; &#125; &#125; &#125; req.send(null); &#125;&lt;/script&gt; 当上传文件的体积大于client_max_body_size时， nginx-upload-module未能帮我们立刻中断上传，并且不能限制上传速度，但是nginx-upload-progress-module可以向前端报告文件过大的错误，前端可以这样子来中断上传： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&lt;form id="upload" enctype="multipart/form-data" action="/upload" method="post" onsubmit="openProgressBar(); return false;"&gt; &lt;input name="userfile" type="file" label="fileupload" id="userfile" /&gt; &lt;input type="submit" value="Upload File" /&gt;&lt;/form&gt;&lt;div&gt; &lt;div id="progress" style="width: 400px; border: 1px solid black"&gt; &lt;div id="progressbar" style="width: 1px; background-color: black; border: 1px solid white"&gt;&amp;nbsp;&lt;/div&gt; &lt;/div&gt; &lt;div id="tp"&gt;(progress)&lt;/div&gt;&lt;/div&gt;&lt;script type="text/javascript"&gt; var interval = null; var uuid = ""; var uploadxhr = null; function openProgressBar() &#123; for (var i = 0; i &lt; 32; i++) &#123; uuid += Math.floor(Math.random() * 16).toString(16); &#125; var action = "/upload?X-Progress-ID=" + uuid; var file = document.getElementById('userfile').files[0]; uploadxhr = new XMLHttpRequest(); // uploadxhr.file = file; uploadxhr.open('post', action, true); uploadxhr.setRequestHeader("Content-Type","multipart/form-data"); uploadxhr.send(file); /* 每隔一秒查询一下上传进度 */ interval = window.setInterval(function () &#123; fetch(uuid); &#125;, 1000); &#125; function fetch(uuid) &#123; var req = new XMLHttpRequest(); req.open("GET", "/progress", 1); req.setRequestHeader("X-Progress-ID", uuid); req.onreadystatechange = function () &#123; if (req.readyState == 4) &#123; if (req.status == 200) &#123; var upload = eval(req.responseText); document.getElementById('tp').innerHTML = upload.state; /* 更新进度条 */ if (upload.state == 'done' || upload.state == 'uploading') &#123; var bar = document.getElementById('progressbar'); var w = 400 * upload.received / upload.size; bar.style.width = w + 'px'; &#125; /* 上传完成，不再查询进度 */ if (upload.state == 'done') &#123; window.clearTimeout(interval); &#125; if (upload.state == 'error') &#123; window.clearTimeout(interval); uploadxhr.abort(); alert('something wrong'); &#125; &#125; &#125; &#125; req.send(null); &#125;&lt;/script&gt; 另外nginx-upload-module和nginx-upload-progress-module还提供了更多的指令，帮忙我们实现更复杂的上传文件功能，比如断点续传等，有兴趣可以阅读两个模块的官方文档，了解更多。另外，因为nginx-upload-module未能及时拦下体积过大的文件上传，所以，尽管保障了用户的正常使用，可是依然不能防范恶意的流量攻击。nginx-upload-progress-module能够在一开始就检测到上传文件的体积是否过大（HTTP请求头里的Content-Length存有文件的体积大小），这时候就应该中断上传（可能是NginX限制，扩展模块无法中断HTTP请求），大家有兴趣的话可以研究一下NginX源码和扩展开发。 思考NginX的client_max_body_size设为32m，攻击者可以上传1GB的文件，直到上传到32MB的时候，NginX才会中断上传，服务器被消耗了32MB的流量。细想一下： 即使NginX在一开始就拦下了体积大于32MB的文件，可是攻击者依然可以直接上传30MB大小的文件，服务器还是会被消耗了30MB的流量，所以在一开始就拦截的意义并不大； 可是上传文件的体积大于client_max_body_size时，nginx-upload-module的限速功能不起作用，这就成问题了； NginX没有直接信任请求头的Content-Length，应该有他的依据，不过正常用户不会虚报吧（即使报小也不报大啊）； 看来这个方案还需继续完善，或者借助现成的云存储服务来实现文件上传功能（可参考腾讯云COS的一次实践）。 最后如果一个网站，允许用户全速上传文件，并持续数十秒，那么这个网站一定存在被流量攻击的风险，有可能是大量用户同时使用造成的，也有可能是恶意的DDoS攻击（？？好像所有网站都会有这个风险）。要是服务器带宽被占满，服务器对于一些用户就像是掉线了，所以上传文件的问题必须重视。另外，开发者不应该局限于一种编程语言或者一个知识领域上去思考解决问题，应该涉览更多的知识领域，从更多角度、更多方位去解决问题。 参考 OPTIMIZED FILE UPLOADING WITH PHP &amp; NGINX How to Upload Large Files in PHP 文件上传的渐进式增强]]></content>
      <categories>
        <category>方案</category>
      </categories>
      <tags>
        <tag>js</tag>
        <tag>scheme</tag>
        <tag>php</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[怎样算出Pi（π）]]></title>
    <url>%2Fblog%2Fmath-calculating-pi.html</url>
    <content type="text"><![CDATA[圆周率日（Pi Day，又译π节）是一年一度的庆祝数学常数π的节日，特地写一篇与π相关的文章。 一道题目最近碰到一道数学编程题目，就是利用以下公式求出π的（近似）值：$$ x - \frac{x^3} {3!} + \frac{x^5} {5!} - \frac{x^7} {7!} + \ldots = \sum_{n=0}^{+\infty} \frac{(-1)^n x^{2n+1}} {(2n+1)!} $$ 网上搜了一下，原来这是正弦函数的泰勒级数展开式（高等数学早忘光了）。 机智的我一下子就想到了sin(π)=0，代入上面公式，得到方程：$$ sin(\pi) = \pi - \frac{\pi^3} {3!} + \frac{\pi^5} {5!} - \frac{\pi^7} {7!} + \ldots = 0 $$ 于是：$$ \pi = \frac{\pi^3} {3!} - \frac{\pi^5} {5!} + \frac{\pi^7} {7!} - \ldots $$ 然后，解方程……呃……这个我不会！再上网找找。 百科知道有空要多看看百科知识，能学到很多东西。 梅钦公式在维基百科的圆周率条目里，提到了计算π的梅钦公式：$$ \frac{\pi} {4} = 4arctan\frac{1} {5} - arctan\frac{1} {239} $$ 这个是利用arctan(x)的泰勒级数展开式，和4arctan(1)=π推导出来的。可是用sin(x)的泰勒级数展开式不能推导出arctan(x)的泰勒级数展开式，所以用梅钦公式求π就不和题意了。 巴塞尔问题在维基百科的巴塞尔问题条目里，提到欧拉利用正弦函数的泰勒级数展开式，求证了：$$ \frac{\pi} {6} = \frac{1} {1^2} + \frac{1} {2^2} + \frac{1} {3^2} + \frac{1} {4^2} + \ldots $$ 可是求证过程中利用了零点代入方程求解，不算严谨，所以这条公式也不能用。 夹挤定理关键方向是用正弦函数去求π，于是用sin(x)和π作为关键字，又在网上搜了一遍，终于发现了一篇“有趣”的文章——一个有趣的圆周率计算公式 x=sin(x)+x。文中主要讲作者“原创”了一种求π算法，就是“通过迭代计算x=sin(x)+x，逼近π”（原话）。 通过“逼近”来求π值，的确是很有意思的一种方法。可是作者只是给出了计算方法，却没有详细的推导过程。一开始对这种算法还是持怀疑态度，直到后来想起了夹挤定理（也叫夹逼准则，其实不大记得这个名字，只是大概知道由它推导出来的极限公式），由夹挤定理可以很容易得到以下极限（一般高等数学书里都会提到）：$$ \lim_{x \rightarrow 0} sin(x) = x $$ 于是，有：$$ \lim_{\pi-x \rightarrow 0} sin(\pi-x) = pi-x $$ 又因为sin(π-x)=sin(x)，得：$$ \lim_{\pi-x \rightarrow 0} sin(x) + x = pi $$ 假设，x大于0小于π，则sin(x)大于0小于1；在x无限趋于π时，sin(x)+x也在无限趋于π，而且比x更趋于π（因为这里sin(x)不是负数）；所以，不断地让x=sin(x)+x那么x就可以无限地接近π了。 再用sin(x)的泰勒级数展开式代替sin(x)，那么求π的函数代码（javascript）就很容易写了： 12345678910111213141516171819202122232425262728var INFINITY = 100; // 用100表示正无穷，越大越准，太大可能会溢出var PI = 3; // x的初始值设为接近PI的数，比如3，也可以是1、2、2.1、2.2、...function getPI(len) &#123; if(PI&gt;3) &#123; return PI.toFixed(len); &#125; for(var i=0; i&lt;INFINITY; i++) &#123; PI = taylorSin(PI)+PI; &#125; return PI.toFixed(len);&#125;function taylorSin(x) &#123; var sinx = 0; for(var i=0; i&lt;INFINITY; i++) &#123; sinx+=Math.pow(-1, i)*Math.pow(x, i*2+1)/factorial(i*2+1); &#125; return sinx;&#125;function factorial(n) &#123; var f = n; while(--n) &#123; f*=n; &#125; return f;&#125; 所以，π值怎么算？死循环算啊。 最后其实，求π的方法还有很多，尽管π是一个无理数，有兴趣的读者可以浏览一下网页，特别是贝利-波尔温-普劳夫公式，其可以直接算出小数点后面的第n位数值： 如何计算圆周率 Pi 贝利-波尔温-普劳夫公式 高斯-勒让德算法 梅钦类公式 巴塞尔问题]]></content>
      <categories>
        <category>求索</category>
      </categories>
      <tags>
        <tag>math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于用户多标签的更新]]></title>
    <url>%2Fblog%2Fthink-about-user-tags.html</url>
    <content type="text"><![CDATA[在项目开发中，经常要现实这样的一个功能——关系表更新。比如，一个用户可以设置多个标签，而一个标签下又可以有多个用户，两者是多对多的关系，用一张关系表记录用户的标签数据，那么，当更新用户标签的时候，怎样安排执行流程，才是最优的呢？ 数据关系假设数据库中有三张表，user，tag，user_tag： 假设数据库中有三张表， user: id name 1 user1 2 user2 3 user3 … … tag: id title 1 tag1 2 tag2 3 tag3 … … user_tag: | id | user_id | tag_id | deleted_at|| — | — | — | — | — || 1 | 1 | 1 | null || 2 | 2 | 1 | null || 3 | 3 | 1 | null || … | … | … | null | user_tag表记录了user表和tag表之间的关系，并且user_tag表内使用软删除。 问题描述如果用户user1的标签为tag1、tag2和tag3，现在想更新为tag2、tag4和tag6，那么应该怎样操做？ 解决方案最暴力的解决办法就是delete旧数据，然后insert新数据。但是项目中，为了安全，一般会禁用硬删除，而使用软删除。如果用软删除结合insert，关系表就会越来越大。 比较常用的解决方案是：实时更新和差集更新。 实时更新当给用户添加一个标签时，后台立刻更新；当给用户移除一个标签时，后台也立刻更新，这样的做法，实现起来很简单，（伪）代码如下： 1234567891011121314151617181920// with laravel// in UserTag Modelstatic public function addUserTag($user_id, $tag_id) &#123; $user_tag = self::where(['user_id'=&gt; $user_id, 'tag_id'=&gt; $tag_id])-&gt;first(); if($user_tag) &#123; $user_tag-&gt;deleted_at = null; return $user_tag-&gt;save(); &#125; else &#123; $user_tag = new self; $user_tag-&gt;user_id = $user_id; $user_tag-&gt;tag_id = $tag_id; $user-&gt;save(); &#125;&#125;static public function removeUserTag($user_id, $tag_id) &#123; return self::where(['user_id'=&gt; $user_id, 'tag_id'=&gt; $tag_id])-&gt;update(['deleted_at'=&gt; time()]);&#125; 差集更新如果使用实时更新，那么每次操作都要向后台发送请求，这样的请求一般都是小而多，倒不如使用批量更新。比较一下新数据和就数据，针对差集进行更新，（伪）代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748// with laravel// in UserTag Modelstatic public function getAllUserTagID($user_id) &#123; $result = self::(['user_id'=&gt; $user_id])-&gt;select('tag_id'); if($result) &#123; return $result-&gt;pluck('tag_id')-&gt;toArray(); &#125; return [];&#125;static public function insertUserTags($user_id, array $tag_ids) &#123; $data = []; foreach ($tag_ids as $tag_id) &#123; $data[] = [ 'user_id' =&gt; $user_id, 'tag_id' =&gt; $tag_id, ]; &#125; return self::insert($data);&#125;static public function updateUserTags($user_id, array $tag_ids, $action = 'in') &#123; self::where(['user_id'=&gt; $user_id])-&gt;whereIn('tag_id', $tag_ids); if ($action == 'in') &#123; return $builder-&gt;update(['deleted_at'=&gt; null]); &#125; else if ($action == 'out') &#123; return $builder-&gt;update(['deleted_at'=&gt; time()]); &#125; return false;&#125;// in UserTag Controllerpublic function postUserTags($request) &#123; $user_id = session('user_id'); $old_tag_ids = UserTag::getAllUserTagID($user_id); $new_tag_ids = $request-&gt;input('tag_ids'); // is array $save_tag_ids = array_intersect($old_tag_ids, $new_tag_ids); // 需要保留的标签id $throw_tag_ids = array_diff($old_tag_ids, $save_tag_ids); // 需要删除的标签id $add_tag_ids = array_diff($new_tag_ids, $save_tag_ids); // 需要添加的标签id UserTag::updateUserTags($employee-&gt;id, $save_tag_ids, 'in'); UserTag::updateUserTags($employee-&gt;id, $throw_tag_ids, 'out'); UserTag::insertUserTags($employee-&gt;id, $add_tag_ids);&#125; 最后最后说两句，多点关注array_intersect、array_diff等等PHP数组函数的使用。]]></content>
      <categories>
        <category>求索</category>
      </categories>
      <tags>
        <tag>think</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于JS的MVVM实现]]></title>
    <url>%2Fblog%2Fthink-about-js-mvvm.html</url>
    <content type="text"><![CDATA[过去Web应用的常用开发模式是MVC，前端后台并在一起开发。随着JavaScript语言的发展，前端能做的越来越多，Web应用开发也趋向了“前后端分离”。前后端分离并不是什么新概念，实质是Web应用从B/S（浏览器／服务器）结构向C/S（客户端／服务端）结构转变 。分离后，前端就自成一个系统，大家开始探讨前端的开发模式，而其中MVVM模式备受推崇。 MVVMMVVM，即Model-View-ViewModel，是从MVC衍生出来的开发模式。MVVM模式用ViewModel替代了Controller，ViewModel就像是Model和View之间的桥梁——数据模型通过ViewModel展示在视图中，当视图发生变化，可以通过ViewModel来触发数据更改；而数据的更改，也可以通过ViewModel来触发View变化，示意图： 数据模型和视图之间的作用是相互的，数据模型跟随了视图变化，视图也跟随数据模型更改，这是一种双向绑定。数据模型和视图的双向绑定是MVVM的基础架构。如果数据模型和视图能够双向绑定，那么前端中用户的复杂交互操作，可以短短几行代码就能实现。但是，怎么才能让数据模型和视图双向绑定呢？ 猜想最初体验到数据模型和视图的双向绑定，是在Angular的教程文档里。从面子，看里子，数据模型和视图的双向绑定是怎么实现的呢？当时就想到了set/get的方法（set/get是指对属性进行操作封装，这里主要用到的是set），伪代码如下： 1234567891011121314151617181920212223242526272829303132333435function Model(data) &#123; var _view; this.bind = function(view) &#123; _view = view; &#125;; this.set = function(name, value) &#123; this[name] = value; _view.update(); &#125;; this.update = function() &#123; // reset by _view; &#125;&#125;function View(dom) &#123; var _model; this.bind = function(model) &#123; _model = model; &#125;; dom.addEventListener('change', function() &#123; _model.update(); &#125;); this.update = function() &#123; // render by _model &#125;;&#125;var m = new Model(data);var v = new View(dom);m.bind(v);v.bind(m);m.set('a', 1);... Model实例通过set方法来修改属性时，set方法中已经带有更新对应View实例的代码；View实例在HTML中的标签触发change事件时，回调函数中也带有更新对应Model实例的代码，这样就简单的实现了一个Model和View的双向绑定。然而，能不能直接通过等于号=赋值时就触发了数据修改的事件呢？ 主流实现主流的前端MVVM框架，实现双向绑定的做法大概可归纳为以下三种： 发布-订阅 脏值检查 数据劫持 发布-订阅发布-订阅，是一种事件模型。Model和View都有各自的发布、订阅方法，同时Model在修改数据的时候会发布广播，而View订阅了这个广播，在收到广播的时候更新视图；View在视图更新的时候会发布广播，而Model也订阅了这个广播，在收到广播的时候更新数据，这样就形成了双向绑定，大致的实现代码与上面的“猜想”差不多。Backbone.js就是使用了 发布-订阅 来实现双向绑定。 脏值检查脏值检查，是指在特定情况下，检查数据是否有修改，是否需要更新视图；或者检查视图是否有更改，是否需要更新数据。例如，我们可以利用setInterval函数来设置定时检查，尽管非实时，但也可以实现了双向绑定。Angular.js也是使用脏值检查来实现双向绑定。不过Angular.js不是定时周期地去检查，而是在一些特殊事件发生时，才执行脏值检查，比如： DOM的change、check、click等事件； XHR响应事件； $digest()、$apply()、$timeout()和$interval()等函数的调用； … 数据劫持ECMAScript262v5中Object有了一个新的方法属性：defineProperty。Object.defineProperty() 方法会直接在一个对象上定义一个新属性，或者修改一个已经存在的属性，并返回这个对象；同时，能够设置该属性在被get或set的回调函数，该属性被赋值，或者被取值的时候都会执行回调函数，这就是数据劫持。利用这个新特性，再结合 发布-订阅，我们就能实现直接通过等于号=赋值时就触发了数据修改的事件，进而更新视图。Vue.js正是使用了这种方式实现了Model到View的绑定，当然View到Model的绑定还是靠监听HTML的DOM事件。 最后最后说两句，如果前端使用了MVVM模式开发，那么一定要抛弃过去手动操作DOM来获取数据、更新视图等等思想（尤其是jQuery根深蒂固的影响），否则很难融入MVVM。]]></content>
      <categories>
        <category>求索</category>
      </categories>
      <tags>
        <tag>think</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于封装第三方类库]]></title>
    <url>%2Fblog%2Fthink-about-encapsulating-libs.html</url>
    <content type="text"><![CDATA[在写《jQuery Ajax的封装》的时候，突然想到一些东西，于是就试着写下来…… 控制反转学习Laravel时，不可避免地一定要研究“控制反转”。这里并不详细介绍“控制反转”，只是简单阐述一些其主要思想。控制反转，是一种编程思想，通过“依赖注入”和“依赖查找”实现依赖倒置。本来一个实体，其控制权主要在其所依赖的其他实体身上，如果反转了这种关系，那么控制权就回到实体自己身上，实际上就是减弱对其他实体的依赖性（就是解耦吧）。控制反转，也是一种设计模式。按照控制反转模式来编程，模块定义的步骤会变得繁杂，但是模块调用还是简便的；模块与模块之间的依赖性减弱，如果后期某个模块有所改动，对于其他模块的影响并不大。 依赖隔离在项目开发中，经常会引入一些第三方类库，毕竟没有足够的时间去开发维护所有功能。引入了第三方类库，我们的代码就会依赖这些类库，就是说，如果缺失了某个类库，或者某个类库发生了一些特殊更改，那么我们的代码就不能够正常运行了。首先，我们在引入第三方类库时，尽量选择持续更新，版本稳定的优质类库，这样的类库很少会出现停止更新，或者版本大改的情况，在使用过程会相对的稳定。引入第三方类库之后，我们就要明白一个事实，第三方类库不可能百分百的适配我们的项目，总是会有一些已知或未知的变数，这时候，其实也是引入了风险。对于足够优秀的类库，我们可以给予足够的信任，但是，谁又能够保证呢？还有，其他的不怎么优秀的类库呢？ 我的建议是对于一些有顾虑的第三方类库，引入后不应该直接使用，而是加一层封装，其实就是加一层隔离。把第三方类库封装在一个模块里面，然后这个模块给其他模块使用，如果那个第三方类库发生比较大的变更，那么只是对应的那个封装模块需要改动，其他模块并不受影响，这样我们的代码就不会处于被人牵一发而全身动的局面。 引入一个第三方类库，我们的项目代码肯定对它有所依赖，但是通过封装隔离，项目整体上对它的依赖性并不高，因为主要都集中在那个封装它的模块里了。这样子，我们项目对自身的控制权还是在自己的手中。 最后最后说两句：通过封装隔离，来减弱对第三方类库的依赖，也许与“控制反转”的实现方式有所不同，但是与其降低耦合的目标是一致的。]]></content>
      <categories>
        <category>求索</category>
      </categories>
      <tags>
        <tag>think</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP中的abstract、interface和trait]]></title>
    <url>%2Fblog%2Fphp-abstract-interface-trait.html</url>
    <content type="text"><![CDATA[面向对象编程，有几个重要特征：继承性，抽象性，多态性等等。这里针对PHP语言，讨论一下abstract、interface和trait，其他语言可能有偏差。 abstract抽象类在面向对象的概念中，所有的对象都是通过类来描绘的。具体类是实例对象的抽象化，而 抽象类 则是具体类的抽象化。定义一个具体类，使用关键字class；定义一个抽象类，要带上关键字abstract，即abstract class。PHP语言的机制比较宽松，抽象类可以继承于其他抽象类，也可以继承于具体类，但是抽象类没有直接的实例化对象。 12345678910111213141516171819202122232425262728&lt;?php abstract class AbstractClass1 &#123; // 强制要求子类定义这些方法 abstract protected function getValue(); abstract protected function prefixValue($prefix); // 普通方法（非抽象方法） public function printOut() &#123; print $this-&gt;getValue() . "\n"; &#125; &#125; class ConcreteClass1 extends AbstractClass1 &#123; protected function getValue() &#123; return "ConcreteClass1"; &#125; public function prefixValue($prefix) &#123; return "&#123;$prefix&#125;ConcreteClass1"; &#125; &#125; abstract class AbstractClass2 extends ConcreteClass1 &#123; &#125; 抽象方法抽象类中可以设置属性，定义具体方法，特别，还可以定义 抽象方法。定义定义一个抽象方法，需要使用关键字abstract，并且只能在抽象类中定义。抽象类中，只能声明抽象方法其调用方式（参数），不能定义其具体的功能实现；而在抽象类的具体子类中，一定要将父类中的所有抽象方法具体化： 具体方法不再带abstract声明； 具体方法的访问控制必须和父类中一样（或者更为宽松）； 具体方法定义的调用方式必须与抽象方法的声明匹配，即所需参数的数量、类型必须一致。如果要增加参数，只能在末尾追加，并且只能是可选参数。 interface首先，接口不是类，既不是具体类，也不是抽象类，接口的定义就没有用到关键字class。定义一个接口，使用关键字interface： 123456789101112131415161718192021&lt;?php interface a &#123; const b = 'Interface constant'; public function foo(); &#125; interface b &#123; public function bar(); &#125; interface c extends a, b &#123; public function baz(); &#125; class ConcreteClass implements c &#123; public function foo()&#123;&#125; public function baz()&#123;&#125; public function bar()&#123;&#125; &#125; 接口有以下几个特点： 接口不能被实例化，因为接口不是类； 接口可以继承于其他接口，并且可以多重继承，但不能继承于类； 接口中不能设置属性，但是可以设置常量； 接口的方法只能是公有的，并且是只声明不定义； 具体类、抽象类都可以使用关键字implements来实现（多个）接口； 具体类中一定要具体化所有要实现的接口方法，并且定义的调用方式必须与接口中所声明的匹配，即所需参数的数量、类型必须一致。如果要增加参数，只能在末尾追加，并且只能是可选参数。 traittrait，中文意思是 特点，算是PHP的一个新语法（自PHP5.4加入）。PHP本身是不支持多重继承的，trait就是为了减少单继承语言的限制而提出，开发人员可以通过trait自由地在不同层次结构内独立的类中复用代码。trait示例： 123456789101112131415161718&lt;?php trait A &#123; public $a = 1; public function say() &#123; echo 'a'; &#125; abstract public function selfSay(); &#125; trait B &#123; use A; &#125; class C &#123; use B; public function selfSay() &#123; echo 'c'; &#125; &#125; trait有以下几个特点： trait不是类，无法通过自身来实例化，也不能继承或者被继承； 但是trait中，可以定义属性，定义具体方法，还可以声明抽象方法； 正如class能够使用trait一样，trait也能够使用其他trait。在trait定义时可以使用一个或多个trait。 使用trait的时候还要注意： 优先级。从基类继承的成员会被 trait 插入的成员所覆盖。优先顺序是来自当前类的成员覆盖了trait的方法，而trait则覆盖了被继承的方法。 多个trait。通过逗号分隔，在use声明列出多个trait，可以都插入到一个类中。 冲突问题。如果引入的两个trait都定义了一个同名方法，且没有明确的解决冲突，那么代码将会产生一个致命错误。为了解决多个 trait 在同一个类中的命名冲突，可以使用insteadof操作符来明确指定使用冲突方法中的哪一个，或者使用as 操作符将其中一个冲突的方法以另一个名称来引入： 123456789101112131415161718192021222324252627282930&lt;?php trait A &#123; public function smallTalk() &#123; echo 'a'; &#125; public function bigTalk() &#123; echo 'A'; &#125; &#125; trait B &#123; public function smallTalk() &#123; echo 'b'; &#125; public function bigTalk() &#123; echo 'B'; &#125; &#125; class Talker &#123; use A, B &#123; B::smallTalk insteadof A; A::bigTalk insteadof B; &#125; &#125; class Aliased_Talker &#123; use A, B &#123; B::smallTalk insteadof A; A::bigTalk insteadof B; B::bigTalk as talk; &#125; &#125; as操作符还可以用来调整方法的访问控制： 1234567891011121314&lt;?php trait HelloWorld &#123; public function sayHello() &#123; echo 'Hello World!'; &#125; &#125; // 修改 sayHello 的访问控制 class MyClass1 &#123; use HelloWorld &#123; sayHello as protected; &#125; &#125; // 给方法一个改变了访问控制的别名，原版 sayHello 的访问控制则没有发生变化 class MyClass2 &#123; use HelloWorld &#123; sayHello as private myPrivateHello; &#125; &#125; 最后PHP面向对象开发时，要灵活利用abstract、interface和trait，不要生搬硬套。 参考-类与对象-抽象类-类与对象-对象接口-类与对象-Trait]]></content>
      <categories>
        <category>知道</category>
      </categories>
      <tags>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows上编译PHP]]></title>
    <url>%2Fblog%2Fphp-compile-on-windows.html</url>
    <content type="text"><![CDATA[平时在Windows系统上做PHP开发，都是直接使用WAMP的继承环境。最近需要用到一个PHP扩展，也没找到现成的DLL文件，于是想着自己编译一个。首先，需要安装一个Visual Studio Visual Studio上大学的时候，老师教我们用 VC6.0 ，我就在自己电脑上装了个 Visual Studio 2010*，功能全选，占了好十几GB空间，然后就没怎么用了，看来只是想体验一下进度条的优雅。后来用上了 *Sublime ，以为此生足矣，没想到今天还是要求 Visual Studio 2015， 不愧为天下第一IDE。 安装过程略去： 熟悉的界面： 其实这里与Visual Studio IDE没有多大关系，主要是要使用它的控制台： PHP SDKPHP For Windows，是一个PHP官方提供Windows系统支持的网站。这里可以找到，已经编译好的、可以在Windows系统上直接运行的PHP，PECL上各种PHP扩展的DLL文件，还有在Windows系统上编译PHP时需要用到的一些工具。 在Windows系统上编译PHP，需要准备以下材料： PHP源码，比如php-7.0.14.tar.gz PHP SDK，比如php-sdk-binary-tools-20110915.zip 编译时依赖，比如deps-7.0-vc14-x64.7z 编译步骤工作空间首先，把php-sdk-binary-tools-20110915.zip里面的内容解压到一个文件夹中，例如：D:\php-sdk-binary-tools。然后打开VC2015 x64 CMD，执行以下命令： 12345D:cd D:\php-sdk-binary-tools\bin\phpsdk_setvars.batbin\phpsdk_buildtree.bat phpdevxcopy /E phpdev\vc9\* phpdev\vc14\ 再把deps-7.0-vc14-x64.7z里面的内容解压到D:\php-sdk-binary-tools\phpdev\vc14\x64，php-7.0.14.tar.gz里面的内容解压到D:\php-sdk-binary-tools\phpdev\vc14\x64\php-7.0，这时候，目录结构大概如下： 12345678910111213141516D:\php-sdk-binary-tools\ |--bin\ |--phpdev\ | |--vc6\ | |--vc8\ | |--vc9\ | |--vc14\ | |--x64\ | |--deps\ | |--bin\ | |--include\ | |--lib\ | |--php-7.0\ | |--x86\ |--script\ |--share\ 开始编译打开VC2015 x64 CMD，执行以下命令： 123456789D:cd D:\php-sdk-binary-tools\phpdev\vc14\x64\php-7.0buildconfconfigure --helpconfigure nmakenmake snap configure --help会输出可用的选项，按需选择。 编译扩展如果需要编译某个PHP扩展，比如名字叫someone_ext， 可以将其源码放置到D:\php-sdk-binary-tools\phpdev\vc14\x64\php-7.0\ext\someone_ext中，然后执行以下命令： 12345D:cd D:\php-sdk-binary-tools\phpdev\vc14\x64\php-7.0nmake cleanbuildconf --forceconfigure --help 正常情况下，configure --help的输出中someone_ext这个PHP扩展的相关选项，执行configure带上相关选项即可。只编译someone_ext这个PHP扩展，不重新编译PHP，大概的命令如下： 12configure --disable-all --enable-someone_ext=sharednmake 后记一开始提到初衷是想编译一个PHP扩展的，但是上文只字未提，主要是因为，在编译完PHP后，下载扩展的源码时才发现，它不支持Windows系统（只有config.m4，没有config.w32），欲哭无泪。这个扩展名字叫pecl-gearman，万事求不得人，有空自己写一个吧（估计写一个config.w32就行了吧），挽勉自尊。 参考 PHP For Windows Build your own PHP on Windows 在Windows下编译PHP和PHP扩展]]></content>
      <categories>
        <category>躬行</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>practice</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP中的$this、self和parent]]></title>
    <url>%2Fblog%2Fphp-%24this-self-parent.html</url>
    <content type="text"><![CDATA[可继承性是面向对象编程的重要特征。在开发过程中，由于类与类之间继承关系，我们很容易弄混对象属性的真实归属，到底自己代码所调用的是父类属性还是子类属性呢？这里针对PHP语言，讨论一下$this、self和parent这三个关键字的作用。 基本概念 声明一下，以下的所有描述都是基于PHP的E_STRICT模式，也希望大家的PHP代码运行于E_STRICT模式下，否则代码很容易产生二义。 首先，$this、self和parent只能在类定义内部使用。 $this是一个伪变量，不能也不需要手动赋值。在类内部定义方法时，$this自动指向了主叫对象，即是主叫对象的引用。如果没有实例化对象，$this就是空值；在静态方法中$this一直是空值，不管是被类名调用，还是被实例化对象调用。 与$this不同，self不是一个变量，不能作为参数传递予函数。在类定义内部，self指向了当前的类。无关有没有实例化对象，self是当前类的引用。在代码上，使用self的地方，都可以用当前类名代替，且运行结果不会改变；然而，使用$this-&gt;的地方，如果是在调用类方法（不是类属性），也可以用self::代替，虽然语法上没有错误，但是逻辑上会有差异，详见下面 $this与self。 parent也不是一个变量，也不能作为参数传递予函数。在类定义内部，parent指向了当前类的直接父类，如果当前类没有父类，使用parent则会报错。 $this与self对于$this与self，一般认为：$this引用类的实例化对象，可以调用类的所有属性和方法；而self引用类本身，与实例化对象无关，只能调用静态资源（如类常量、静态属性和静态方法）。但是实际上self可以“踩过界”——self也可以调用非静态资源。 分析在类定义内部， $this-&gt;后面可以连接当前类的所以类属性和类方法，但不能连接类常量；而self::后面可以连接类常量、静态属性和 _所有类方法_。self可以调用非静态方法，实际上是要借用当前类的实例化对象来调用的。在静态方法中，self不能调用非静态方法，正如$this不能被使用；而在非静态方法中，self就可以调用其他非静态方法了，正如$this可以正常被使用。那么，在非静态方法中调用其他非静态方法，使用$this-&gt;和使用self::有什么区别呢？ 1234567891011121314151617181920212223&lt;?php class A &#123; public function name() &#123; echo 'A'; &#125; public function thisName() &#123; $this-&gt;name(); &#125; public function selfName() &#123; self::name(); &#125; &#125; class B extends A &#123; public function name() &#123; echo 'B'; &#125; &#125; $b = new B(); $b-&gt;name(); // echo B; $b-&gt;thisName(); // echo B; $b-&gt;selfName(); // echo A; 对于调用非静态方法，可以这样来总结$this和self的区别：$this是直接指向 运行时 的实例化对象的，而self是借用 定义时 的实例化对象。（self是不能调用非静态属性的，所以这一点不需要讨论$this与self的区别） 使用假设父类定义了一个非静态方法a，里面调用了另一个非静态方法b： 如果希望子类的实例化对象调用a时可以使用子类自身的b，那么，父类的a定义时应该使用$this-&gt;b();； 如果希望子类的实例化对象调用a时可以使用父类的b，那么，父类的a定义时就应该使用self::b();。 $this与parent在类定义内部，parent指向了当前类的直接父类。parent和self的意义不同，但是性质上是几乎一样的。 分析parent::后面可以连接直接父类的常量、静态属性和 _所有类方法_。parent可以调用非静态方法，实际上是借用直接父类的实例化对象来调用的。直接看代码： 12345678910111213141516171819202122232425262728293031323334353637383940&lt;?php class A &#123; public function name() &#123; echo 'A'; &#125; public function thisName() &#123; $this-&gt;name(); &#125; public function selfName() &#123; self::name(); &#125; &#125; class B extends A &#123; public function name() &#123; echo 'B'; &#125; public function parentName() &#123; parent::name(); &#125; public function bparentName() &#123; parent::name(); &#125; &#125; class C extends B &#123; public function name() &#123; echo 'C'; &#125; public function parentName() &#123; parent::name(); &#125; &#125; $c = new C(); $c-&gt;name(); // echo C; $c-&gt;parentName(); // echo B; $c-&gt;bparentName(); // echo A; 对于调用非静态方法，parent是借用 定义时 的直接父类的实例化对象。（parent也是不能调用非静态属性的） 使用后期静态绑定性质上，self和parent可以归为一类，其实它们还有一个同类——static。范围解析操作符::，除了类名，就只有这三个关键字可以使用。 分析上面 $this与self 的讨论是基于对非静态方法的调用，如果是对静态方法的调用呢？还是直接看代码： 12345678910111213141516171819202122&lt;?php class A &#123; public static function name() &#123; echo 'A'; &#125; public static function staticName() &#123; static::name(); &#125; public static function selfName() &#123; self::name(); &#125; &#125; class B extends A &#123; public static function name() &#123; echo 'B'; &#125; &#125; B::name(); // echo B; B::staticName(); // echo B; B::selfName(); // echo A; 这里static::的作用，叫做 后期静态绑定，用于在继承范围内引用静态调用的类。从语言内部角度看，“后期绑定”的意思是说：static::不被解析为 定义时 当前类，而是在实际 运行时 的使用类。static::后面只能连接静态属性和静态方法，弥补了$this与self的不足。 使用假设父类定义了一个静态方法a，里面调用了另一个静态方法b： 如果希望子类调用a时可以使用子类自身的b，那么，父类的a定义时应该使用static::b();； 如果希望子类调用a时可以使用父类的b，那么，父类的a定义时就应该使用self::b();。 最后所以在定义类的时候，应该使用$this的地方就使用$this，应该使用self的地方就使用self，parent估计会很少用到，总之不要混着用了。 参考-类与对象-基本概念-类与对象-范围解析操作符-类与对象-后期静态绑定-类与对象-基本概念]]></content>
      <categories>
        <category>知道</category>
      </categories>
      <tags>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTML中单引号的转义符]]></title>
    <url>%2Fblog%2Fphp-escape-apostrophe-in-html.html</url>
    <content type="text"><![CDATA[就在今天（2016-11-12），一个正常运行了几个月的Web管理系统，突然出现了一个BUG，而且只针对个别用户，其他用户使用正常；排查了一下，发现问题就出在HTML的转义符上。 HTML的转义符就算没查看过HTML的符号表，HTML写的多了，也自然会知道空格的转义符是&amp;nbsp;。其他一些常用的转义符还有： 显示 转义实体名称 转义实体编号 “ &qout; &#34; &amp; &amp; &#38; &lt; &lt; &#60; &gt; &gt; &#62; … … … 有些符号没有转义的实体名称，但一定有转义的实体编号，可以查看HTML ASCII 参考手册。这里先说明单引号&#39;的转义符是&amp;#39;， 下面再来陈述今天遇到的BUG。 还原现场PHP开发者经常会把一些数据保存在HTML页面上，方便JS开发者调用，比如说，把用户的一些个人信息记录在页面上： 1234567891011//php&lt;?php $user = array( "id" =&gt; 1 "name" =&gt; "坂本", "work" =&gt; "贵干", "addr" =&gt; "不详'", );?&gt;//html&lt;button class="btn user-btn" data-user='&lt;?php echo json_encode($user); ?&gt;' &gt;查看信息&lt;/button&gt; 这里可以看到，button标签的class的值用双引号包合，而data-user的值用单引号包合，因为PHP中的json_encode函数会产生双引号，如果data-user的值用双引号包合，碰上json_encode函数产生的双引号，就会提前闭合，保存的值就失真了。 但是，另一个问题也随之而来：数组user的addr属性的值是&quot;不详&#39;&quot;，这个值由用户填写，不知道有意还是无意，值中带有一个单引号，于是data-user的值还是被提前闭合而失真了。 这该怎么解决呢？ 正则替换当然是用正则匹配替换的方法啊！一开始我以为单引号&#39;的转义符是\&#39;，毕竟类C语言都是这样子，于是就写了一个正则替换，把&#39;（不包括\&#39;）换成\&#39;： 1preg_replace('/([^\\])\'/', '$1\\\'', json_encode($user)); 运行一下，报错了。可能是因为优先级限制，&#39;/[^\\]\&#39;/&#39;中先转义了]，于是就报出中括号没闭合的错误。那就加上个括号()，区分一下： 1preg_replace('/([^(\\)])\'/', '$1\\\'', json_encode($user)); 哈，替换是成功了，可是\&#39;中还是带有&#39;，data-user的值还是被提前闭合了…… 解决办法网上查了一下，才知道HTML中&#39;的转义符根本不是\&#39;，而是&amp;#39;，于是，最后的解决办法就是： 1preg_replace('/\'/', '&amp;#39;', json_encode($user)); 把数据直接保存在页面标签的data属性上，这种实现方式经常会用到的吧，但是要注意转义一下单引号或者双引号： 1preg_replace(array('/\'/', '/"/'), array('&amp;#39;', '&amp;#34;'), json_encode($user)); 最后两句最后说两句，只要是BUG，一定能百分百重现；BUG不针对谁，BUG针对所有人。]]></content>
      <categories>
        <category>躬行</category>
      </categories>
      <tags>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[批量更新短ID]]></title>
    <url>%2Fblog%2Fmysql-mass-update-short-id.html</url>
    <content type="text"><![CDATA[生成唯一码（ID）的方案有很多，一般要减少冲突，就要增加码长。可是，很多应用场景中（比如把唯一码附在URL中），我们就需要比较短的唯一码。 Hashids这里先推荐一个生成短ID的开源库——Hashids，它的实现原理大概是根据长的唯一码，通过转码，生成短的唯一码。如果想要得到尽量短的唯一码，那么原码应该是纯数字ID。 Mysql的自增ID以Mysql的自增ID作为原码，借助Hashids，就可以得到比较短的唯一码。插入一条记录再更新字段，其实现过程是先Insert，然后Update。但是，如果是批量插入记录，那又应该怎样更新短ID字段呢？ 批量更新不同值因为短ID来源于自增ID，所以必然是先插入记录，才能获取到短ID。在批量插入记录后，再一条一条地去更新短ID字段，效率肯定很慢。 如果有Hashids在Mysql中有实现函数（比如说，函数名字叫HASHID）的话，那么更新语句可以这样写： 1UPDATE table_name SET `short_id` = HASHID(`id`) WHERE `short_id` IS NULL; 事实是目前还没有实现HASHID这个函数，这里记下一个方法，以备后忘： 12345678910111213// with laravel$list = DB::table('table_name')-&gt;whereNull('short_id')-&gt;select('id')-&gt;get();$ids= [];$sql = ' CASE id ';foreach($list as $k=&gt;$v) &#123; $ids[] = $v-&gt;id; $short_id = Hashids::encode($v-&gt;id); $sql .= sprintf('WHEN %d THEN "%s" ', $v-&gt;id, $short_id);&#125;$sql .= ' END ';DB::table('table_name')-&gt;whereIn('id', $ids)-&gt;update(['short_cdkey'=&gt;DB::raw($sql)]); 最后两句CASE WHEN是一个好东西，要多灵活使用。]]></content>
      <categories>
        <category>躬行</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CONCAT 和 GROUP_CONCAT]]></title>
    <url>%2Fblog%2Fmysql-concat-and-group_concat.html</url>
    <content type="text"><![CDATA[在MySQL数据库中查询数据的时候，如果查询语句里使用了GROUP BY，那么SELECT表字段时只能获取分组内第一条记录的数据值，要怎样才能得到分组内所有记录的字段数据值呢？ CONCATMySQL中，主要的连接字符串函数，就是 CONCAT。CONCAT函数用于将多个数据值连接成一个字符串。语法： 1CONCAT(str1, str2, …) 注意：如果有任何一个参数为NULL，那么返回结果就是NULL。怎样避免参数为NULL的情况，当然是使用CASE WHEN： 1CONCAT(CASE WHEN str1 is NULL THEN "NULL" ELSE str1 END, CASE WHEN str2 is NULL THEN "NULL" ELSE str2 END, …) 还有个连接字符串的函数，CONCAT_WS，表示“CONCAT With Separator”，是CONCAT的特殊形式。CONCAT_WS函数用于将多个数据值用指定的分隔符连接成一个字符串。语法： 1CONCAT_WS(separator, str1, str2, …) 注意：如果第一参数，即分隔符，设置为空字符串&#39;&#39;，相当于移除分隔符，设置为NULL，那么返回结果就是NULL；其他参数如果为NULL，就会被忽略，进而连接下个参数，但是空字符串&#39;&#39;不会被忽略。为了保证连接数据的顺序，还得使用CASE WHEN： 1CONCAT_WS(separator, CASE WHEN str1 is NULL THEN "NULL" ELSE str1 END, CASE WHEN str2 is NULL THEN "NULL" ELSE str2 END, …) GROUP_CONCATGROUP_CONCAT函数可以将分组内的数据连接合成一个字符串。因为是做分组内操作，所以GROUP_CONCAT的功能会复杂一些，处理可以设置分隔符，还可以对记录数据做去重，排序处理。在逻辑上，GROUP_CONCAT应该是与GROUP BY配合使用的，当然就算查询语句中没有出现GROUP BY，也是可以使用GROUP_CONCAT的，就是把整个记录数据看作一个组了。语法： 12345GROUP_CONCAT( [DISTINCT] expr [,expr ...] [ORDER BY &#123;unsigned_integer | col_name | formula&#125; [ASC | DESC] [,col_name ...]] [SEPARATOR str_val]) 注意：分隔符缺省为一个逗号&quot;,&quot;，可以设置为空字符串&#39;&#39;，相当于移除分隔符，但是不能设置为NULL，否则报错；如果某个连接参数的值为NULL，就会被忽略，进而连接下个参数，但是空字符串&#39;&#39;不会被忽略。 应用在MySQL数据库中查询数据的时候，如果查询语句里使用了GROUP BY，那么SELECT表字段时只能获取分组内第一条记录的数据值，要怎样才能得到分组内所有记录的字段数据值呢？ 假设，有两张表，users和friends：users: id name 1 user1 2 user2 3 user3 friends: id user_id name create_at 1 1 friend1 1457452801 2 1 friend2 1457452802 3 1 friend3 1457452803 4 2 friend4 1457452804 5 2 friend5 1457452805 6 2 friend6 1457452806 7 3 friend7 1457452807 8 3 friend8 1457452808 9 3 friend9 1457452809 想要获取每一个user的所有firend，并且按照create_at顺排序的话，可以使用GROUP_CONCAT和CONCAT_WS： 12345678910111213SELECT u.id as user_id, u.name as user_name, GROUP_CONCAT( CONCAT_WS("%", f.id, f.name) ORDER BY f.create_at ASC SEPARATOR ";" ) as friends_groupFROM users as u JOIN friends as f on u.id = f.user_idWHERE 1; 最后最后说两句，在MySQL中查询数据时，要获取分组内的数据时，可以考虑使用GROUP_CONCAT。还有组内数据排序，也可以借用GROUP_CONCAT。]]></content>
      <categories>
        <category>知道</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SELECT INTO 和 INSERT SELECT INTO]]></title>
    <url>%2Fblog%2Fmysql-select-into-and-insert-select-into.html</url>
    <content type="text"><![CDATA[开发中经常会碰到把已存在记录的数据赋给新记录的场景，怎样才能把SELECT和INSERT合并到一个执行语句中呢？ SELECT INTO语法： 1SELECT `t1`.`column1` AS column1, `t1`.`column2` AS column2, 'column3' AS column3 INTO `Table2` FROM `Table1` AS t1; 注意：执行过程中，会创建表Table2，所以，执行前要求表Table2不存在。 INSERT SELECT INTO语法： 1Insert INTO `Table2` (column1, column2, ...) SELECT value1,value2,... FROM `Table1`; 注意：执行前要求表Table2存在切有固定结构；SELECT前面没有VALUES关键字；FROM后面可以跟更复杂的查询语句。]]></content>
      <categories>
        <category>知道</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jQuery Ajax的封装]]></title>
    <url>%2Fblog%2Fjs-encapsulate-jquery-ajax.html</url>
    <content type="text"><![CDATA[程序开发时，经常引入第三方类库。如果类库中的一些函数调用得非常频繁，那么就应该考虑自己封装一下，这样对于后面的代码迭代，会带来很大便利。这里针对jQuery.ajax，讨论一下其如何封装，对于其他类库或许也适用。 $.ajaxjQuery的ajax的确是个好东西，主要实现异步HTTP请求的功能，相信大家都有用过，并且觉得好用。jQuery从1.5.0版本开始，引入了deferred对象，$.ajax（都知道$是jQuery的别称）的调用就变得更加简单快捷。比如，发起一个POST请求： 123var url = '/';var data = &#123;&#125;;$.post(url, data).done(function() &#123;&#125;).fail(function() &#123;&#125;); $.ajax本身就是对 XMLHttpRequest 的封装，并且已经封装得非常好。借用$.ajax，我们只需要一两行代码就能完成一个异步HTTP请求；$.ajax在很多应用场景中也适用，那么，为什么还要自己再封装一层呢？ 毕竟，世间没有百分百完美的第三方类库，各个开发项目有各自不同的需求，$.ajax本身不可能完全去适配，自己改装一下很有必要；对于以后的代码变更，如果直接使用$.ajax，那么控制权就在jQuery手中，而自己封装一层，控制权就在自己手中，到时候改代码会简单很多。 还是先说说，怎么封装$.ajax吧。比如，封装$.post： 12345678910111213141516171819202122// 假设前面已经引入了jQueryfunction BL() &#123; this._author = 'BreezeLin'; this._version = '0.1.0';&#125;BL.prototype = &#123; post: function(url, data) &#123; return $.post(url, data); &#125;,&#125;// 或者BL.prototype = &#123; post: function() &#123; return $.post.apply(this, arguments); &#125;,&#125;;// 使用var B = new BL();B.post('/', &#123;&#125;).done(function() &#123;&#125;).fail(function() &#123;&#125;);// 后面凡是要发起异步POST请求，都是使用B.post，而不是$.post 哈，说好的封装，结果只是直接返回，这样的封装跟不封装有什么区别？是的，当前是没有区别，一切都是为以后的代码迭代做准备。假设有那么一天，jQuery开始收费或者停止更新，如果我们做了这一层的封装，那么我们只需要在BL.prototype中，实现或者加固异步HTTP功能——实际上我们的代码完全可以摆脱对jQuery依赖，控制权始终在我们手上（怎么有种“控制反转”的感觉？）。 参数过滤一般的HTTP传输，为了确保安全性，都会对请求参数进行加密。$.ajax是原样提交的，不能满足（所以肯定要封装啊）。如果一开始就有做自己的一层封装，那么后期从参数无加密，到参数加密，或者加密算法变更都是很方便的。像下面代码，只需要修改my_encrypt函数，就行了： 1234567891011121314function BL() &#123; this._author = 'BreezeLin'; this._version = '0.1.0';&#125;// 加密函数function my_encrypt(data) &#123; return data;&#125;BL.prototype = &#123; post: function(url, data) &#123; data = my_encrypt(data); return $.post(url, data); &#125;,&#125;; 第一个参数，请求路径，可能会需要补全、校验等操作，也可以在BL.prototype里面设置。如果有必要，还可以考虑开发第三参数，第四参数…… 回调函数改装 别看“参数过滤”和“回调函数改装”名字上不对仗，实际上他们是异步HTTP请求的一前一后：一个是请求前处理，一个是返回后处理。 首先，我们假设开发项目中有这么一个场景： 项目的HTTP服务接口采用数据无加密返回； 前端JS的异步请求使用的是$.ajax，并且进行了如下封装： 123456789function BL() &#123; this._author = 'BreezeLin'; this._version = '0.1.0';&#125;;BL.prototype = &#123; post: function(url, data) &#123; return $.post(url, data); &#125;,&#125;; 项目代码中，多处使用了如下代码： 1234567891011var B = new BL();var url = '/';var data = &#123;&#125;;B.post().done(function(result) &#123; // 伪代码，对返回数据的一些操作 if(result.status==1) &#123; handle_with(result.data); &#125; else &#123; alert(result.info); &#125;&#125;); 问题来了，项目的HTTP服务接口开始采用数据加密返回。 如果当初自己没有封装$.ajax，那么项目中用到异步请求的地方只能一行一行代码地去改（所以知道自己封装的好处了吧）。现在是有自己封装且多处调用了，但是请求返回有变更，那该怎么办呢？ 其实这是一道面试题，单凭这个问题就可以展开写成一篇文章了。这个问题，以前面试的时候人家问过我，后来面试的时候我也问过人家，虽然不是百分百的原题，但是核心思想是一样的。 先看问题：项目中，done函数已经被大量使用，一个个地去改，工程量太大；但是done的函数参数中的result已经被加密，不能直接使用，比如alert(result.info);并不能得到预期结果。 解决办法：还是得修改done函数，在哪里改呢？在BL.prototype里面改。这其实是对JavaScript中函数的call或者apply，arguments等知识点的考查： 12345678910111213141516171819202122232425262728function BL() &#123; this._author = 'BreezeLin'; this._version = '0.1.0';&#125;;// 解密函数function my_decrypt(data) &#123; return data;&#125;BL.prototype = &#123; post: function(url, data) &#123; var $deferred = $.post(url, data); var $done = $deferred.done; $deferred.done = function() &#123; var arg1 = arguments[0]; if(typeof arg1 === 'function') &#123; var func = function() &#123; var args = arguments; var result = args[0]; args[0] = my_decrypt(result); return arg1.apply(this, args); &#125;; arguments[0] = func; &#125; return $done.apply(this, arguments); &#125;; return $deferred; &#125;,&#125;; 哈哈，代码是不是有点绕，细心读一下，还是挺精彩的。这是一个二重改装，先改装了done函数，在改装了done函数参数（嗯，好像比原来的面试题复杂了点，开始还以为实现不了了）。就这样，本来调用了done函数的地方不用改动代码，程序也可以能够正常运行了。 最后最后说两句：项目开发的过程中，经常会引入一些第三方类库，这样自己代码就会“依赖”这些类库；我们自己对其封装一层，把控制权掌握在自己手中，还是很有必要的。自己封装代码，对后面不可预期的变更风险，还是有相对高的可控性。jQuery.ajax只是一个例子，以其为镜，对频繁使用的类库加一层自己的封装，保证自己的控制权。]]></content>
      <categories>
        <category>躬行</category>
      </categories>
      <tags>
        <tag>js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[时间的灰烬]]></title>
    <url>%2Fblog%2Ffilm-ashes-of-time.html</url>
    <content type="text"><![CDATA[第一次看《东邪西毒》，那些独白，一句句戳入心肺；后来每次看完，都想写点东西，却发现写的还是那一句句独白。 慕容嫣一直在问，问你最喜欢的人是不是我；孤女一直在等，等那个为她报仇的人出现； 武士一心想回到家乡，再看一眼桃花；洪七一心想出去闯荡，就算带上妻子； 黄药师喝了半埕醉生梦死，渐渐忘了一切；欧阳锋也喝了半埕醉生梦死，却记得更清楚： 记得曾经有个人问他，最爱的人是不是我；记得曾经有个人等他，等他回去； 记得曾经出来闯荡，却没有带上她；记得曾经想过回去，却始终没有…… 所以话，年青人唔好睇王家卫明明系爱，偏偏唔讲]]></content>
      <categories>
        <category>有感</category>
      </categories>
      <tags>
        <tag>life</tag>
        <tag>film</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动手写一个简单的PHP扩展]]></title>
    <url>%2Fblog%2Fphp-a-simple-extension.html</url>
    <content type="text"><![CDATA[PHP基于C语言编写，支持自定义扩展，扩展自然也是基于C语言编写咯。大学里学（水）过C语言，写一个简单的PHP扩展，应该没问题吧。 运行环境 OS：Linux PHP：5.6 phpize：20131226 新建项目标准的自动生成首先要准备一份 PHP源代码 。将源代码包解压后，在ext目录里（PHP自带扩展的源代码就存放在这里），可以找到一个名字叫做ext_skel的可运行文件。这个ext_skel文件就是PHP提供给我们来创建扩展项目的，用法： 12$ cd ext/$ ./ext_skel --extname=my_ext_name 执行如上命令后，当前路径下就会多了一个名字叫my_ext_name的目录，里面存放着一个规范的PHP扩展项目代码，这些都是ext_skel自动生成的。主要的文件是这几个： config.m4（对应unix） config.w32（对应windows） my_ext_name.c php_my_ext_name.h 如果对扩展结构已经足够熟悉，./ext_skel命令后面带上--no-help参数，自动生成的代码中就不会出现多余的注释。 手动创建当然，没有ext_skel，也可以自己手动建立一个PHP扩展项目，先新建一个目录来存放代码： 12$ mkdir my_ext_name$ cd my_ext_name 然后新建一个 config.m4 文件，写入如下配置： 12345678//config.m4PHP_ARG_ENABLE(my_ext_name, whether to enable my_ext_name support,[ --enable-my_ext_name Enable my_ext_name support])if test "$PHP_MY_EXT_NAME" != "no"; then PHP_SUBST(MY_EXT_NAME_SHARED_LIBADD) PHP_NEW_EXTENSION(my_ext_name, my_ext_name.c, $ext_shared)fi 解释一下： PHP_ARG_ENABLE函数是用来配置扩展的工作方式的，如果该扩展依赖其他扩展，应该使用PHP_ARG_WITH函数（这里不用）； PHP_SUBST函数将变量输出到由configure生成的文件中； PHP_NEW_EXTENSION函数声明了该扩展的名称（如my_ext_name）、需要的源文件名（如my_ext_name.c）、此扩展的编译形式（$ext_shared）。$ext_shared这个参数表明该扩展不是一个静态模块，而是在PHP运行时动态加载的。更多内容参见《PHP扩展开发与内核应用》的 第五章 。 编写函数接下来，把想要实现的功能写入扩展中。写点什么好呢？其实我想写一个友好时间转化的函数，这是一个怎样的函数？用PHP语言表达会直观点： 123456789101112131415161718192021222324252627282930313233343536373839function php_friendly_time($time) &#123; $arg_time = null; $now_time = null; $dif_time = null; $ret_time = null; $timeinfo = null; if(is_int($time)) &#123; $arg_time = $time; &#125; else if(is_string($time)) &#123; $arg_time = strtotime($time); &#125; else &#123; return null; &#125; $now_time = time(); $dif_time = $now_time - $arg_time; if($dif_time&lt;60) &#123; $ret_time = 'just now'; &#125; else if($dif_time&lt;120) &#123; $ret_time = 'one minute ago'; &#125; else if($dif_time&lt;3600) &#123; $ret_time = (int)($dif_time/60) . ' minutes ago'; &#125; else if($dif_time&lt;7200) &#123; $ret_time = 'one hour ago'; &#125; else if($dif_time&lt;86400) &#123; $ret_time = (int)($dif_time/3600) . ' hours ago'; &#125; else if($dif_time&lt;172800) &#123; $timeinfo = getdate($arg_time); $ret_time = 'one day ago ' . $timeinfo['hours'] . ':' . $timeinfo['minutes']; &#125; else if($dif_time&lt;1209600) &#123; $timeinfo = getdate($arg_time); $ret_time = (int)($dif_time/86400) . ' days ago ' . $timeinfo['hours'] . ':' . $timeinfo['minutes']; &#125; else &#123; $ret_time = date("Y-m-d H:i:s", $arg_time); &#125; return $ret_time;&#125; 好，想表达的大概就是这个意思，那么用C语言怎么在PHP扩展实现呢？ 头文件按照C语言开发规范，我们先创建一个头文件php_my_ext_name.h，这里主要是做一些宏定义操作： 1234567891011//php_my_ext_name.h#ifndef PHP_MY_EXT_NAME_H#define PHP_MY_EXT_NAME_H#define phpext_my_ext_name_ptr &amp;my_ext_name_module_entry#define PHP_MY_EXT_NAME_VERSION "0.1.0"extern zend_module_entry my_ext_name_module_entry;#endif 程序文件创建一个程序文件my_ext_name.c，里面要写的代码大概是这样的： 1234567891011121314151617181920212223242526272829303132333435//my_ext_name.c#ifdef HAVE_CONFIG_H#include "config.h"#endif#include "php.h"#include "php_my_ext_name.h"PHP_FUNCTION(friendly_time)&#123; ...&#125;const zend_function_entry my_ext_name_functions[] = &#123; PHP_FE(friendly_time, NULL) PHP_FE_END&#125;;zend_module_entry my_ext_name_module_entry = &#123; STANDARD_MODULE_HEADER, "my_ext_name", my_ext_name_functions, NULL, /* MINIT */ NULL, /* MSHUTDOWN */ NULL, /* RINIT */ NULL, /* RSHUTDOWN */ NULL, /* MINFO */ PHP_MY_EXT_NAME_VERSION, STANDARD_MODULE_PROPERTIES&#125;;#ifdef COMPILE_DL_MY_EXT_NAMEZEND_GET_MODULE(my_ext_name)#endif 主要是这几个步骤： 首先，加载一些需要的头文件； 用PHP_FUNCTION这个宏函数定义想要在PHP中实现的扩展函数，参数名称将会是在PHP中调用的函数名称，如：friendly_time； 然后在一个zend_function_entry结构体数组中，用PHP_FE（也是一个宏函数）注册刚刚定义的扩展函数，如：friendly_time； 接下来，就是在一个zend_module_entry结构体中填写扩展模块的入口信息，当然这个结构体的名字要跟扩展名对应，如：my_ext_name_module_entry； 最后，判断一下这个扩展模块是否被动态链接，如果是，就执行ZEND_GET_MODULE宏函数（在这里一定是）。 简单的介绍一下PHP_FUNCTION，他的宏定义如下： 1234#define PHP_FUNCTION ZEND_FUNCTION#define ZEND_FUNCTION(name) ZEND_NAMED_FUNCTION(ZEND_FN(name))#define ZEND_NAMED_FUNCTION(name) void name(INTERNAL_FUNCTION_PARAMETERS)#define ZEND_FN(name) zif_##name 所以呢，PHP_FUNCTION(friendly_time)最终会被转化成： 1void zif_friendly_time(INTERNAL_FUNCTION_PARAMETERS) 这样子看，代码是不是觉得熟悉多了？这才是正常的C代码啊！大家有没有注意到my_ext_name_functions数组里没有,分隔？来看看PHP_FE的宏定义： 12#define ZEND_FE(name, arg_info) ZEND_FENTRY(name, ZEND_FN(name), arg_info, 0)#define ZEND_FENTRY(zend_name, name, arg_info, flags) &#123; #zend_name, name, arg_info, (zend_uint) (sizeof(arg_info)/sizeof(struct _zend_arg_info)-1), flags &#125;, 于是，PHP_FE(friendly_time, NULL)最终会被转化成： 1&#123;"friendly_time",zif_walu_hello,NULL, (zend_uint) (sizeof(NULL)/sizeof(struct _zend_arg_info)-1), 0 &#125;, 可以看到,已经带上了。如果扩展模块里有多个函数，可以继续使用PHP_FUNCTION来定义，如PHP_FUNCTION(more_function){...}；然后在my_ext_name_functions数组中以与friendly_time同样的形式注册函数，如：PHP_FE(more_function)。 具体实现那么，PHP_FUNCTION(friendly_time)函数具体要怎么实现呢？先上代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455PHP_FUNCTION(friendly_time)&#123; char* strg; int argc; int len; int dif_time; long arg_time; long now_time; struct tm tm_time; zval **arg; argc = ZEND_NUM_ARGS(); if (argc == 0) &#123; RETURN_NULL(); &#125; if (zend_parse_parameters(argc TSRMLS_CC, "Z", &amp;arg) == FAILURE) &#123; RETURN_NULL(); &#125; if (Z_TYPE_PP(arg) == IS_STRING) &#123; strptime(Z_STRVAL_PP(arg), "%Y-%m-%d %H:%M:%S", &amp;tm_time); arg_time = mktime(&amp;tm_time); &#125; else if(Z_TYPE_PP(arg) == IS_LONG) &#123; arg_time = Z_LVAL_PP(arg); &#125; else &#123; RETURN_NULL(); &#125; time ( &amp;now_time ); dif_time = now_time - arg_time; if(dif_time&lt;60) &#123; len = spprintf(&amp;strg, 0, "just now"); &#125; else if(dif_time&lt;120) &#123; len = spprintf(&amp;strg, 0, "one minute ago"); &#125; else if(dif_time&lt;3600) &#123; len = spprintf(&amp;strg, 0, "%d minutes ago", dif_time/60); &#125; else if(dif_time&lt;7200) &#123; len = spprintf(&amp;strg, 0, "one hour ago"); &#125; else if(dif_time&lt;86400) &#123; len = spprintf(&amp;strg, 0, "%d hours ago", dif_time/3600); &#125; else if(dif_time&lt;172800) &#123; tm_time = *localtime( &amp;arg_time ); len = spprintf(&amp;strg, 0, "one day ago %d:%d", tm_time.tm_hour, tm_time.tm_min); &#125; else if(dif_time&lt;1209600) &#123; tm_time = *localtime( &amp;arg_time ); len = spprintf(&amp;strg, 0, "%d days ago %d:%d", dif_time/86400, tm_time.tm_hour, tm_time.tm_min); &#125; else &#123; tm_time = *localtime( &amp;arg_time ); len = spprintf(&amp;strg, 0, "%d-%d-%d %d:%d", tm_time.tm_year+1900, tm_time.tm_mon+1, tm_time.tm_mday, tm_time.tm_hour, tm_time.tm_min); &#125; RETURN_STRINGL(strg, len, 0);&#125; 这里涉及了几个知识点，记好了，考试会考到（开玩笑的）： 变量类型 函数参数 函数返回 接收参数 ZEND_NUM_ARGS这个函数（看他名字全大写，就知道也是个宏函数）可以获取到扩展函数在PHP运行环境中传入的参数个数； zend_parse_parameters函数是用来解析传入参数的，像上面的代码中： 123if (zend_parse_parameters(argc TSRMLS_CC, "Z", &amp;arg) == FAILURE) &#123; RETURN_NULL();&#125; Z表示传入的参数类型是zval**（即在PHP中调用该函数时可以传入任意类型函数），这里是把一个zval**类型参数赋值给变量arg，详细内容参见《PHP扩展开发与内核应用》的 第七章 ； 大家有没有发现zend_parse_parameters的第一个参数和第二参数是用空格分隔的，实际上他的宏定义是这样的： 1#define TSRMLS_CC ,tsrm_ls 所以，,是有的。那么他的作用是什么呢？具体参见《揭秘TSRM（Introspecting TSRM）》。 类型判断Z_TYPE_PP(arg) == IS_STRING要表达的意思很直观，就是判断一下变量arg的实际值是不是字符串类型，Z_TYPE_PP是用来获取zval**类型变量的实际值类型，类似的还有Z_TYPE（对应zval）和Z_TYPE_P（对应zval*）。PHP内核中的变量类型详细内容参见《PHP扩展开发与内核应用》的 第二章。 返回值比如在上面代码中，传入参数合法的花，返回的是RETURN_STRINGL(strg, len, 0)。与之类似的还有RETURN_LONG、RETURN_DOUBLE、RETURN_BOOL和RETURN_NULL等待，具体参见《PHP扩展开发与内核应用》的 第六章。 编译运行代码编写完成后，在扩展项目目录下执行： 1234$ phpize$ ./configure$ make$ make install 如果编译成功的话，该扩展模块已经安装到本地的PHP中了，然后在php.ini（一般在/etc/php/下）中开启该扩展模块，即在php.ini里加上： 1extension="my_ext_name.so" 用一下命令可以查看PHP开启的扩展模块： 1$ php -m 测试一下friendly_time函数能不能正常运行： 1$ php -r 'echo friendly_time(time()-1000), "\n";' 最后通过测试比较，扩展形式实现的friendly_time函数，和纯PHP语言实现的php_friendly_time函数的执行效率差距不大，所以说，并不是所有的函数都应该用扩展形式实现。除非是非常复杂、耗时的操作需要以扩展形式实现，否则，我们应该尽量地使用PHP提供的原生函数来实现想要的功能。 源码 https://coding.net/u/breeze2/p/php-ext-dev-trip/git 参考 风雪之隅 PHP扩展开发与内核应用]]></content>
      <categories>
        <category>躬行</category>
      </categories>
      <tags>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于查询数据去重]]></title>
    <url>%2Fblog%2Fmysql-about-deduplication.html</url>
    <content type="text"><![CDATA[开始在MySQL中，去除重复数据的方式有两种：分别是DISTINCT和GROUP BY，虽然两者的去重效率都不高，但是GROUP BY的执行效率要比DISTINCT高，有图为证：图样，并没有图，这里只把道理说清楚，图不重要。 GROUP BY使用GROUP BY去重，是直接把每一行记录分到对应的组里，第一条入组的记录会成为组代表，SELECT字段值就是选取该条记录的字段值。 DISTINCT而使用DISTINCT去重，是真正意义上的去重，对于每一条记录，都会先查询一下是否已经存在（慢在这里），不存在就选上，存在就跳过。 索引如果对需要去重的关键字段加上索引，去重效率会有大幅度提升，而且使用DISTINCT去重的执行效率，和使用GROUP BY去重的差不多。其实索引就像是GROUP BY的缓存，对于关键字段的相同的记录，它们的索引是一样的，就像是分到了同一组里。有了索引，就好像已经分好了组，去重的速度自然就变快了；而DISTINCT会按照GROUP BY的方式去重，彼此的效率自然也就差不多了。 子查询讨论数据去重问题怎么会扯上子查询呢？我们先来探讨一下重复数据是怎么产生的。 JOIN + GROUP BY一般来说，单表里面很少会有重复数据，但是连接（JOIN）上一对多关系或者多对多关系的其他表时，总的记录数量就有可能增加。然而我们更关注主表的内容，总是希望主表的记录能保持唯一，副表的某些内容用GROUP_ CONCAT()串联起来作为一个字段值附在主表上就好了，这时我们通常会用GROUP BY（不用效率低的DISTINCT）主表的主键来去重。主表的主键当然有索引，但是这个索引只能用在主表里面使用，JOIN上其他表后，索引就没什么用了(当然，)，这时候再用GROUP BY，效率不但没有提高，还可能变得更低（因为记录数量增加了）。 解决数据重复问题，可以考虑如何去除重复，但更应该考虑的是：如何阻止重复数据的产生（问题的根源） Subquery VS JOIN普遍的，大家总是推崇使用JOIN，而避免使用子查询。因为大多情况下，JOIN可以替代子查询，并且效率更高。 反过来说，就是子查询也能替代JOIN 所以，子查询跟数据去重问题扯上了！JOIN，特别是OUTER JOIN可能会产生数据重复，正是问题的根源。如果不考虑去重，那么自然选择JOIN，而不用子查询；但是如果在JOIN后又要用GROUP BY去重，那么还不如选择子查询。合适地使用子查询，执行效率会比JOIN+GROUP BY要更高。 最后说一句不要整天的JOIN、JOIN、JOIN；有的还整天LEFT JOIN、LEFT JOIN、LEFT JOIN……]]></content>
      <categories>
        <category>求索</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Apache HTTP Server中的Allow、Deny指令]]></title>
    <url>%2Fblog%2Fapache-allow-and-deny.html</url>
    <content type="text"><![CDATA[在配置Apache HTTP Server的时候，经常会用到Allow、Deny这两个个指令，来实现目录权限控制、内外网隔离的功能。然而这两个指令是怎样相互配合使用的呢？ mod_authz_hostmod_authz_host是Apache HTTP Server的一个官方标准模块，主要提供三个指令：Allow，Deny和Order，指令用在&lt;Directory&gt;, &lt;Files&gt;, &lt;Location&gt;中，也用于.htaccess文件中控制对服务器特定部分的访问。Allow和Deny指令用于指出允许哪些用户主机及不允许哪些用户主机访问服务器，而Order指令设置默认的访问状态并配置Allow和Deny指令怎样相互作用。 AllowAllow，控制哪些主机能够访问服务器的某些区域。用法： 1Allow from 10.1.2.3 DenyDeny，控制哪些主机被禁止访问服务器的某些区域。用法： 1Deny from 10.1.2.3 OrderOrder，控制默认的访问状态与Allow和Deny指令生效的顺序在没有Order指令的情况下，Allow的优先级会比Deny高，如下配置实际上没有限制IP10.1.2.3主机的访问权限： 123Deny from 10.1.2.3Allow from 10.1.2.3Deny from 10.1.2.3 Order的有三种取值： Deny,Allow Deny指令在Allow指令之前被评估。默认允许所有访问。任何不匹配Deny指令或者匹配Allow指令的客户都被允许访问。 Allow,Deny Allow指令在Deny指令之前被评估。默认拒绝所有访问。任何不匹配Allow指令或者匹配Deny指令的客户都将被禁止访问。 Mutual-failure 只有出现在Allow列表并且不出现在Deny列表中的主机才被允许访问。这种顺序与”Order Allow,Deny”具有同样效果，不赞成使用。 关键字只能用逗号分隔,它们之间不能有空格。注意在所有情况下每个Allow和Deny指令语句都将被评估。]]></content>
      <categories>
        <category>知道</category>
      </categories>
      <tags>
        <tag>apache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[写在之前]]></title>
    <url>%2Fblog%2Ffeature.html</url>
    <content type="text"><![CDATA[写在之前每当我有想不明白的事情，我会试着把它写下来。如果我能写的清楚，那么我就能知道它的道理。 不能说的，应该保持沉默； 能够说的，一定能说清楚。 Write it down and make it out.]]></content>
      <categories>
        <category>封面</category>
      </categories>
      <tags>
        <tag>dream</tag>
      </tags>
  </entry>
</search>
